{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des Datasets\n",
    "=============\n",
    "\n",
    "Ce notebook prépare les datasets séparés, standardisés, relabelés, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" !!! Long run time (csv importation) !!! \"\"\"\n",
    "import proj1_helpers as _help\n",
    "\n",
    "yb, input_data, ids, featnames = _help.load_csv_data('all/train.csv', step=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_data, yb\n",
    "\n",
    "PRI_jet_num = 22\n",
    "EPSILON = np.finfo(float).eps\n",
    "NULL, ONE, PLURAL = 0, 1, 2\n",
    "\n",
    "cond_null = X[:, PRI_jet_num] == 0.\n",
    "cond_one = X[:, PRI_jet_num] == 1.\n",
    "cond_plural = X[:, PRI_jet_num] >= 2.\n",
    "conditions = (cond_null, cond_one, cond_plural)\n",
    "\n",
    "dsets = [X[cond] for cond in conditions]\n",
    "ybs = [y[cond] for cond in conditions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now, just remove any column with undefined -999 values\n",
    "\n",
    "clean_dsets = []\n",
    "\n",
    "for dset in dsets:\n",
    "    \n",
    "    contains_undef = (dset == -999).any(axis=0)\n",
    "    dset_no_undef = dset.T[~contains_undef].T\n",
    "\n",
    "    # Check all -999 were indeed removed\n",
    "    assert not (dset_no_undef == -999).any()\n",
    "        \n",
    "    clean_dsets.append(dset_no_undef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "\n",
    "We standardize each ***dset*** in ***dsets***, check if ***(mean, norm) == (0, 1)*** and put the result in ***std_dsets***.\n",
    "\n",
    "After this cell, ***std_dsets*** contains the ***dsets*** NULL, ONE and PLURAL in standardized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dsets = []\n",
    "\n",
    "for dset in clean_dsets:\n",
    "    means = np.mean(dset, axis=1)\n",
    "    norms = np.std(dset, axis=1)\n",
    "    std_dset = ((dset.T - means) / norms).T\n",
    "    \n",
    "    # Check new distributions are indeed N(0, 1²)\n",
    "    assert np.all(np.abs(std_dset.mean(axis=1)) < EPSILON)\n",
    "    assert np.all(np.abs(std_dset.std(axis=1) - 1) < EPSILON+1e-16)#TODO understand why < EPSILON fails here\n",
    "    \n",
    "    std_dsets.append(std_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 19) + (4,) = (4, 20)\n",
      "(2, 23) + (2,) = (2, 24)\n",
      "(4, 30) + (4,) = (4, 31)\n"
     ]
    }
   ],
   "source": [
    "# Adds yb's to newdatasets\n",
    "\n",
    "augmented_sets = []\n",
    "\n",
    "for yb, dset in zip(ybs, std_dsets):\n",
    "    aug = np.column_stack((yb, dset))\n",
    "    print(dset.shape, '+', yb.shape, '=', aug.shape)\n",
    "    augmented_sets.append(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves .csv files with results\n",
    "\n",
    "keys = ('NULL', 'ONE', 'PLURAL')\n",
    "\n",
    "for key, dset in zip(keys, augmented_sets):\n",
    "    np.savetxt(f'{key}.csv', dset, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
