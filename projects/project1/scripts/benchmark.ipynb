{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_visualization(lambds, mse_tr, mse_te):\n",
    "    \"\"\"visualization the curves of mse_tr and mse_te.\"\"\"\n",
    "    plt.semilogx(lambds, mse_tr, marker=\".\", color='b', label='train error')\n",
    "    plt.semilogx(lambds, mse_te, marker=\".\", color='r', label='test error')\n",
    "    plt.xlabel(\"lambda\")\n",
    "    plt.ylabel(\"rmse\")\n",
    "    plt.title(\"cross validation\")\n",
    "    plt.legend(loc=2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"cross_validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_and_standardize(input_data, mean=None, std=None):\n",
    "    if mean is not None and std is not None:\n",
    "        mean_x = mean\n",
    "        std_x = std\n",
    "        tx = (input_data - mean) / std\n",
    "        num_samples = input_data.shape[0]\n",
    "        tx = np.c_[np.ones(num_samples), tx]\n",
    "    else: \n",
    "        x, mean_x, std_x = standardize(input_data)\n",
    "        tx = build_model_data(x)\n",
    "    return tx, mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_labels():\n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(tx, ws, pri_jet_num_idx, clean_features, parameters):\n",
    "    cond_null = tx[:, pri_jet_num_idx] == 0\n",
    "    cond_one = tx[:, pri_jet_num_idx] == 1\n",
    "    cond_plural = tx[:, pri_jet_num_idx] >= 2\n",
    "    conditions = (cond_null, cond_one, cond_plural)\n",
    "\n",
    "    N = tx.shape[0]\n",
    "    model_output = np.zeros(N)\n",
    "    for pri_jet_num, cond in enumerate(conditions):\n",
    "        select_features = clean_features[pri_jet_num]\n",
    "        reduced_dset = tx[cond][:,select_features]\n",
    "        mean, std = parameters[pri_jet_num]\n",
    "        extended_dset,_,_ = extend_and_standardize(reduced_dset,mean,std)\n",
    "        weight = ws[pri_jet_num]\n",
    "        sub_output = extended_dset.dot(weight)\n",
    "        model_output[cond] = sub_output\n",
    "        \n",
    "    return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(model_output):\n",
    "    predictions = model_output\n",
    "    predictions[predictions > 0.5] = 1 \n",
    "    predictions[predictions <= 0.5] = 0 \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predictions(model_output):\n",
    "    predictions = np.sign(model_output)\n",
    "    predictions[predictions == -1] = 0\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, predictions):\n",
    "    N = y.size\n",
    "    accuracy = 1 - (np.count_nonzero(predictions-y)/N)\n",
    "    print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(weights, clean_features, parameters):\n",
    "    np.save('all/weights.npy', weights)\n",
    "    np.save('all/clean_features.npy', clean_features)\n",
    "    np.save('all/parameters.npy', parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Without feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'all/train.csv'\n",
    "labels, input_data, ids, features = load_csv_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n",
       "       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
       "       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n",
       "       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n",
       "       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num',\n",
       "       'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
       "       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n",
       "       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], dtype='<U27')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "i, = np.where(features == 'PRI_jet_num')\n",
    "categorial_index = np.squeeze(i)\n",
    "print(categorial_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = extend_and_standardize(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/99): loss=0.1710925, w0=-2.9427268665000046, w1=-1.0965389080000032\n",
      "Gradient Descent(1/99): loss=9044196252.375938, w0=1067369.715524102, w1=-604250.9584981919\n",
      "Gradient Descent(2/99): loss=2.96613578261203e+21, w0=676556181059.0527, w1=-343691735948.4086\n",
      "Gradient Descent(3/99): loss=9.74751522294366e+32, w0=3.8974846366841414e+17, w1=-1.969887387915228e+17\n",
      "Gradient Descent(4/99): loss=3.2033231238617575e+44, w0=2.2349952291066886e+23, w1=-1.1292573538441004e+23\n",
      "Gradient Descent(5/99): loss=1.05270722272537e+56, w0=1.281269972346089e+29, w1=-6.47360668911357e+28\n",
      "Gradient Descent(6/99): loss=3.459508936306597e+67, w0=7.345053266512663e+34, w1=-3.711075037454182e+34\n",
      "Gradient Descent(7/99): loss=1.1368974983795755e+79, w0=4.210643285763422e+40, w1=-2.1274196330067505e+40\n",
      "Gradient Descent(8/99): loss=3.736183214493115e+90, w0=2.413803341208911e+46, w1=-1.219569598973335e+46\n",
      "Gradient Descent(9/99): loss=1.227820892574402e+102, w0=1.3837426010619725e+52, w1=-6.991333461753131e+51\n",
      "Gradient Descent(10/99): loss=4.0349845221568575e+113, w0=7.932475488436632e+57, w1=-4.007868318018301e+57\n",
      "Gradient Descent(11/99): loss=1.3260158865604786e+125, w0=4.547389617127906e+63, w1=-2.297560049516885e+63\n",
      "Gradient Descent(12/99): loss=4.3576824688062587e+136, w0=2.6068473025768755e+69, w1=-1.317104695631843e+69\n",
      "Gradient Descent(13/99): loss=1.4320640266383228e+148, w0=1.49440743615881e+75, w1=-7.550465458433902e+74\n",
      "Gradient Descent(14/99): loss=4.706188188496759e+159, w0=8.566875332663571e+80, w1=-4.328397645841959e+80\n",
      "Gradient Descent(15/99): loss=1.5465933682824326e+171, w0=4.911067168806618e+86, w1=-2.4813074483511812e+86\n",
      "Gradient Descent(16/99): loss=5.082565658257768e+182, w0=2.8153299540348466e+92, w1=-1.4224401630838165e+92\n",
      "Gradient Descent(17/99): loss=1.6702821957131056e+194, w0=1.6139226928985122e+98, w1=-8.154314044792776e+97\n",
      "Gradient Descent(18/99): loss=5.48904392171194e+205, w0=9.25201131369954e+103, w1=-4.674561311384097e+103\n",
      "Gradient Descent(19/99): loss=1.8038630389411531e+217, w0=5.303829838038486e+109, w1=-2.679750048116357e+109\n",
      "Gradient Descent(20/99): loss=5.928030290278917e+228, w0=3.040486008616761e+115, w1=-1.5361998360982619e+115\n",
      "Gradient Descent(21/99): loss=1.948127012075812e+240, w0=1.7429961840580037e+121, w1=-8.806455430748704e+120\n",
      "Gradient Descent(22/99): loss=6.40212460014409e+251, w0=9.991941054920109e+126, w1=-5.0484094211816915e+126\n",
      "Gradient Descent(23/99): loss=2.1039284985888396e+263, w0=5.728003707532821e+132, w1=-2.894063097723442e+132\n",
      "Gradient Descent(24/99): loss=6.9141346094305604e+274, w0=3.283648921983393e+138, w1=-1.6590574406392403e+138\n",
      "Gradient Descent(25/99): loss=2.27219021128285e+286, w0=1.8823923295759813e+144, w1=-9.510751833661018e+143\n",
      "Gradient Descent(26/99): loss=7.467092626758684e+297, w0=1.0791046688103985e+150, w1=-5.452156039072126e+149\n",
      "Gradient Descent(27/99): loss=inf, w0=6.186100888493888e+155, w1=-3.125515836632652e+155\n",
      "Gradient Descent(28/99): loss=inf, w0=3.5462587929316784e+161, w1=-1.79174058391475e+161\n",
      "Gradient Descent(29/99): loss=inf, w0=2.032936683886979e+167, w1=-1.0271374351780431e+167\n",
      "Gradient Descent(30/99): loss=inf, w0=1.1654060806083543e+173, w1=-5.8881922986810664e+172\n",
      "Gradient Descent(31/99): loss=inf, w0=6.680834398256262e+178, w1=-3.375479011748564e+178\n",
      "Gradient Descent(32/99): loss=inf, w0=3.829870892180825e+184, w1=-1.9350350635299563e+184\n",
      "Gradient Descent(33/99): loss=inf, w0=2.195520825153539e+190, w1=-1.1092827667000675e+190\n",
      "Gradient Descent(34/99): loss=inf, w0=1.2586094490872293e+196, w1=-6.359100564580929e+195\n",
      "Gradient Descent(35/99): loss=inf, w0=7.21513422775608e+201, w1=-3.645432995479692e+201\n",
      "Gradient Descent(36/99): loss=inf, w0=4.13616487324891e+207, w1=-2.0897895212650753e+207\n",
      "Gradient Descent(37/99): loss=inf, w0=2.3711076355149877e+213, w1=-1.1979976723216656e+213\n",
      "Gradient Descent(38/99): loss=inf, w0=1.3592667583343726e+219, w1=-6.86766972598915e+218\n",
      "Gradient Descent(39/99): loss=inf, w0=7.792164693997653e+224, w1=-3.936976553039856e+224\n",
      "Gradient Descent(40/99): loss=inf, w0=4.466954719968789e+230, w1=-2.2569204690391983e+230\n",
      "Gradient Descent(41/99): loss=inf, w0=2.560737003623911e+236, w1=-1.2938075538283707e+236\n",
      "Gradient Descent(42/99): loss=inf, w0=1.4679741373726056e+242, w1=-7.416911713579188e+241\n",
      "Gradient Descent(43/99): loss=inf, w0=8.415343180284499e+247, w1=-4.251836310914347e+247\n",
      "Gradient Descent(44/99): loss=inf, w0=4.824199489557173e+253, w1=-2.43741771682568e+253\n",
      "Gradient Descent(45/99): loss=inf, w0=2.765531983243118e+259, w1=-1.3972798320211267e+259\n",
      "Gradient Descent(46/99): loss=inf, w0=1.5853753906521315e+265, w1=-8.010079337224256e+264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:6: RuntimeWarning: overflow encountered in square\n",
      "  return 1/2*np.mean(e**2)\n",
      "/home/julien/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(47/99): loss=inf, w0=9.08836037519975e+270, w1=-4.591876982566845e+270\n",
      "Gradient Descent(48/99): loss=inf, w0=5.210014914860252e+276, w1=-2.6323502346649437e+276\n",
      "Gradient Descent(49/99): loss=inf, w0=2.986705444376741e+282, w1=-1.5090273071878761e+282\n",
      "Gradient Descent(50/99): loss=inf, w0=1.7121658108936018e+288, w1=-8.650685550315859e+287\n",
      "Gradient Descent(51/99): loss=inf, w0=9.815202130201088e+293, w1=-4.95911241194818e+293\n",
      "Gradient Descent(52/99): loss=inf, w0=5.626685934490384e+299, w1=-2.8428724834924974e+299\n",
      "Gradient Descent(53/99): loss=inf, w0=inf, w1=-inf\n",
      "Gradient Descent(54/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(55/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(56/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(57/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(58/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(59/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(60/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(61/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(62/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(63/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(64/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(65/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(66/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(67/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(68/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(69/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(70/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(71/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(72/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(73/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(74/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(75/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(76/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(77/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(78/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(79/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(80/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(81/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(82/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(83/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(84/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(85/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(86/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(87/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(88/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(89/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(90/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(91/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(92/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(93/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(94/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(95/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(96/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(97/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(98/99): loss=nan, w0=nan, w1=nan\n",
      "Gradient Descent(99/99): loss=nan, w0=nan, w1=nan\n"
     ]
    }
   ],
   "source": [
    "losses_GD, ws_GD = least_squares_GD(y_tr, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_GD = ws_GD[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([ 2.94272687e-02,  1.09653891e-02,  2.75102620e-02,  2.56041405e-02,\n",
       "        -2.11858017e-01, -1.45857418e-01, -2.12510540e-01,  8.16895690e-04,\n",
       "         6.30458877e-03,  6.25701617e-02,  4.13644105e-04,  1.11273860e-04,\n",
       "        -2.12175279e-01,  1.57377058e-02, -4.59088000e-06, -6.39518500e-06,\n",
       "         1.56228530e-02, -6.00935500e-06,  1.88166500e-05,  1.45894218e-02,\n",
       "         1.94715000e-06,  7.98476189e-02,  3.96995000e-04, -7.93485458e-02,\n",
       "        -1.01669647e-01, -1.01670661e-01, -2.04880286e-01, -2.12253652e-01,\n",
       "        -2.12255425e-01,  3.12096044e-02]),\n",
       " array([ 1.06796415e+02, -6.04029458e+01, -9.23697636e+01, -3.84355884e+01,\n",
       "         1.12706000e+03,  1.13516483e+03,  1.12697427e+03, -2.85423127e+00,\n",
       "        -1.67887619e+01, -1.18068634e+02, -1.58943812e+00,  5.15068626e-01,\n",
       "         1.12702983e+03, -4.02580278e+01,  1.82093523e-02,  1.43004140e-02,\n",
       "        -4.96417773e+01,  3.41930168e-02, -4.70343472e-02, -3.90102937e+01,\n",
       "         2.03012981e-02, -1.75483088e+02, -4.36533857e-01,  6.53003364e+02,\n",
       "         6.81478439e+02,  6.81481814e+02,  1.12735278e+03,  1.12702439e+03,\n",
       "         1.12702449e+03, -2.81688279e+01]),\n",
       " array([-6.76232678e+05,  3.43508681e+05,  5.17925945e+05,  2.00012527e+05,\n",
       "        -6.43149859e+06, -6.53213579e+06, -6.43054004e+06,  1.61017044e+04,\n",
       "         9.22409552e+04,  6.31794927e+05,  8.91199147e+03, -3.14485566e+03,\n",
       "        -6.43108970e+06,  2.23701736e+05, -1.04869213e+02, -8.21867526e+01,\n",
       "         2.76761311e+05, -2.00660375e+02,  2.64583334e+02,  2.15862136e+05,\n",
       "        -1.19164876e+02,  9.52838273e+05,  2.15998581e+03, -3.83701867e+06,\n",
       "        -3.97938401e+06, -3.97940218e+06, -6.43972216e+06, -6.43100383e+06,\n",
       "        -6.43100464e+06,  1.31331875e+05]),\n",
       " array([ 3.89475200e+09, -1.96849924e+09, -2.96589591e+09, -1.14085444e+09,\n",
       "         3.68507585e+10,  3.74360471e+10,  3.68451947e+10, -9.22348015e+07,\n",
       "        -5.27785692e+08, -3.61009445e+09, -5.10336277e+07,  1.80937546e+07,\n",
       "         3.68483773e+10, -1.28051162e+09,  6.01714571e+05,  4.71308299e+05,\n",
       "        -1.58444959e+09,  1.15269482e+06, -1.51528420e+06, -1.23539849e+09,\n",
       "         6.83923762e+05, -5.44826468e+09, -1.22858086e+07,  2.20383142e+10,\n",
       "         2.28483291e+10,  2.28484328e+10,  3.68990444e+10,  3.68478760e+10,\n",
       "         3.68478807e+10, -7.45133219e+08]),\n",
       " array([-2.23302769e+13,  1.12826291e+13,  1.69985120e+13,  6.53686736e+12,\n",
       "        -2.11208618e+14, -2.14564809e+14, -2.11176717e+14,  5.28638677e+11,\n",
       "         3.02477498e+12,  2.06878235e+13,  2.92489636e+11, -1.03736088e+11,\n",
       "        -2.11194962e+14,  7.33884936e+12, -3.44917124e+09, -2.70151095e+09,\n",
       "         9.08084092e+12, -6.60811181e+09,  8.68461698e+09,  7.08020172e+12,\n",
       "        -3.92035815e+09,  3.12228611e+13,  7.03819525e+10, -1.26337703e+14,\n",
       "        -1.30978090e+14, -1.30978684e+14, -2.11485635e+14, -2.11192087e+14,\n",
       "        -2.11192114e+14,  4.26813304e+12]),\n",
       " array([ 1.27991616e+17, -6.46676640e+16, -9.74285478e+16, -3.74658768e+16,\n",
       "         1.21056342e+18,  1.22980019e+18,  1.21038058e+18, -3.02994663e+15,\n",
       "        -1.73367224e+16, -1.18572960e+17, -1.67643110e+15,  5.94589135e+14,\n",
       "         1.21048515e+18, -4.20632188e+16,  1.97695103e+13,  1.54840991e+13,\n",
       "        -5.20476136e+16,  3.78757930e+13, -4.97766960e+13, -4.05807129e+16,\n",
       "         2.24701476e+13, -1.78955453e+17, -4.03386269e+14,  7.24130010e+17,\n",
       "         7.50725877e+17,  7.50729280e+17,  1.21215127e+18,  1.21046868e+18,\n",
       "         1.21046883e+18, -2.44621262e+16]),\n",
       " array([-7.33599947e+20,  3.70650062e+20,  5.58422625e+20,  2.14739490e+20,\n",
       "        -6.93848043e+21, -7.04873828e+21, -6.93743242e+21,  1.73664806e+19,\n",
       "         9.93673386e+19,  6.79613611e+20,  9.60865224e+18, -3.40796194e+18,\n",
       "        -6.93803181e+21,  2.41090010e+20, -1.13311291e+17, -8.87489143e+16,\n",
       "         2.98316690e+20, -2.17089730e+17,  2.85300706e+17,  2.32592840e+20,\n",
       "        -1.28790285e+17,  1.02570260e+21,  2.31204665e+18, -4.15043888e+21,\n",
       "        -4.30287561e+21, -4.30289511e+21, -6.94758137e+21, -6.93793736e+21,\n",
       "        -6.93793825e+21,  1.40206906e+20]),\n",
       " array([ 4.20471214e+24, -2.12442293e+24, -3.20066263e+24, -1.23080357e+24,\n",
       "         3.97686881e+25,  4.04006435e+25,  3.97626813e+25, -9.95379550e+22,\n",
       "        -5.69535163e+23, -3.89528224e+24, -5.50730804e+22,  1.95331243e+22,\n",
       "         3.97661168e+25, -1.38183473e+24,  6.49456581e+20,  5.08674505e+20,\n",
       "        -1.70983594e+24,  1.24427461e+21, -1.63523337e+21, -1.33313222e+24,\n",
       "         7.38176187e+20, -5.87893056e+24, -1.32517543e+22,  2.37887146e+25,\n",
       "         2.46624228e+25,  2.46625346e+25,  3.98208512e+25,  3.97655755e+25,\n",
       "         3.97655806e+25, -8.03611545e+23]),\n",
       " array([-2.40997856e+28,  1.21763714e+28,  1.83449614e+28,  7.05449037e+27,\n",
       "        -2.27938753e+29, -2.31560878e+29, -2.27904325e+29,  5.70513095e+26,\n",
       "         3.26435547e+27,  2.23262524e+28,  3.15657616e+26, -1.11956322e+26,\n",
       "        -2.27924015e+29,  7.92014267e+27, -3.72243419e+24, -2.91552572e+24,\n",
       "         9.80011888e+27, -7.13170133e+24,  9.37252579e+24,  7.64099874e+27,\n",
       "        -4.23094069e+24,  3.36957581e+28,  7.59539335e+25, -1.36347721e+29,\n",
       "        -1.41355479e+29, -1.41356120e+29, -2.28237732e+29, -2.27920913e+29,\n",
       "        -2.27920942e+29,  4.60599073e+27]),\n",
       " array([ 1.38130659e+32, -6.97902557e+31, -1.05146230e+32, -4.04336129e+31,\n",
       "         1.30645686e+33,  1.32721747e+33,  1.30625953e+33, -3.26996062e+30,\n",
       "        -1.87100242e+31, -1.27965452e+32, -1.80922748e+30,  6.41690380e+29,\n",
       "         1.30637239e+33, -4.53951974e+31,  2.13355545e+28,  1.67106669e+28,\n",
       "        -5.61704946e+31,  4.08761563e+28, -5.37196963e+28, -4.37952522e+31,\n",
       "         2.42501172e+28, -1.93131065e+32, -4.35338597e+29,  7.81492455e+32,\n",
       "         8.10194987e+32,  8.10198659e+32,  1.30817049e+33,  1.30635460e+33,\n",
       "         1.30635477e+33, -2.63997590e+31]),\n",
       " array([-7.91711564e+35,  4.00010779e+35,  6.02657563e+35,  2.31749845e+35,\n",
       "        -7.48810589e+36, -7.60709772e+36, -7.48697486e+36,  1.87421507e+34,\n",
       "         1.07238629e+35,  7.33448525e+35,  1.03697928e+34, -3.67792131e+33,\n",
       "        -7.48762173e+36,  2.60187731e+35, -1.22287154e+32, -9.57790854e+31,\n",
       "         3.21947571e+35, -2.34286333e+32,  3.07900542e+32,  2.51017463e+35,\n",
       "        -1.38992302e+32,  1.10695264e+36,  2.49519262e+33, -4.47921278e+36,\n",
       "        -4.64372460e+36, -4.64374565e+36, -7.49792775e+36, -7.48751980e+36,\n",
       "        -7.48752076e+36,  1.51313218e+35]),\n",
       " array([ 4.53778477e+39, -2.29270722e+39, -3.45420029e+39, -1.32830056e+39,\n",
       "         4.29189295e+40,  4.36009447e+40,  4.29124469e+40, -1.07422766e+38,\n",
       "        -6.14650384e+38, -4.20384354e+39, -5.94356456e+37,  2.10804238e+37,\n",
       "         4.29161545e+40, -1.49129554e+39,  7.00902715e+35,  5.48968708e+35,\n",
       "        -1.84527907e+39,  1.34283873e+36, -1.76476693e+36, -1.43873511e+39,\n",
       "         7.96650165e+35, -6.34462480e+39, -1.43014800e+37,  2.56731169e+40,\n",
       "         2.66160351e+40,  2.66161557e+40,  4.29752246e+40,  4.29155703e+40,\n",
       "         4.29155758e+40, -8.67268896e+38]),\n",
       " array([-2.60088289e+43,  1.31409119e+43,  1.97981413e+43,  7.61330557e+42,\n",
       "        -2.45994720e+44, -2.49903768e+44, -2.45957564e+44,  6.15705786e+41,\n",
       "         3.52293850e+42,  2.40948068e+43,  3.40662154e+41, -1.20824844e+41,\n",
       "        -2.45978815e+44,  8.54752977e+42, -4.01730353e+39, -3.14647651e+39,\n",
       "         1.05764266e+43, -7.69663275e+39,  1.01149621e+40,  8.24627369e+42,\n",
       "        -4.56609092e+39,  3.63649378e+43,  8.19705570e+40, -1.47148386e+44,\n",
       "        -1.52552829e+44, -1.52553520e+44, -2.46317382e+44, -2.45975466e+44,\n",
       "        -2.45975498e+44,  4.97085020e+42]),\n",
       " array([ 1.49072557e+47, -7.53186291e+46, -1.13475296e+47, -4.36365257e+46,\n",
       "         1.40994668e+48,  1.43235183e+48,  1.40973372e+48, -3.52898765e+45,\n",
       "        -2.01921222e+46, -1.38102122e+47, -1.95254384e+45,  6.92521317e+44,\n",
       "         1.40985552e+48, -4.89911379e+46,  2.30256315e+43,  1.80343876e+43,\n",
       "        -6.06199907e+46,  4.41141249e+43, -5.79750545e+43, -4.72644544e+46,\n",
       "         2.61710688e+43, -2.08429772e+47, -4.69823559e+44,  8.43397689e+47,\n",
       "         8.74373866e+47,  8.74377830e+47,  1.41179606e+48,  1.40983633e+48,\n",
       "         1.40983651e+48, -2.84909926e+46]),\n",
       " array([-8.54426296e+50,  4.31697279e+50,  6.50396550e+50,  2.50107704e+50,\n",
       "        -8.08126957e+51, -8.20968724e+51, -8.08004896e+51,  2.02267936e+49,\n",
       "         1.15733442e+50,  7.91548001e+50,  1.11912268e+49, -3.96926460e+48,\n",
       "        -8.08074707e+51,  2.80798272e+50, -1.31974023e+47, -1.03366141e+47,\n",
       "         3.47450363e+50, -2.52845118e+47,  3.32290611e+47,  2.70901590e+50,\n",
       "        -1.50002454e+47,  1.19463891e+51,  2.69284710e+48, -4.83402966e+51,\n",
       "        -5.01157314e+51, -5.01159586e+51, -8.09186947e+51, -8.08063707e+51,\n",
       "        -8.08063810e+51,  1.63299360e+50]),\n",
       " array([ 4.89724138e+54, -2.47432199e+54, -3.72782171e+54, -1.43352072e+54,\n",
       "         4.63187146e+55,  4.70547550e+55,  4.63117185e+55, -1.15932165e+53,\n",
       "        -6.63339371e+53, -4.53684729e+54, -6.41437877e+52,  2.27502909e+52,\n",
       "         4.63157198e+55, -1.60942719e+54,  7.56424104e+50,  5.92454779e+50,\n",
       "        -1.99145122e+54,  1.44921052e+51, -1.90456138e+51, -1.55270324e+54,\n",
       "         8.59756104e+50, -6.84720864e+54, -1.54343590e+52,  2.77067901e+55,\n",
       "         2.87244008e+55,  2.87245310e+55,  4.63794691e+55,  4.63150893e+55,\n",
       "         4.63150952e+55, -9.35968835e+53]),\n",
       " array([-2.80690953e+58,  1.41818576e+58,  2.13664336e+58,  8.21638684e+57,\n",
       "        -2.65480974e+59, -2.69699674e+59, -2.65440875e+59,  6.64478375e+56,\n",
       "         3.80200496e+57,  2.60034556e+58,  3.67647406e+56, -1.30395877e+56,\n",
       "        -2.65463809e+59,  9.22461479e+57, -4.33553068e+54, -3.39572187e+54,\n",
       "         1.14142289e+58, -8.30631471e+54,  1.09162099e+55,  8.89949498e+57,\n",
       "        -4.92778978e+54,  3.92455542e+58,  8.84637822e+55, -1.58804615e+59,\n",
       "        -1.64637166e+59, -1.64637912e+59, -2.65829196e+59, -2.65460195e+59,\n",
       "        -2.65460229e+59,  5.36461170e+57]),\n",
       " array([ 1.60881208e+62, -8.12849277e+61, -1.22464141e+62, -4.70931546e+61,\n",
       "         1.52163436e+63,  1.54581432e+63,  1.52140453e+63, -3.80853329e+60,\n",
       "        -2.17916233e+61, -1.49041760e+62, -2.10721287e+60,  7.47378781e+59,\n",
       "         1.52153598e+63, -5.28719275e+61,  2.48495866e+58,  1.94629656e+58,\n",
       "        -6.54219497e+61,  4.76085863e+58, -6.25674972e+58, -5.10084664e+61,\n",
       "         2.82441869e+58, -2.24940352e+62, -5.07040217e+59,  9.10206691e+62,\n",
       "         9.43636619e+62,  9.43640896e+62,  1.52363023e+63,  1.52151527e+63,\n",
       "         1.52151546e+63, -3.07478814e+61]),\n",
       " array([-9.22108920e+65,  4.65893797e+65,  7.01917137e+65,  2.69919765e+65,\n",
       "        -8.72142020e+66, -8.86001036e+66, -8.72010289e+66,  2.18290412e+64,\n",
       "         1.24901165e+65,  8.54249776e+65,  1.20777299e+64, -4.28368638e+63,\n",
       "        -8.72085630e+66,  3.03041459e+65, -1.42428228e+62, -1.11554198e+62,\n",
       "         3.74973336e+65, -2.72874021e+62,  3.58612718e+62,  2.92360820e+65,\n",
       "        -1.61884766e+62,  1.28927118e+66,  2.90615860e+63, -5.21695305e+66,\n",
       "        -5.40856048e+66, -5.40858499e+66, -8.73285975e+66, -8.72073759e+66,\n",
       "        -8.72073870e+66,  1.76234975e+65]),\n",
       " array([ 5.28517202e+69, -2.67032322e+69, -4.02311781e+69, -1.54707580e+69,\n",
       "         4.99878106e+70,  5.07821559e+70,  4.99802603e+70, -1.25115629e+68,\n",
       "        -7.15885213e+68, -4.89622963e+69, -6.92248812e+67,  2.45524351e+67,\n",
       "         4.99845786e+70, -1.73691655e+69,  8.16343571e+65,  6.39385561e+65,\n",
       "        -2.14920227e+69,  1.56400845e+66, -2.05542953e+66, -1.67569925e+69,\n",
       "         9.27860924e+65, -7.38960422e+69, -1.66569782e+67,  2.99015590e+70,\n",
       "         3.09997788e+70,  3.09999193e+70,  5.00533777e+70,  4.99838981e+70,\n",
       "         4.99839045e+70, -1.01011078e+69]),\n",
       " array([-3.02925638e+73,  1.53052609e+73,  2.30589567e+73,  8.86724067e+72,\n",
       "        -2.86510815e+74, -2.91063695e+74, -2.86467540e+74,  7.17114443e+71,\n",
       "         4.10317742e+72,  2.80632963e+73,  3.96770270e+71, -1.40725071e+71,\n",
       "        -2.86492290e+74,  9.95533449e+72, -4.67896591e+69, -3.66471097e+69,\n",
       "         1.23183970e+73, -8.96429209e+69,  1.17809278e+70,  9.60446060e+72,\n",
       "        -5.31814029e+69,  4.23543560e+73,  9.54713625e+70, -1.71384182e+74,\n",
       "        -1.77678754e+74, -1.77679559e+74, -2.86886620e+74, -2.86488390e+74,\n",
       "        -2.86488427e+74,  5.78956467e+72]),\n",
       " array([ 1.73625271e+77, -8.77238414e+76, -1.32165030e+77, -5.08235972e+76,\n",
       "         1.64216928e+78,  1.66826463e+78,  1.64192125e+78, -4.11022289e+75,\n",
       "        -2.35178275e+76, -1.60847971e+77, -2.27413388e+75,  8.06581730e+74,\n",
       "         1.64206311e+78, -5.70601306e+76,  2.68180246e+73,  2.10047072e+73,\n",
       "        -7.06042916e+76,  5.13798584e+73, -6.75237262e+73, -5.50490570e+76,\n",
       "         3.04815252e+73, -2.42758803e+77, -5.47204959e+74,  9.82307910e+77,\n",
       "         1.01838596e+78,  1.01839058e+78,  1.64432325e+78,  1.64204075e+78,\n",
       "         1.64204096e+78, -3.31835476e+76]),\n",
       " array([-9.95152963e+80,  5.02799162e+80,  7.57518883e+80,  2.91301221e+80,\n",
       "        -9.41227979e+81, -9.56184825e+81, -9.41085814e+81,  2.35582094e+79,\n",
       "         1.34795100e+80,  9.21918417e+80,  1.30344566e+79, -4.62301481e+78,\n",
       "        -9.41167123e+81,  3.27046620e+80, -1.53710555e+77, -1.20390866e+77,\n",
       "         4.04676518e+80, -2.94489495e+77,  3.87019907e+77,  3.15519924e+80,\n",
       "        -1.74708324e+77,  1.39139966e+81,  3.13636739e+78, -5.63020937e+81,\n",
       "        -5.83699481e+81, -5.83702127e+81, -9.42462552e+81, -9.41154311e+81,\n",
       "        -9.41154431e+81,  1.90195273e+80]),\n",
       " array([ 5.70383225e+84, -2.88185052e+84, -4.34180553e+84, -1.66962604e+84,\n",
       "         5.39475508e+85,  5.48048194e+85,  5.39394025e+85, -1.35026553e+83,\n",
       "        -7.72593427e+83, -5.28408014e+84, -7.47084689e+82,  2.64973346e+82,\n",
       "         5.39440628e+85, -1.87450485e+84,  8.81009505e+80,  6.90033923e+80,\n",
       "        -2.31944943e+84,  1.68789999e+81, -2.21824856e+81, -1.80843828e+84,\n",
       "         1.00136061e+81, -7.97496519e+84, -1.79764460e+82,  3.22701846e+85,\n",
       "         3.34553988e+85,  3.34555505e+85,  5.40183118e+85,  5.39433284e+85,\n",
       "         5.39433353e+85, -1.09012581e+84]),\n",
       " array([-3.26921625e+88,  1.65176536e+88,  2.48855516e+88,  9.56965130e+87,\n",
       "        -3.09206516e+89, -3.14120048e+89, -3.09159813e+89,  7.73920029e+86,\n",
       "         4.42820699e+87,  3.02863056e+88,  4.28200076e+86, -1.51872483e+86,\n",
       "        -3.09186524e+89,  1.07439375e+88, -5.04960606e+84, -3.95500781e+84,\n",
       "         1.32941879e+88, -9.67439056e+84,  1.27141436e+85,  1.03652695e+88,\n",
       "        -5.73941207e+84,  4.57094189e+88,  1.03034042e+86, -1.84960229e+89,\n",
       "        -1.91753419e+89, -1.91754288e+89, -3.09612090e+89, -3.09182315e+89,\n",
       "        -3.09182354e+89,  6.24817992e+87]),\n",
       " array([ 1.87378843e+92, -9.46728080e+91, -1.42634366e+92, -5.48495435e+91,\n",
       "         1.77225227e+93,  1.80041474e+93,  1.77198459e+93, -4.43581056e+90,\n",
       "        -2.53807714e+91, -1.73589401e+92, -2.45427738e+90,  8.70474389e+89,\n",
       "         1.77213768e+93, -6.15800984e+91,  2.89423907e+88,  2.26685766e+88,\n",
       "        -7.61971481e+91,  5.54498685e+88, -7.28725585e+88, -5.94097194e+91,\n",
       "         3.28960923e+88, -2.61988727e+92, -5.90551317e+89,  1.06012056e+93,\n",
       "         1.09905650e+93,  1.09906149e+93,  1.77457687e+93,  1.77211356e+93,\n",
       "         1.77211379e+93, -3.58121530e+91]),\n",
       " array([-1.07398312e+96,  5.42627954e+95,  8.17525071e+95,  3.14376389e+95,\n",
       "        -1.01578652e+97, -1.03192816e+97, -1.01563309e+97,  2.54243521e+94,\n",
       "         1.45472775e+95,  9.94947370e+95,  1.40669696e+94, -4.98922284e+93,\n",
       "        -1.01572084e+97,  3.52953329e+95, -1.65886600e+92, -1.29927522e+92,\n",
       "         4.36732610e+95, -3.17817220e+92,  4.17677347e+92,  3.40513555e+95,\n",
       "        -1.88547690e+92,  1.50161815e+96,  3.38481196e+93, -6.07620143e+96,\n",
       "        -6.29936720e+96, -6.29939575e+96, -1.01711889e+97, -1.01570702e+97,\n",
       "        -1.01570715e+97,  2.05261423e+95]),\n",
       " array([ 6.15565628e+099, -3.11013376e+099, -4.68573782e+099,\n",
       "        -1.80188399e+099,  5.82209584e+100,  5.91461348e+100,\n",
       "         5.82121645e+100, -1.45722562e+098, -8.33793733e+098,\n",
       "        -5.70265387e+099, -8.06264343e+097,  2.85962975e+097,\n",
       "         5.82171940e+100, -2.02299210e+099,  9.50797894e+095,\n",
       "         7.44694350e+095, -2.50318257e+099,  1.82160550e+096,\n",
       "        -2.39396516e+096, -1.95169212e+099,  1.08068250e+096,\n",
       "        -8.60669501e+099, -1.94004342e+097,  3.48264387e+100,\n",
       "         3.61055387e+100,  3.61057023e+100,  5.82973246e+100,\n",
       "         5.82164015e+100,  5.82164090e+100, -1.17647916e+099]),\n",
       " array([-3.52818432e+103,  1.78260849e+103,  2.68568386e+103,\n",
       "         1.03277028e+103, -3.33700037e+104, -3.39002790e+104,\n",
       "        -3.33649634e+104,  8.35225420e+101,  4.77898350e+102,\n",
       "         3.26854085e+103,  4.62119567e+101, -1.63902928e+101,\n",
       "        -3.33678461e+104,  1.15950090e+103, -5.44960614e+099,\n",
       "        -4.26830026e+099,  1.43472752e+103, -1.04407389e+100,\n",
       "         1.37212833e+100,  1.11863451e+103, -6.19405452e+099,\n",
       "         4.93302501e+103,  1.11195793e+101, -1.99611690e+104,\n",
       "        -2.06942997e+104, -2.06943935e+104, -3.34137738e+104,\n",
       "        -3.33673919e+104, -3.33673961e+104,  6.74312397e+102]),\n",
       " array([ 2.02221893e+107, -1.02172231e+107, -1.53933021e+107,\n",
       "        -5.91944016e+106,  1.91263967e+108,  1.94303300e+108,\n",
       "         1.91235078e+108, -4.78718937e+105, -2.73912868e+106,\n",
       "        -1.87340132e+107, -2.64869079e+105,  9.39428248e+104,\n",
       "         1.91251600e+108, -6.64581114e+106,  3.12350366e+103,\n",
       "         2.44642478e+103, -8.22330378e+106,  5.98422808e+103,\n",
       "        -7.86450938e+103, -6.41158078e+106,  3.55019271e+103,\n",
       "        -2.82741932e+107, -6.37331317e+104,  1.14409708e+108,\n",
       "         1.18611729e+108,  1.18612267e+108,  1.91514840e+108,\n",
       "         1.91248997e+108,  1.91249021e+108, -3.86489810e+106]),\n",
       " array([-1.15905775e+111,  5.85611747e+110,  8.82284597e+110,\n",
       "         3.39279437e+110, -1.09625115e+112, -1.11367144e+112,\n",
       "        -1.09608557e+112,  2.74383197e+109,  1.56996272e+110,\n",
       "         1.07376125e+111,  1.51812722e+109, -5.38443972e+108,\n",
       "        -1.09618027e+112,  3.80912215e+110, -1.79027161e+107,\n",
       "        -1.40219615e+107,  4.71327998e+110, -3.42992830e+107,\n",
       "         4.50763289e+107,  3.67487036e+110, -2.03483328e+107,\n",
       "         1.62056750e+111,  3.65293684e+108, -6.55752236e+111,\n",
       "        -6.79836600e+111, -6.79839682e+111, -1.09768906e+112,\n",
       "        -1.09616535e+112, -1.09616549e+112,  2.21521025e+110]),\n",
       " array([ 6.64327115e+114, -3.35650025e+114, -5.05691439e+114,\n",
       "        -1.94461863e+114,  6.28328801e+115,  6.38313435e+115,\n",
       "         6.28233897e+115, -1.57265846e+113, -8.99841966e+113,\n",
       "        -6.15438456e+114, -8.70131860e+112,  3.08615279e+112,\n",
       "         6.28288176e+115, -2.18324163e+114,  1.02611451e+111,\n",
       "         8.03684654e+110, -2.70146996e+114,  1.96590237e+111,\n",
       "        -2.58360100e+111, -2.10629369e+114,  1.16628781e+111,\n",
       "        -9.28846674e+114, -2.09372225e+112,  3.75851843e+115,\n",
       "         3.89656070e+115,  3.89657836e+115,  6.29152956e+115,\n",
       "         6.28279623e+115,  6.28279703e+115, -1.26967292e+114]),\n",
       " array([-3.80766633e+118,  1.92381625e+118,  2.89842793e+118,\n",
       "         1.11458026e+118, -3.60133790e+119, -3.65856597e+119,\n",
       "        -3.60079395e+119,  9.01387063e+116,  5.15754645e+117,\n",
       "         3.52745542e+118,  4.98725960e+116, -1.76886353e+116,\n",
       "        -3.60110505e+119,  1.25134974e+118, -5.88129187e+114,\n",
       "        -4.60640989e+114,  1.54837820e+118, -1.12677928e+115,\n",
       "         1.48082026e+115,  1.20724616e+118, -6.68471108e+114,\n",
       "         5.32379023e+118,  1.20004069e+116, -2.15423753e+119,\n",
       "        -2.23335803e+119, -2.23336815e+119, -3.60606164e+119,\n",
       "        -3.60105603e+119, -3.60105649e+119,  7.27727458e+117]),\n",
       " array([ 2.18240721e+122, -1.10265714e+122, -1.66126689e+122,\n",
       "        -6.38834338e+121,  2.06414773e+123,  2.09694864e+123,\n",
       "         2.06383595e+123, -5.16640235e+120, -2.95610634e+121,\n",
       "        -2.02180115e+122, -2.85850449e+120,  1.01384423e+120,\n",
       "         2.06401427e+123, -7.17225319e+121,  3.37092925e+118,\n",
       "         2.64021616e+118, -8.87470552e+121,  6.45826342e+118,\n",
       "        -8.48748953e+118, -6.91946848e+121,  3.83141809e+118,\n",
       "        -3.05139085e+122, -6.87816954e+119,  1.23472571e+123,\n",
       "         1.28007453e+123,  1.28008033e+123,  2.06685519e+123,\n",
       "         2.06398617e+123,  2.06398643e+123, -4.17105259e+121]),\n",
       " array([-1.25087148e+126,  6.32000464e+125,  9.52173992e+125,\n",
       "         3.66155158e+125, -1.18308972e+127, -1.20188994e+127,\n",
       "        -1.18291102e+127,  2.96118220e+124,  1.69432593e+125,\n",
       "         1.15881829e+126,  1.63838432e+124, -5.81096335e+123,\n",
       "        -1.18301322e+127,  4.11085839e+125, -1.93208639e+122,\n",
       "        -1.51326988e+122,  5.08663829e+125, -3.70162704e+122,\n",
       "         4.86470104e+122,  3.96597196e+125, -2.19602080e+122,\n",
       "         1.74893933e+126,  3.94230101e+123, -7.07697069e+126,\n",
       "        -7.33689256e+126, -7.33692581e+126, -1.18464153e+127,\n",
       "        -1.18299712e+127, -1.18299727e+127,  2.39068617e+125]),\n",
       " array([ 7.16951200e+129, -3.62238245e+129, -5.45749340e+129,\n",
       "        -2.09865988e+129,  6.78101312e+130,  6.88876870e+130,\n",
       "         6.77998890e+130, -1.69723521e+128, -9.71122152e+128,\n",
       "        -6.64189869e+129, -9.39058586e+127,  3.33061966e+127,\n",
       "         6.78057468e+130, -2.35618519e+129,  1.10739726e+126,\n",
       "         8.67347824e+125, -2.91546452e+129,  2.12162959e+126,\n",
       "        -2.78825866e+126, -2.27314188e+129,  1.25867427e+126,\n",
       "        -1.00242444e+130, -2.25957460e+127,  4.05624614e+130,\n",
       "         4.20522331e+130,  4.20524237e+130,  6.78990751e+130,\n",
       "         6.78048238e+130,  6.78048325e+130, -1.37024894e+129]),\n",
       " array([-4.10928725e+133,  2.07620965e+133,  3.12802434e+133,\n",
       "         1.20287075e+133, -3.88661470e+134, -3.94837603e+134,\n",
       "        -3.88602765e+134,  9.72789643e+131,  5.56609693e+132,\n",
       "         3.80687969e+133,  5.38232096e+131, -1.90898249e+131,\n",
       "        -3.88636340e+134,  1.35047431e+133, -6.34717321e+129,\n",
       "        -4.97130258e+129,  1.67103161e+133, -1.21603610e+130,\n",
       "         1.59812213e+130,  1.30287709e+133, -7.21423455e+129,\n",
       "         5.74550957e+133,  1.29510085e+131, -2.32488356e+134,\n",
       "        -2.41027151e+134, -2.41028244e+134, -3.89171262e+134,\n",
       "        -3.88631050e+134, -3.88631100e+134,  7.85373745e+132]),\n",
       " array([ 2.35528467e+137, -1.19000315e+137, -1.79286268e+137,\n",
       "        -6.89439035e+136,  2.22765737e+138,  2.26305658e+138,\n",
       "         2.22732089e+138, -5.57565434e+135, -3.19027169e+136,\n",
       "        -2.18195634e+137, -3.08493840e+135,  1.09415500e+135,\n",
       "         2.22751333e+138, -7.74039689e+136,  3.63795443e+133,\n",
       "         2.84935855e+133, -9.57770748e+136,  6.96984904e+133,\n",
       "        -9.15981851e+133, -7.46758806e+136,  4.13492049e+133,\n",
       "        -3.29310407e+137, -7.42301766e+134,  1.33253342e+138,\n",
       "         1.38147450e+138,  1.38148076e+138,  2.23057930e+138,\n",
       "         2.22748301e+138,  2.22748330e+138, -4.50145884e+136]),\n",
       " array([-1.34995816e+141,  6.82063822e+140,  1.02759961e+141,\n",
       "         3.95159815e+140, -1.27680712e+142, -1.29709658e+142,\n",
       "        -1.27661427e+142,  3.19574963e+139,  1.82854046e+140,\n",
       "         1.25061306e+141,  1.76816749e+139, -6.27127368e+138,\n",
       "        -1.27672457e+142,  4.43649641e+140, -2.08513491e+137,\n",
       "        -1.63314222e+137,  5.48957184e+140, -3.99484815e+137,\n",
       "         5.25005403e+137,  4.28013293e+140, -2.36997665e+137,\n",
       "         1.88748001e+141,  4.25458689e+138, -7.63756667e+141,\n",
       "        -7.91807801e+141, -7.91811390e+141, -1.27848186e+142,\n",
       "        -1.27670719e+142, -1.27670735e+142,  2.58006227e+140]),\n",
       " array([ 7.73743856e+144, -3.90932628e+144, -5.88980391e+144,\n",
       "        -2.26490337e+144,  7.31816508e+145,  7.43445642e+145,\n",
       "         7.31705972e+145, -1.83168020e+143, -1.04804873e+144,\n",
       "        -7.16803082e+144, -1.01344528e+143,  3.59445175e+142,\n",
       "         7.31769191e+145, -2.54282831e+144,  1.19511876e+141,\n",
       "         9.36054015e+140, -3.14641046e+144,  2.28969260e+141,\n",
       "        -3.00912811e+141, -2.45320681e+144,  1.35837904e+141,\n",
       "        -1.08183061e+145, -2.43856481e+142,  4.37755810e+145,\n",
       "         4.53833636e+145,  4.53835693e+145,  7.32776404e+145,\n",
       "         7.31759230e+145,  7.31759323e+145, -1.47879200e+144]),\n",
       " array([-4.43480081e+148,  2.24067476e+148,  3.37580802e+148,\n",
       "         1.29815509e+148, -4.19448945e+149, -4.26114315e+149,\n",
       "        -4.19385590e+149,  1.04984831e+147,  6.00701038e+147,\n",
       "         4.10843829e+148,  5.80867676e+146, -2.06020085e+146,\n",
       "        -4.19421825e+149,  1.45745093e+148, -6.84995892e+144,\n",
       "        -5.36509992e+144,  1.80340090e+148, -1.31236332e+145,\n",
       "         1.72471596e+145,  1.40608335e+148, -7.78570377e+144,\n",
       "         6.20063503e+148,  1.39769112e+146, -2.50904715e+149,\n",
       "        -2.60119904e+149, -2.60121083e+149, -4.19999120e+149,\n",
       "        -4.19416115e+149, -4.19416169e+149,  8.47586432e+147]),\n",
       " array([ 2.54185646e+152, -1.28426819e+152, -1.93488271e+152,\n",
       "        -7.44052339e+151,  2.40411927e+153,  2.44232260e+153,\n",
       "         2.40375615e+153, -6.01732487e+150, -3.44298624e+151,\n",
       "        -2.35479808e+152, -3.32930907e+150,  1.18082752e+150,\n",
       "         2.40396383e+153, -8.35354559e+151,  3.92613177e+148,\n",
       "         3.07506797e+148, -1.03363971e+152,  7.52195947e+148,\n",
       "        -9.88540544e+148, -8.05912645e+151,  4.46246456e+148,\n",
       "        -3.55396440e+152, -8.01102544e+149,  1.43808888e+153,\n",
       "         1.49090678e+153,  1.49091354e+153,  2.40727267e+153,\n",
       "         2.40393111e+153,  2.40393142e+153, -4.85803792e+151]),\n",
       " array([-1.45689391e+156,  7.36092905e+155,  1.10900001e+156,\n",
       "         4.26462050e+155, -1.37794827e+157, -1.39984494e+157,\n",
       "        -1.37774014e+157,  3.44889811e+154,  1.97338667e+155,\n",
       "         1.34967927e+156,  1.90823131e+154, -6.76804708e+153,\n",
       "        -1.37785918e+157,  4.78792955e+155, -2.25030702e+152,\n",
       "        -1.76251014e+152,  5.92442342e+155, -4.31129652e+152,\n",
       "         5.66593242e+152,  4.61917987e+155, -2.55771225e+152,\n",
       "         2.03699507e+156,  4.59161023e+153, -8.24256976e+156,\n",
       "        -8.54530156e+156, -8.54534030e+156, -1.37975567e+157,\n",
       "        -1.37784042e+157, -1.37784060e+157,  2.78443962e+155]),\n",
       " array([ 8.35035292e+159, -4.21900010e+159, -6.35635952e+159,\n",
       "        -2.44431569e+159,  7.89786706e+160,  8.02337032e+160,\n",
       "         7.89667414e+160, -1.97677513e+158, -1.13106899e+159,\n",
       "        -7.73584005e+159, -1.09372445e+158,  3.87918307e+157,\n",
       "         7.89735641e+160, -2.74425621e+159,  1.28978903e+156,\n",
       "         1.01020271e+156, -3.39565058e+159,  2.47106858e+156,\n",
       "        -3.24749353e+156, -2.64753542e+159,  1.46598183e+156,\n",
       "        -1.16752686e+160, -2.63173357e+157,  4.72432249e+160,\n",
       "         4.89783666e+160,  4.89785886e+160,  7.90822639e+160,\n",
       "         7.89724890e+160,  7.89724991e+160, -1.59593320e+159]),\n",
       " array([-4.78609963e+163,  2.41816784e+163,  3.64321967e+163,\n",
       "         1.40098730e+163, -4.52675222e+164, -4.59868584e+164,\n",
       "        -4.52606849e+164,  1.13301112e+162,  6.48285040e+162,\n",
       "         4.43388460e+163,  6.26880595e+161, -2.22339784e+161,\n",
       "        -4.52645954e+164,  1.57290162e+163, -7.39257236e+159,\n",
       "        -5.79009157e+159,  1.94625571e+163, -1.41632102e+160,\n",
       "         1.86133781e+160,  1.51746500e+163, -8.40244141e+159,\n",
       "         6.69181285e+163,  1.50840799e+161, -2.70779910e+164,\n",
       "        -2.80725072e+164, -2.80726345e+164, -4.53268979e+164,\n",
       "        -4.52639792e+164, -4.52639850e+164,  9.14727242e+162]),\n",
       " array([ 2.74320737e+167, -1.38600036e+167, -2.08815274e+167,\n",
       "        -8.02991787e+166,  2.59455946e+168,  2.63578903e+168,\n",
       "         2.59416757e+168, -6.49398194e+165, -3.71571935e+166,\n",
       "        -2.54133133e+167, -3.59303734e+165,  1.27436573e+165,\n",
       "         2.59439170e+168, -9.01526432e+166,  4.23713683e+163,\n",
       "         3.31865676e+163, -1.11551857e+167,  8.11780484e+163,\n",
       "        -1.06684691e+164, -8.69752302e+166,  4.81595474e+163,\n",
       "        -3.83548855e+167, -8.64561174e+164,  1.55200582e+168,\n",
       "         1.60900764e+168,  1.60901493e+168,  2.59796264e+168,\n",
       "         2.59435639e+168,  2.59435672e+168, -5.24286310e+166]),\n",
       " array([-1.57230047e+171,  7.94401854e+170,  1.19684846e+171,\n",
       "         4.60243865e+170, -1.48710123e+172, -1.51073242e+172,\n",
       "        -1.48687661e+172,  3.72209952e+169,  2.12970675e+170,\n",
       "         1.45659292e+171,  2.05939017e+169, -7.30417194e+168,\n",
       "        -1.48700508e+172,  5.16720115e+170, -2.42856310e+167,\n",
       "        -1.90212582e+167,  6.39372138e+170, -4.65281206e+167,\n",
       "         6.11475425e+167,  4.98508412e+170, -2.76031917e+167,\n",
       "         2.19835383e+171,  4.95533058e+168, -8.89549764e+171,\n",
       "        -9.22221007e+171, -9.22225188e+171, -1.48905180e+172,\n",
       "        -1.48698483e+172, -1.48698502e+172,  3.00500654e+170]),\n",
       " array([ 9.01181874e+174, -4.55320447e+174, -6.85987292e+174,\n",
       "        -2.63793999e+174,  8.52348961e+175,  8.65893450e+175,\n",
       "         8.52220220e+175, -2.13336362e+173, -1.22066562e+174,\n",
       "        -8.34862778e+174, -1.18036287e+173,  4.18646912e+172,\n",
       "         8.52293851e+175, -2.96164004e+174,  1.39195853e+171,\n",
       "         1.09022502e+171, -3.66463404e+174,  2.66681209e+171,\n",
       "        -3.50474086e+171, -2.85725759e+174,  1.58210829e+171,\n",
       "        -1.26001147e+175, -2.84020401e+172,  5.09855552e+175,\n",
       "         5.28581447e+175,  5.28583842e+175,  8.53466955e+175,\n",
       "         8.52282249e+175,  8.52282358e+175, -1.72235364e+174]),\n",
       " array([-5.16522628e+178,  2.60972086e+178,  3.93181409e+178,\n",
       "         1.51196527e+178, -4.88533490e+179, -4.96296667e+179,\n",
       "        -4.88459700e+179,  1.22276159e+177,  6.99638366e+177,\n",
       "         4.78511085e+178,  6.76538387e+176, -2.39952234e+176,\n",
       "        -4.88501903e+179,  1.69749763e+178, -7.97816845e+174,\n",
       "        -6.24874855e+174,  2.10042663e+178, -1.52851364e+175,\n",
       "         2.00878204e+175,  1.63766965e+178, -9.06803338e+174,\n",
       "         7.22189889e+178,  1.62789519e+176, -2.92229502e+179,\n",
       "        -3.02962461e+179, -3.02963834e+179, -4.89174280e+179,\n",
       "        -4.88495253e+179, -4.88495315e+179,  9.87186552e+177]),\n",
       " array([ 2.96050812e+182, -1.49579116e+182, -2.25356391e+182,\n",
       "        -8.66600072e+181,  2.80008519e+183,  2.84458073e+183,\n",
       "         2.79966226e+183, -7.00839698e+180, -4.01005677e+181,\n",
       "        -2.74264064e+182, -3.87765662e+180,  1.37531348e+180,\n",
       "         2.79990415e+183, -9.72940051e+181,  4.57277787e+178,\n",
       "         3.58154122e+178, -1.20388338e+182,  8.76084958e+178,\n",
       "        -1.15135624e+179, -9.38648962e+181,  5.19744634e+178,\n",
       "        -4.13931339e+182, -9.33046623e+179,  1.67494658e+183,\n",
       "         1.73646376e+183,  1.73647163e+183,  2.80375796e+183,\n",
       "         2.79986603e+183,  2.79986639e+183, -5.65817186e+181]),\n",
       " array([-1.69684886e+186,  8.57329694e+185,  1.29165576e+186,\n",
       "         4.96701675e+185, -1.60490064e+187, -1.63040376e+187,\n",
       "        -1.60465823e+187,  4.01694234e+184,  2.29840959e+185,\n",
       "         1.57197564e+186,  2.22252294e+184, -7.88276547e+183,\n",
       "        -1.60479687e+187,  5.57651643e+185, -2.62093958e+182,\n",
       "        -2.05280103e+182,  6.90019437e+185, -5.02138046e+182,\n",
       "         6.59912910e+182,  5.37997315e+185, -2.97897541e+182,\n",
       "         2.37249449e+186,  5.34786271e+183, -9.60014662e+186,\n",
       "        -9.95273929e+186, -9.95278440e+186, -1.60700572e+187,\n",
       "        -1.60477502e+187, -1.60477523e+187,  3.24304548e+185]),\n",
       " array([ 9.72568200e+189, -4.91388253e+189, -7.40327169e+189,\n",
       "        -2.84690208e+189,  9.19867031e+190,  9.34484434e+190,\n",
       "         9.19728092e+190, -2.30235614e+188, -1.31735957e+189,\n",
       "        -9.00995695e+189, -1.27386427e+188,  4.51809657e+187,\n",
       "         9.19807555e+190, -3.19624374e+189,  1.50222130e+186,\n",
       "         1.17658623e+186, -3.95492479e+189,  2.87806125e+186,\n",
       "        -3.78236581e+186, -3.08359273e+189,  1.70743360e+186,\n",
       "        -1.35982217e+190, -3.06518826e+187,  5.50243309e+190,\n",
       "         5.70452559e+190,  5.70455144e+190,  9.21073585e+190,\n",
       "         9.19795034e+190,  9.19795152e+190, -1.85878836e+189]),\n",
       " array([-5.57438512e+193,  2.81644759e+193,  4.24326927e+193,\n",
       "         1.63173427e+193, -5.27232238e+194, -5.35610369e+194,\n",
       "        -5.27152604e+194,  1.31962157e+192,  7.55059601e+192,\n",
       "         5.16415918e+193,  7.30129777e+191, -2.58959838e+191,\n",
       "        -5.27198149e+194,  1.83196341e+193, -8.61015201e+189,\n",
       "        -6.74373764e+189,  2.26681007e+193, -1.64959350e+190,\n",
       "         2.16790593e+190,  1.76739620e+193, -9.78634962e+189,\n",
       "         7.79397522e+193,  1.75684747e+191, -3.15378203e+194,\n",
       "        -3.26961364e+194, -3.26962846e+194, -5.27923789e+194,\n",
       "        -5.27190972e+194, -5.27191040e+194,  1.06538566e+193]),\n",
       " array([ 3.19502215e+197, -1.61427893e+197, -2.43207798e+197,\n",
       "        -9.35247030e+196,  3.02189147e+198,  3.06991167e+198,\n",
       "         3.02143503e+198, -7.56356096e+195, -4.32770987e+196,\n",
       "        -2.95989650e+197, -4.18482176e+195,  1.48425773e+195,\n",
       "         3.02169608e+198, -1.05001064e+197,  4.93500643e+193,\n",
       "         3.86524984e+193, -1.29924794e+197,  9.45483253e+193,\n",
       "        -1.24255991e+194, -1.01300321e+197,  5.60915746e+193,\n",
       "        -4.46720544e+197, -1.00695709e+195,  1.80762600e+198,\n",
       "         1.87401620e+198,  1.87402469e+198,  3.02585516e+198,\n",
       "         3.02165495e+198,  3.02165533e+198, -6.10637894e+196]),\n",
       " array([-1.83126324e+201,  9.25242308e+200,  1.39397312e+201,\n",
       "         5.36047460e+200, -1.73203142e+202, -1.75955475e+202,\n",
       "        -1.73176981e+202,  4.33514088e+199,  2.48047608e+200,\n",
       "         1.69649830e+201,  2.39857813e+199, -8.50719177e+198,\n",
       "        -1.73191943e+202,  6.01825525e+200, -2.82855500e+197,\n",
       "        -2.21541185e+197,  7.44678717e+200, -5.41914467e+197,\n",
       "         7.12187328e+197,  5.80614297e+200, -3.21495232e+197,\n",
       "         2.56042954e+201,  5.77148893e+198, -1.03606137e+202,\n",
       "        -1.07411367e+202, -1.07411854e+202, -1.73430326e+202,\n",
       "        -1.73189586e+202, -1.73189608e+202,  3.49994046e+200]),\n",
       " array([ 1.04960933e+205, -5.30313139e+204, -7.98971532e+204,\n",
       "        -3.07241691e+204,  9.92733484e+205,  1.00850879e+206,\n",
       "         9.92583539e+205, -2.48473524e+203, -1.42171304e+204,\n",
       "        -9.72367272e+204, -1.37477230e+203,  4.87599360e+202,\n",
       "         9.92669298e+205, -3.44943136e+204,  1.62121843e+201,\n",
       "         1.26978847e+201, -4.26821066e+204,  3.10604433e+201,\n",
       "        -4.08198257e+201, -3.32785680e+204,  1.84268644e+201,\n",
       "        -1.46753928e+205, -3.30799444e+202,  5.93830346e+205,\n",
       "         6.15640454e+205,  6.15643244e+205,  9.94035615e+205,\n",
       "         9.92655785e+205,  9.92655912e+205, -2.00603063e+204]),\n",
       " array([-6.01595511e+208,  3.03955000e+208,  4.57939609e+208,\n",
       "         1.76099065e+208, -5.68996474e+209, -5.78038271e+209,\n",
       "        -5.68910531e+209,  1.42415423e+207,  8.14870980e+207,\n",
       "         5.57323348e+208,  7.87966362e+206, -2.79473112e+206,\n",
       "        -5.68959684e+209,  1.97708077e+208, -9.29219759e+204,\n",
       "        -7.27793686e+204,  2.44637343e+208, -1.78026459e+205,\n",
       "         2.33963468e+205,  1.90739893e+208, -1.05615667e+205,\n",
       "         8.41136808e+208,  1.89601459e+206, -3.40360609e+209,\n",
       "        -3.52861320e+209, -3.52862919e+209, -5.69742805e+209,\n",
       "        -5.68951939e+209, -5.68952012e+209,  1.14977924e+208]),\n",
       " array([ 3.44811301e+212, -1.74215261e+212, -2.62473289e+212,\n",
       "        -1.00933180e+212,  3.26126793e+213,  3.31309201e+213,\n",
       "         3.26077534e+213, -8.16270175e+210, -4.67052559e+211,\n",
       "        -3.19436208e+212, -4.51631872e+210,  1.60183189e+210,\n",
       "         3.26105706e+213, -1.13318630e+212,  5.32592860e+208,\n",
       "         4.17143219e+208, -1.40216672e+212,  1.02037887e+209,\n",
       "        -1.34098820e+209, -1.09324736e+212,  6.05348191e+208,\n",
       "        -4.82107117e+212, -1.08672230e+210,  1.95081549e+213,\n",
       "         2.02246474e+213,  2.02247390e+213,  3.26554561e+213,\n",
       "         3.26101267e+213,  3.26101309e+213, -6.59009035e+211]),\n",
       " array([-1.97632514e+216,  9.98534559e+215,  1.50439547e+216,\n",
       "         5.78509985e+215, -1.86923276e+217, -1.89893632e+217,\n",
       "        -1.86895043e+217,  4.67854523e+214,  2.67696480e+215,\n",
       "         1.83088491e+216,  2.58857938e+214, -9.18108144e+213,\n",
       "        -1.86911190e+217,  6.49498601e+215, -3.05261648e+212,\n",
       "        -2.39090374e+212,  8.03667783e+215, -5.84841743e+212,\n",
       "         7.68602618e+212,  6.26607145e+215, -3.46962192e+212,\n",
       "         2.76325171e+216,  6.22867232e+213, -1.11813206e+217,\n",
       "        -1.15919864e+217, -1.15920389e+217, -1.87168456e+217,\n",
       "        -1.86908646e+217, -1.86908670e+217,  3.77718515e+215]),\n",
       " array([ 1.13275320e+220, -5.72321426e+219, -8.62261355e+219,\n",
       "        -3.31579570e+219,  1.07137199e+221,  1.08839693e+221,\n",
       "         1.07121017e+221, -2.68156135e+218, -1.53433278e+219,\n",
       "        -1.04939249e+220, -1.48367368e+218,  5.26224112e+217,\n",
       "         1.07130272e+221, -3.72267502e+219,  1.74964181e+216,\n",
       "         1.37037364e+216, -4.60631319e+219,  3.35208688e+216,\n",
       "        -4.40533322e+216, -3.59147004e+219,  1.98865322e+216,\n",
       "        -1.58378910e+220, -3.57003430e+217,  6.40870092e+220,\n",
       "         6.64407868e+220,  6.64410880e+220,  1.07277727e+221,\n",
       "         1.07128814e+221,  1.07128827e+221, -2.16493658e+219]),\n",
       " array([-6.49250367e+223,  3.28032527e+223,  4.94214891e+223,\n",
       "         1.90048597e+223, -6.14069026e+224, -6.23827062e+224,\n",
       "        -6.13976276e+224,  1.53696735e+222,  8.79420264e+222,\n",
       "         6.01471224e+223,  8.50384421e+221, -3.01611328e+221,\n",
       "        -6.14029323e+224,  2.13369347e+223, -1.00282708e+220,\n",
       "        -7.85445220e+219,  2.64016073e+223, -1.92128668e+220,\n",
       "         2.52496678e+220,  2.05849185e+223, -1.13981918e+220,\n",
       "         9.07766717e+223,  2.04620571e+221, -3.67321973e+224,\n",
       "        -3.80812917e+224, -3.80814643e+224, -6.14874477e+224,\n",
       "        -6.14020964e+224, -6.14021043e+224,  1.24085799e+223]),\n",
       " array([ 3.72125223e+227, -1.88015569e+227, -2.83264879e+227,\n",
       "        -1.08928512e+227,  3.51960638e+228,  3.57553567e+228,\n",
       "         3.51907477e+228, -8.80930295e+225, -5.04049714e+226,\n",
       "        -3.44740065e+227, -4.87407491e+225,  1.72871959e+225,\n",
       "         3.51937882e+228, -1.22295065e+227,  5.74781733e+223,\n",
       "         4.50186850e+223, -1.51323812e+227,  1.10120728e+224,\n",
       "        -1.44721339e+224, -1.17984799e+227,  6.53300313e+223,\n",
       "        -5.20296806e+227, -1.17280605e+225,  2.10534762e+228,\n",
       "         2.18267249e+228,  2.18268239e+228,  3.52422292e+228,\n",
       "         3.51933091e+228,  3.51933136e+228, -7.11211854e+226]),\n",
       " array([-2.13287799e+231,  1.07763259e+231,  1.62356483e+231,\n",
       "         6.24336142e+230, -2.01730238e+232, -2.04935889e+232,\n",
       "        -2.01699768e+232,  5.04915206e+229,  2.88901820e+230,\n",
       "         1.97591684e+231,  2.79363140e+229, -9.90835269e+228,\n",
       "        -2.01717195e+232,  7.00948059e+230, -3.29442680e+227,\n",
       "        -2.58029707e+227,  8.67329616e+230, -6.31169464e+227,\n",
       "         8.29486795e+227,  6.76243277e+230, -3.74446495e+227,\n",
       "         2.98214025e+231,  6.72207109e+228, -1.20670390e+232,\n",
       "        -1.25102353e+232, -1.25102920e+232, -2.01994840e+232,\n",
       "        -2.01714449e+232, -2.01714475e+232,  4.07639153e+230]),\n",
       " array([ 1.22248325e+235, -6.17657362e+234, -9.30564626e+234,\n",
       "        -3.57845352e+234,  1.15623977e+236,  1.17461333e+236,\n",
       "         1.15606513e+236, -2.89397886e+233, -1.65587360e+234,\n",
       "        -1.13251918e+235, -1.60120157e+233,  5.67908490e+232,\n",
       "         1.15616502e+236, -4.01756343e+234,  1.88823814e+231,\n",
       "         1.47892658e+231, -4.97119822e+234,  3.61761948e+231,\n",
       "        -4.75429779e+231, -3.87596516e+234,  2.14618262e+231,\n",
       "        -1.70924756e+235, -3.85283141e+232,  6.91636050e+235,\n",
       "         7.17038350e+235,  7.17041600e+235,  1.15775637e+236,\n",
       "         1.15614928e+236,  1.15614943e+236, -2.33643011e+234]),\n",
       " array([-7.00680161e+238,  3.54017333e+238,  5.33363687e+238,\n",
       "         2.05103129e+238, -6.62711962e+239, -6.73242971e+239,\n",
       "        -6.62611864e+239,  1.65871686e+237,  9.49082763e+237,\n",
       "         6.49116236e+238,  9.17746871e+236, -3.25503202e+236,\n",
       "        -6.62669113e+239,  2.30271212e+238, -1.08226514e+235,\n",
       "        -8.47663568e+234,  2.84929873e+238, -2.07347970e+235,\n",
       "         2.72497979e+235,  2.22155346e+238, -1.23010895e+235,\n",
       "         9.79674655e+238,  2.20829409e+236, -3.96419059e+239,\n",
       "        -4.10978676e+239, -4.10980538e+239, -6.63581216e+239,\n",
       "        -6.62660092e+239, -6.62660177e+239,  1.33915146e+238]),\n",
       " array([ 4.01602794e+242, -2.02909056e+242, -3.05703456e+242,\n",
       "        -1.17557188e+242,  3.79840889e+243,  3.85876857e+243,\n",
       "         3.79783517e+243, -9.50712410e+240, -5.43977567e+241,\n",
       "        -3.72048344e+242, -5.26017045e+240,  1.86565858e+240,\n",
       "         3.79816330e+243, -1.31982561e+242,  6.20312560e+238,\n",
       "         4.85848003e+238, -1.63310794e+242,  1.18843845e+239,\n",
       "        -1.56185312e+239, -1.27330860e+242,  7.05050919e+238,\n",
       "        -5.61511657e+242, -1.26570884e+240,  2.27212087e+243,\n",
       "         2.35557097e+243,  2.35558164e+243,  3.80339112e+243,\n",
       "         3.79811159e+243,  3.79811208e+243, -7.67549872e+241]),\n",
       " array([-2.30183203e+246,  1.16299631e+246,  1.75217408e+246,\n",
       "         6.73792378e+245, -2.17710120e+247, -2.21169704e+247,\n",
       "        -2.17677237e+247,  5.44911618e+244,  3.11786922e+245,\n",
       "         2.13243735e+246,  3.01492645e+244, -1.06932341e+244,\n",
       "        -2.17696044e+247,  7.56473040e+245, -3.55539190e+242,\n",
       "        -2.78469302e+242,  9.36034365e+245, -6.81166995e+242,\n",
       "         8.95193858e+242,  7.29811290e+245, -4.04107944e+242,\n",
       "         3.21836785e+246,  7.25455401e+243, -1.30229189e+247,\n",
       "        -1.35012226e+247, -1.35012838e+247, -2.17995682e+247,\n",
       "        -2.17693081e+247, -2.17693108e+247,  4.39929928e+245]),\n",
       " array([ 1.31932118e+250, -6.66584544e+249, -1.00427848e+250,\n",
       "        -3.86191755e+249,  1.24783029e+251,  1.26765928e+251,\n",
       "         1.24764181e+251, -3.12322284e+248, -1.78704216e+249,\n",
       "        -1.22223069e+250, -1.72803934e+248,  6.12894859e+247,\n",
       "         1.24774961e+251, -4.33581116e+249,  2.03781326e+246,\n",
       "         1.59607844e+246, -5.36498729e+249,  3.90418601e+246,\n",
       "        -5.13090529e+246, -4.18299631e+249,  2.31619058e+246,\n",
       "        -1.84464409e+250, -4.15803004e+247,  7.46423388e+250,\n",
       "         7.73837909e+250,  7.73841417e+250,  1.24946702e+251,\n",
       "         1.24773262e+251,  1.24773278e+251, -2.52150836e+249]),\n",
       " array([-7.56183921e+253,  3.82060503e+253,  5.75613619e+253,\n",
       "         2.21350192e+253, -7.15208104e+254, -7.26573318e+254,\n",
       "        -7.15100077e+254,  1.79011065e+252,  1.02426351e+253,\n",
       "         7.00535405e+253,  9.90445378e+251, -3.51287651e+251,\n",
       "        -7.15161861e+254,  2.48511942e+253, -1.16799582e+250,\n",
       "        -9.14810488e+249,  3.07500341e+253, -2.23772856e+250,\n",
       "         2.94083665e+250,  2.39753185e+253, -1.32755094e+250,\n",
       "         1.05727872e+254,  2.38322215e+251, -4.27821044e+254,\n",
       "        -4.43533988e+254, -4.43535999e+254, -7.16146215e+254,\n",
       "        -7.15152126e+254, -7.15152217e+254,  1.44523116e+253]),\n",
       " array([ 4.33415404e+257, -2.18982318e+257, -3.29919485e+257,\n",
       "        -1.26869377e+257,  4.09929649e+258,  4.16443751e+258,\n",
       "         4.09867732e+258, -1.02602225e+256, -5.87068269e+256,\n",
       "        -4.01519825e+257, -5.67685020e+255,  2.01344508e+255,\n",
       "         4.09903145e+258, -1.42437443e+257,  6.69450071e+253,\n",
       "         5.24334023e+253, -1.76247314e+257,  1.28257955e+254,\n",
       "        -1.68557393e+254, -1.37417262e+257,  7.60900905e+253,\n",
       "        -6.05991307e+257, -1.36597085e+255,  2.45210491e+258,\n",
       "         2.54216544e+258,  2.54217696e+258,  4.10467338e+258,\n",
       "         4.09897565e+258,  4.09897617e+258, -8.28350656e+256]),\n",
       " array([-2.48416962e+261,  1.25512203e+261,  1.89097101e+261,\n",
       "         7.27166245e+260, -2.34955835e+262, -2.38689466e+262,\n",
       "        -2.34920347e+262,  5.88076310e+259,  3.36484847e+260,\n",
       "         2.30135649e+261,  3.25375118e+259, -1.15402892e+259,\n",
       "        -2.34940644e+262,  8.16396383e+260, -3.83702913e+257,\n",
       "        -3.00528002e+257,  1.01018150e+261, -7.35125037e+257,\n",
       "         9.66105848e+257,  7.87622646e+260, -4.36118997e+257,\n",
       "         3.47330801e+261,  7.82921710e+258, -1.40545179e+262,\n",
       "        -1.45707100e+262, -1.45707760e+262, -2.35264018e+262,\n",
       "        -2.34937446e+262, -2.34937476e+262,  4.74778589e+260]),\n",
       " array([ 1.42383004e+265, -7.19387449e+264, -1.08383151e+265,\n",
       "        -4.16783594e+264,  1.34667606e+266,  1.36807579e+266,\n",
       "         1.34647265e+266, -3.37062617e+263, -1.92860113e+264,\n",
       "        -1.31904861e+265, -1.86492445e+263,  6.61444784e+262,\n",
       "         1.34658899e+266, -4.67926861e+264,  2.19923683e+261,\n",
       "         1.72251038e+261, -5.78997002e+264,  4.21345266e+261,\n",
       "        -5.53734542e+261, -4.51434867e+264,  2.49966557e+261,\n",
       "        -1.99076594e+265, -4.48740472e+262,  8.05550657e+265,\n",
       "         8.35136795e+265,  8.35140580e+265,  1.34844244e+266,\n",
       "         1.34657066e+266,  1.34657083e+266, -2.72124741e+264]),\n",
       " array([-8.16084361e+268,  4.12325088e+268,  6.21210343e+268,\n",
       "         2.38884251e+268, -7.71862681e+269, -7.84128181e+269,\n",
       "        -7.71746097e+269,  1.93191268e+267,  1.10539964e+268,\n",
       "         7.56027697e+268,  1.06890263e+267, -3.79114592e+266,\n",
       "        -7.71812776e+269,  2.68197596e+268, -1.26051757e+265,\n",
       "        -9.87276393e+264,  3.31858709e+268, -2.41498825e+265,\n",
       "         3.17379243e+265,  2.58745022e+268, -1.43271172e+265,\n",
       "         1.14103012e+269,  2.57200699e+266, -4.61710510e+269,\n",
       "        -4.78668141e+269, -4.78670311e+269, -7.72875104e+269,\n",
       "        -7.71802269e+269, -7.71802368e+269,  1.55971387e+268]),\n",
       " array([ 4.67748022e+272, -2.36328808e+272, -3.56053765e+272,\n",
       "        -1.36919222e+272,  4.42401864e+273,  4.49431974e+273,\n",
       "         4.42335042e+273, -1.10729770e+271, -6.33572363e+271,\n",
       "        -4.33325863e+272, -6.12653687e+270,  2.17293835e+270,\n",
       "         4.42373260e+273, -1.53720499e+272,  7.22479966e+268,\n",
       "         5.65868680e+268, -1.90208589e+272,  1.38417795e+269,\n",
       "        -1.81909518e+269, -1.48302649e+272,  8.21174997e+268,\n",
       "        -6.53994373e+272, -1.47417502e+270,  2.64634624e+273,\n",
       "         2.74354083e+273,  2.74355326e+273,  4.42982146e+273,\n",
       "         4.42367238e+273,  4.42367295e+273, -8.93967721e+271]),\n",
       " array([-2.68095092e+276,  1.35454541e+276,  2.04076260e+276,\n",
       "         7.84768077e+275, -2.53567654e+277, -2.57597041e+277,\n",
       "        -2.53529354e+277,  6.34660255e+274,  3.63139197e+275,\n",
       "         2.48365641e+276,  3.51149420e+274, -1.24544430e+274,\n",
       "        -2.53551259e+277,  8.81066501e+275, -4.14097600e+272,\n",
       "        -3.24334062e+272,  1.09020213e+276, -7.93357317e+272,\n",
       "         1.04263507e+273,  8.50013478e+275, -4.70665778e+272,\n",
       "         3.74844304e+276,  8.44940161e+273, -1.51678341e+277,\n",
       "        -1.57249159e+277, -1.57249872e+277, -2.53900249e+277,\n",
       "        -2.53547808e+277, -2.53547840e+277,  5.12387755e+275]),\n",
       " array([ 1.53661748e+280, -7.76373090e+279, -1.16968627e+280,\n",
       "        -4.49798738e+279,  1.45335181e+281,  1.47644671e+281,\n",
       "         1.45313230e+281, -3.63762735e+278, -2.08137356e+279,\n",
       "        -1.42353588e+280, -2.01265279e+278,  7.13840547e+277,\n",
       "         1.45325784e+281, -5.04993274e+279,  2.37344743e+276,\n",
       "         1.85895752e+276, -6.24861738e+279,  4.54721758e+276,\n",
       "        -5.97598134e+276, -4.87194881e+279,  2.69767437e+276,\n",
       "        -2.14846271e+280, -4.84287051e+277,  8.69361640e+280,\n",
       "         9.01291418e+280,  9.01295503e+280,  1.45525812e+281,\n",
       "         1.45323806e+281,  1.45323825e+281, -2.93680862e+279]),\n",
       " array([-8.80729763e+283,  4.44987056e+283,  6.70418972e+283,\n",
       "         2.57807256e+283, -8.33005101e+284, -8.46242201e+284,\n",
       "        -8.32879282e+284,  2.08494744e+282,  1.19296290e+283,\n",
       "         8.15915763e+283,  1.15357481e+282, -4.09145819e+281,\n",
       "        -8.32951242e+284,  2.89442631e+283, -1.36036836e+280,\n",
       "        -1.06548262e+280,  3.58146603e+283, -2.60628941e+280,\n",
       "         3.42520159e+280,  2.79241280e+283, -1.54620271e+280,\n",
       "         1.23141581e+284,  2.77574625e+281, -4.98284500e+284,\n",
       "        -5.16585415e+284, -5.16587756e+284, -8.34097722e+284,\n",
       "        -8.32939903e+284, -8.32940010e+284,  1.68326522e+283]),\n",
       " array([ 5.04800268e+287, -2.55049386e+287, -3.84258249e+287,\n",
       "        -1.47765158e+287,  4.77446337e+288,  4.85033331e+288,\n",
       "         4.77374222e+288, -1.19501131e+286, -6.83760237e+286,\n",
       "        -4.67651388e+287, -6.61184507e+285,  2.34506574e+285,\n",
       "         4.77415467e+288, -1.65897332e+287,  7.79710578e+283,\n",
       "         6.10693467e+283, -2.05275794e+287,  1.49382438e+284,\n",
       "        -1.96319320e+284, -1.60050312e+287,  8.86223649e+283,\n",
       "        -7.05799959e+287, -1.59095049e+285,  2.85597422e+288,\n",
       "         2.96086799e+288,  2.96088141e+288,  4.78072585e+288,\n",
       "         4.77408968e+288,  4.77409029e+288, -9.64782584e+286]),\n",
       " array([-2.89332008e+291,  1.46184453e+291,  2.20241981e+291,\n",
       "         8.46932786e+290, -2.73653791e+292, -2.78002363e+292,\n",
       "        -2.73612458e+292,  6.84934306e+289,  3.91904947e+290,\n",
       "         2.68039706e+291,  3.78965411e+289, -1.34410107e+289,\n",
       "        -2.73636098e+292,  9.50859405e+290, -4.46899975e+287,\n",
       "        -3.50025898e+287,  1.17656153e+291, -8.56202415e+287,\n",
       "         1.12522648e+288,  9.17346544e+290, -5.07949151e+287,\n",
       "         4.04537264e+291,  9.11871349e+288, -1.63693406e+292,\n",
       "        -1.69705512e+292, -1.69706281e+292, -2.74012733e+292,\n",
       "        -2.73632373e+292, -2.73632408e+292,  5.52976098e+290]),\n",
       " array([ 1.65833927e+295, -8.37872798e+294, -1.26234193e+295,\n",
       "        -4.85429147e+294,  1.56847779e+296,  1.59340213e+296,\n",
       "         1.56824089e+296, -3.92577878e+293, -2.24624773e+294,\n",
       "        -1.53630002e+295, -2.17208330e+293,  7.70386795e+292,\n",
       "         1.56837638e+296, -5.44995869e+294,  2.56145798e+291,\n",
       "         2.00621320e+291, -6.74359608e+294,  4.90742140e+291,\n",
       "        -6.44936342e+291, -5.25787593e+294,  2.91136826e+291,\n",
       "        -2.31865128e+295, -5.22649422e+292,  9.38227354e+295,\n",
       "         9.72686421e+295,  9.72690830e+295,  1.57053510e+296,\n",
       "         1.56835503e+296,  1.56835523e+296, -3.16944532e+294]),\n",
       " array([-9.50495992e+298,  4.80236312e+298,  7.23525618e+298,\n",
       "         2.78229230e+298,             -inf,             -inf,\n",
       "                    -inf,  2.25010470e+297,  1.28746240e+298,\n",
       "         8.80547809e+298,  1.24495422e+297, -4.41555943e+296,\n",
       "                    -inf,  3.12370574e+298, -1.46812874e+295,\n",
       "        -1.14988388e+295,  3.86516870e+298, -2.81274433e+295,\n",
       "         3.69652591e+295,  3.01361131e+298, -1.66868379e+295,\n",
       "         1.32896132e+299,  2.99562453e+296, -5.37755666e+299,\n",
       "        -5.57506272e+299, -5.57508799e+299,             -inf,\n",
       "                    -inf,             -inf,  1.81660359e+298]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan]),\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in less_equal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "predictions_GD = compute_predictions(x_te,w_GD)\n",
    "compute_accuracy(y_te,predictions_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_LS = least_squares(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.93423695e-05, -3.48912943e-03, -3.26343760e-03, -1.51679834e-04,\n",
       "        1.21211206e-02,  2.12027995e-04, -9.48648403e-03,  1.85929094e-01,\n",
       "       -1.27078510e-04, -2.83775188e+00, -1.02706124e-01,  4.86724095e-02,\n",
       "        6.75712296e-03,  2.84230389e+00,  1.55100772e-04, -5.89131487e-04,\n",
       "        2.84419968e+00,  4.10388756e-05,  3.85893837e-04,  1.79363132e-03,\n",
       "       -2.06294585e-04, -2.17852008e-04,  2.12432765e-04,  9.49320717e-04,\n",
       "       -5.80701064e-04, -3.12251922e-04,  1.39182472e-03, -4.00767000e-03,\n",
       "       -7.01506316e-03,  2.83630071e+00])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_predictions(x_te,w_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7453000000000001\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross-validation to find good hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "lambda_ = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "lambdas, tr_losses, te_losses = find_optimal_lambda(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_losses = (2*np.array(tr_losses))**(0.5)\n",
    "te_losses = (2*np.array(te_losses))**(0.5)\n",
    "cross_validation_visualization(lambdas, tr_losses, te_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "optimal_lambda = find_optimal_lambda(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rr = ridge_regression(y_tr,x_tr,optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004520353656360241"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_predictions(x_te,w_rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7453000000000001\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:194: RuntimeWarning: divide by zero encountered in log\n",
      "  # start the logistic regression\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:194: RuntimeWarning: invalid value encountered in multiply\n",
      "  # start the logistic regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_logistic = logistic_regression(y_tr, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876599999999999\n"
     ]
    }
   ],
   "source": [
    "predictions = logistic_predictions(x_te,w_logistic)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:194: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:194: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_reg_logistic = reg_logistic_regression(y_tr, x_tr, optimal_lambda, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6372800000000001\n"
     ]
    }
   ],
   "source": [
    "predictions = logistic_predictions(x_te,w_reg_logistic)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: EDA and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'all/train.csv'\n",
    "labels, input_data, ids, features = load_csv_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00368e+02,  3.58310e+01,  7.71850e+01,  4.12500e+00,\n",
       "        -9.99000e+02, -9.99000e+02, -9.99000e+02,  3.02200e+00,\n",
       "         4.12500e+00,  6.41480e+01,  9.88000e-01, -1.41200e+00,\n",
       "        -9.99000e+02,  3.22700e+01,  1.98700e+00,  1.14000e+00,\n",
       "         3.18780e+01,  6.82000e-01, -1.58500e+00,  1.37440e+01,\n",
       "         2.64400e+00,  1.21919e+02,  0.00000e+00, -9.99000e+02,\n",
       "        -9.99000e+02, -9.99000e+02, -9.99000e+02, -9.99000e+02,\n",
       "        -9.99000e+02,  0.00000e+00],\n",
       "       [ 7.66620e+01,  4.15970e+01,  5.76100e+01,  2.09940e+01,\n",
       "        -9.99000e+02, -9.99000e+02, -9.99000e+02,  2.62700e+00,\n",
       "         2.09940e+01,  5.95500e+01,  8.16000e-01, -1.40500e+00,\n",
       "        -9.99000e+02,  3.27900e+01,  4.08000e-01,  1.96800e+00,\n",
       "         2.67600e+01,  1.86000e-01, -6.50000e-01,  3.74580e+01,\n",
       "        -2.08300e+00,  1.34038e+02,  0.00000e+00, -9.99000e+02,\n",
       "        -9.99000e+02, -9.99000e+02, -9.99000e+02, -9.99000e+02,\n",
       "        -9.99000e+02,  0.00000e+00]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = x_tr, y_tr  # input_data, labels\n",
    "\n",
    "i, = np.where(features == 'PRI_jet_num')\n",
    "pri_jet_num_idx = np.squeeze(i)\n",
    "cond_null = X[:, pri_jet_num_idx] == 0\n",
    "cond_one = X[:, pri_jet_num_idx] == 1\n",
    "cond_plural = X[:, pri_jet_num_idx] >= 2\n",
    "conditions = (cond_null, cond_one, cond_plural)\n",
    "\n",
    "dsets = [X[cond] for cond in conditions]\n",
    "ybs = [y[cond] for cond in conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 1 2]\n",
      " [2 3 1]]\n",
      "[1 2 3]\n",
      "[7 7 7]\n",
      "[[1 2 3]\n",
      " [3 1 2]\n",
      " [2 3 1]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[1,2,3],[3,1,2],[2,3,1]])\n",
    "print(test)\n",
    "col = test[0]\n",
    "print(col)\n",
    "col = np.array([7,7,7])\n",
    "print(col)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, just remove any column with undefined -999 values. Also, before standardization, remove features with 0 variance. \n",
    "Second part: test how replacing -999 in DER_mass_MMC by defined mean affects the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dsets = []\n",
    "clean_features = []\n",
    "\n",
    "for dset in dsets:\n",
    "    \n",
    "    # do something\n",
    "    \"\"\"\n",
    "    DER_mass_MMC = dset[:,0]\n",
    "    undefined_indices = (DER_mass_MMC == -999)\n",
    "    filter_undefined = DER_mass_MMC[~undefined_indices]\n",
    "    defined_mean = np.mean(filter_undefined)\n",
    "    print(defined_mean)\n",
    "    defined_median = np.median(filter_undefined)\n",
    "    print(defined_median)\n",
    "    DER_mass_MMC[undefined_indices] = defined_median\n",
    "    \"\"\"\n",
    "    \n",
    "    # do another thing\n",
    "    no_undefined = np.all(dset != -999, axis = 0)\n",
    "    no_constant = np.any(dset != dset[0], axis = 0)\n",
    "    cleaned = no_undefined * no_constant\n",
    "    clean_dset = dset[:,cleaned]\n",
    "    clean_dsets.append(clean_dset)\n",
    "    clean_features.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC'], dtype='<U27')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[~clean_features[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize and extend data, save mean and standard deviation of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "standardized_dsets = []\n",
    "\n",
    "for clean_dset in clean_dsets:\n",
    "    standardized_dset, mean_x, std_x = extend_and_standardize(clean_dset)\n",
    "    # Added for testing purposes, handles outliers\n",
    "    # standardized_dset[standardized_dset > 3] = 3\n",
    "    # standardized_dset[standardized_dset < -3]  = -3\n",
    "    standardized_dsets.append(standardized_dset)\n",
    "    parameters.append((mean_x,std_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out what to do with ones (first standardize test data, then extend?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws_GD = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 100\n",
    "    gamma = 0.1\n",
    "    losses_GD, w_GD = gradient_descent(ybs[jet_num], standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_GD.append(w_GD[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_GD = model_output(x_te, ws_GD, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_predictions(output_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75754\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72386\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: bit worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72848\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_LS = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    w_LS = least_squares(ybs[jet_num],standardized_dset)\n",
    "    ws_LS.append(w_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_LS = model_output(x_te, ws_LS, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_predictions(output_LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75932\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75986\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76336\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    optimal_lambda = find_optimal_lambda(ybs[jet_num], standardized_dset)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_RR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    w_RR = ridge_regression(ybs[jet_num],standardized_dset,lambdas[jet_num])\n",
    "    ws_RR.append(w_RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_RR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_RR = model_output(x_te, ws_RR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_predictions(output_RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75922\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75988\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75992\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5960066874471566\n",
      "Current iteration=100, loss=0.40133374072830863\n",
      "Current iteration=200, loss=0.3926881661997025\n",
      "Current iteration=300, loss=0.3894244170034508\n",
      "Current iteration=400, loss=0.3879967243127494\n",
      "Current iteration=500, loss=0.3873052345488007\n",
      "Current iteration=600, loss=0.38694265515314824\n",
      "Current iteration=700, loss=0.3867391217284569\n",
      "Current iteration=800, loss=0.38661744992896246\n",
      "Current iteration=900, loss=0.38654016496053434\n",
      "Current iteration=0, loss=0.6368307187394493\n",
      "Current iteration=100, loss=0.5402924410178843\n",
      "Current iteration=200, loss=0.5376170196986818\n",
      "Current iteration=300, loss=0.5369559052499969\n",
      "Current iteration=400, loss=0.5367143813921327\n",
      "Current iteration=500, loss=0.5365993468071344\n",
      "Current iteration=600, loss=0.5365316664917763\n",
      "Current iteration=700, loss=0.5364845702036576\n",
      "Current iteration=800, loss=0.5364478411558201\n",
      "Current iteration=900, loss=0.536417252962046\n",
      "Current iteration=0, loss=0.6079005788197551\n",
      "Current iteration=100, loss=0.5288761281652368\n",
      "Current iteration=200, loss=0.5261665499790427\n",
      "Current iteration=300, loss=0.5254154824195849\n",
      "Current iteration=400, loss=0.5251646743082041\n",
      "Current iteration=500, loss=0.5250684051134756\n",
      "Current iteration=600, loss=0.5250255714103008\n",
      "Current iteration=700, loss=0.5250027276211185\n",
      "Current iteration=800, loss=0.5249878961295223\n",
      "Current iteration=900, loss=0.5249765604442729\n"
     ]
    }
   ],
   "source": [
    "ws_LR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 1000\n",
    "    gamma = 0.7 # 0.01\n",
    "    loss, w_LR = logistic_regression(ybs[jet_num], standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_LR.append(w_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('all/weights.npy', ws_LR)\n",
    "np.save('all/clean_features.npy', clean_features)\n",
    "np.save('all/parameters.npy', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.06508255, -0.45119356, -0.21199313, -0.03595331,  0.29905659,\n",
       "        -0.03595332,  0.15784936, -0.29798676,  0.12536019,  0.3155822 ,\n",
       "        -0.00140518, -0.00415845, -0.07345946,  0.01703571,  0.00186719,\n",
       "        -0.22621891, -0.01126403,  0.08581374]),\n",
       " array([-5.88681443e-01, -4.18555938e-01, -1.09752612e-01,  2.88555303e-02,\n",
       "         2.60236753e-01,  9.17481911e-02,  1.28123028e-01, -2.07077520e-01,\n",
       "         3.24420954e-01,  2.59683834e-01,  3.11862629e-03, -1.18188949e-02,\n",
       "         2.16878347e-02, -1.40054880e-02,  3.95079151e-03, -3.45611948e-02,\n",
       "         5.27341240e-03,  2.29069799e-02,  5.33176476e-02, -6.22587356e-03,\n",
       "        -4.50925292e-04,  5.33176835e-02]),\n",
       " array([-0.21953986, -0.33926629,  0.00072089,  0.20529115,  0.17305107,\n",
       "         0.29032011, -0.11119544,  0.13171476, -0.13120939, -0.00159301,\n",
       "        -0.15334595,  0.320811  ,  0.27236755,  0.24750596, -0.00959139,\n",
       "        -0.00425963,  0.09248357, -0.01408606,  0.00742005,  0.08697769,\n",
       "         0.01693134, -0.14080728, -0.20162592, -0.05764856,  0.00644641,\n",
       "         0.00792598,  0.01087114,  0.0096146 , -0.00906491, -0.09454302])]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.79541225e+00, -4.30300129e-01, -2.81973114e+00,  1.39003814e-02,\n",
       "         2.02812866e+00,  1.38997616e-02,  8.10015203e-01, -1.09004776e+00,\n",
       "        -4.23623089e-03,  4.57996729e-01,  2.70286407e-03,  1.82370480e-03,\n",
       "         8.32812055e-01,  1.95594749e-02,  9.18937607e-05,  1.41167833e-02,\n",
       "        -2.35670628e-02,  1.01385779e-01]),\n",
       " array([-0.78616621, -0.56095392, -1.03472427,  0.04193777,  0.95663736,\n",
       "         0.16256699,  0.38806414, -0.66185926,  0.32872608,  0.42582772,\n",
       "         0.01353226, -0.01160814,  0.76169172, -0.02008233,  0.00286527,\n",
       "         0.04309859,  0.00455754, -0.12136045, -0.00413086, -0.00851973,\n",
       "        -0.00278753, -0.00412857]),\n",
       " array([-0.26022381, -0.44161697, -0.55470916,  0.7094484 , -0.34954631,\n",
       "         1.10896809,  0.08253075,  0.80318046, -0.0582413 ,  0.07304029,\n",
       "        -0.61765873,  0.3264373 ,  0.39981799,  0.38679416, -0.0068546 ,\n",
       "        -0.00174016,  0.73145221, -0.01982798,  0.01057222,  0.0588061 ,\n",
       "         0.01347587, -0.45906422, -0.19561769, -0.39024222,  0.0083346 ,\n",
       "         0.00843456,  0.06031377,  0.01649003, -0.0053095 , -0.2146092 ])]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_LR = model_output(x_te, ws_LR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_predictions(output_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76418\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76258\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76196\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75488\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Current iteration=0, loss=0.5985665553496784\n",
      "Current iteration=100, loss=0.40557929202525944\n",
      "Current iteration=200, loss=0.39793366841149214\n",
      "Current iteration=300, loss=0.3949550545132445\n",
      "Current iteration=400, loss=0.3935836792995515\n",
      "Current iteration=500, loss=0.3929015946370937\n",
      "Current iteration=600, loss=0.39254697900561397\n",
      "Current iteration=700, loss=0.3923579038077661\n",
      "Current iteration=800, loss=0.3922554613715885\n",
      "Current iteration=900, loss=0.39219934993675315\n",
      "Current iteration=0, loss=0.39322514887411075\n",
      "Current iteration=100, loss=0.3931482727630207\n",
      "Current iteration=200, loss=0.3931374795044835\n",
      "Current iteration=300, loss=0.3931319180850954\n",
      "Current iteration=400, loss=0.3931289051392934\n",
      "Current iteration=500, loss=0.39312725458286024\n",
      "Current iteration=600, loss=0.39312634748222397\n",
      "Current iteration=700, loss=0.39312584830003167\n",
      "Current iteration=800, loss=0.3931255733848451\n",
      "Current iteration=900, loss=0.3931254219004781\n",
      "Current iteration=0, loss=0.39127969300401744\n",
      "Current iteration=100, loss=0.39117267558211144\n",
      "Current iteration=200, loss=0.39116451533650043\n",
      "Current iteration=300, loss=0.3911608187111363\n",
      "Current iteration=400, loss=0.39115911403413717\n",
      "Current iteration=500, loss=0.39115832551179164\n",
      "Current iteration=600, loss=0.3911579595695403\n",
      "Current iteration=700, loss=0.3911577890655494\n",
      "Current iteration=800, loss=0.39115770924483423\n",
      "Current iteration=900, loss=0.3911576716694936\n",
      "Current iteration=0, loss=0.3925452199300491\n",
      "Current iteration=100, loss=0.39245560862197376\n",
      "Current iteration=200, loss=0.39244825073148865\n",
      "Current iteration=300, loss=0.3924450020603832\n",
      "Current iteration=400, loss=0.3924433620331157\n",
      "Current iteration=500, loss=0.39244250000146447\n",
      "Current iteration=600, loss=0.3924420400410183\n",
      "Current iteration=700, loss=0.3924417924814891\n",
      "Current iteration=800, loss=0.39244165833284433\n",
      "Current iteration=900, loss=0.3924415852069894\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.39289689897731306\n",
      "Current iteration=100, loss=0.39279744115295456\n",
      "Current iteration=200, loss=0.3927888617989092\n",
      "Current iteration=300, loss=0.3927848364651401\n",
      "Current iteration=400, loss=0.3927827118594349\n",
      "Current iteration=500, loss=0.3927815590694864\n",
      "Current iteration=600, loss=0.3927809287798728\n",
      "Current iteration=700, loss=0.3927805831464201\n",
      "Current iteration=800, loss=0.39278039328041353\n",
      "Current iteration=900, loss=0.392780288846034\n",
      "Current iteration=0, loss=0.39383265109160603\n",
      "Current iteration=100, loss=0.3937753748805586\n",
      "Current iteration=200, loss=0.39377465261871425\n",
      "Current iteration=300, loss=0.39377457088907947\n",
      "Current iteration=400, loss=0.3937745589026228\n",
      "Current iteration=500, loss=0.39377455607385614\n",
      "Current iteration=600, loss=0.393774555000614\n",
      "Current iteration=700, loss=0.39377455449416526\n",
      "Current iteration=800, loss=0.39377455423867913\n",
      "Current iteration=900, loss=0.3937745541069879\n",
      "Current iteration=0, loss=0.3919150062556105\n",
      "Current iteration=100, loss=0.3918078248443666\n",
      "Current iteration=200, loss=0.391799534383033\n",
      "Current iteration=300, loss=0.3917958113135305\n",
      "Current iteration=400, loss=0.3917941098929168\n",
      "Current iteration=500, loss=0.3917933294277872\n",
      "Current iteration=600, loss=0.39179296995039475\n",
      "Current iteration=700, loss=0.39179280357129875\n",
      "Current iteration=800, loss=0.3917927261267521\n",
      "Current iteration=900, loss=0.39179268984433885\n",
      "Current iteration=0, loss=0.3931989921667967\n",
      "Current iteration=100, loss=0.3931102054029449\n",
      "Current iteration=200, loss=0.39310302199885144\n",
      "Current iteration=300, loss=0.3930999243879289\n",
      "Current iteration=400, loss=0.3930983989433582\n",
      "Current iteration=500, loss=0.3930976170346302\n",
      "Current iteration=600, loss=0.3930972101586781\n",
      "Current iteration=700, loss=0.3930969965468828\n",
      "Current iteration=800, loss=0.3930968835986678\n",
      "Current iteration=900, loss=0.3930968234964353\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.3937701821454242\n",
      "Current iteration=100, loss=0.39366681613018134\n",
      "Current iteration=200, loss=0.3936560529487661\n",
      "Current iteration=300, loss=0.3936508489818898\n",
      "Current iteration=400, loss=0.39364811288523877\n",
      "Current iteration=500, loss=0.39364664867128757\n",
      "Current iteration=600, loss=0.3936458618487278\n",
      "Current iteration=700, loss=0.3936454385251726\n",
      "Current iteration=800, loss=0.393645210644141\n",
      "Current iteration=900, loss=0.3936450879254256\n",
      "Current iteration=0, loss=0.3946960352230924\n",
      "Current iteration=100, loss=0.3946387542965126\n",
      "Current iteration=200, loss=0.3946380674393501\n",
      "Current iteration=300, loss=0.39463799561159263\n",
      "Current iteration=400, loss=0.39463798692709395\n",
      "Current iteration=500, loss=0.394637985507847\n",
      "Current iteration=600, loss=0.3946379851266081\n",
      "Current iteration=700, loss=0.39463798497795227\n",
      "Current iteration=800, loss=0.39463798491078433\n",
      "Current iteration=900, loss=0.39463798487896395\n",
      "Current iteration=0, loss=0.3927585093315584\n",
      "Current iteration=100, loss=0.3926518432342577\n",
      "Current iteration=200, loss=0.392643777131628\n",
      "Current iteration=300, loss=0.3926402330233906\n",
      "Current iteration=400, loss=0.3926386498587698\n",
      "Current iteration=500, loss=0.39263794036861105\n",
      "Current iteration=600, loss=0.39263762130235225\n",
      "Current iteration=700, loss=0.39263747721230163\n",
      "Current iteration=800, loss=0.39263741181864964\n",
      "Current iteration=900, loss=0.3926373819708723\n",
      "Current iteration=0, loss=0.39406762985684507\n",
      "Current iteration=100, loss=0.39397941192944375\n",
      "Current iteration=200, loss=0.3939723911090874\n",
      "Current iteration=300, loss=0.3939694571998931\n",
      "Current iteration=400, loss=0.3939680598468753\n",
      "Current iteration=500, loss=0.39396736761867057\n",
      "Current iteration=600, loss=0.39396701955633895\n",
      "Current iteration=700, loss=0.39396684297394197\n",
      "Current iteration=800, loss=0.39396675272740583\n",
      "Current iteration=900, loss=0.39396670629337643\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.3949226473997558\n",
      "Current iteration=100, loss=0.3948112016522972\n",
      "Current iteration=200, loss=0.3947970610562917\n",
      "Current iteration=300, loss=0.3947901512651877\n",
      "Current iteration=400, loss=0.3947865841148853\n",
      "Current iteration=500, loss=0.39478472413470006\n",
      "Current iteration=600, loss=0.3947837528009882\n",
      "Current iteration=700, loss=0.3947832455666889\n",
      "Current iteration=800, loss=0.39478298075621043\n",
      "Current iteration=900, loss=0.3947828425382553\n",
      "Current iteration=0, loss=0.3958328155615678\n",
      "Current iteration=100, loss=0.3957755060109731\n",
      "Current iteration=200, loss=0.3957748520794725\n",
      "Current iteration=300, loss=0.3957747874604382\n",
      "Current iteration=400, loss=0.3957747803721079\n",
      "Current iteration=500, loss=0.3957747794109246\n",
      "Current iteration=600, loss=0.39577477920579823\n",
      "Current iteration=700, loss=0.39577477913646164\n",
      "Current iteration=800, loss=0.3957747791072545\n",
      "Current iteration=900, loss=0.3957747790940434\n",
      "Current iteration=0, loss=0.39386957299044045\n",
      "Current iteration=100, loss=0.39376357963176956\n",
      "Current iteration=200, loss=0.39375582014460536\n",
      "Current iteration=300, loss=0.39375250992052213\n",
      "Current iteration=400, loss=0.3937510757777092\n",
      "Current iteration=500, loss=0.3937504528345634\n",
      "Current iteration=600, loss=0.393750181511386\n",
      "Current iteration=700, loss=0.39375006294281145\n",
      "Current iteration=800, loss=0.39375001092083206\n",
      "Current iteration=900, loss=0.3937499879895001\n",
      "Current iteration=0, loss=0.3952097805288029\n",
      "Current iteration=100, loss=0.3951214948707534\n",
      "Current iteration=200, loss=0.39511464332375845\n",
      "Current iteration=300, loss=0.3951119013592047\n",
      "Current iteration=400, loss=0.3951106532773173\n",
      "Current iteration=500, loss=0.3951100629829928\n",
      "Current iteration=600, loss=0.39510977978101997\n",
      "Current iteration=700, loss=0.3951096427395828\n",
      "Current iteration=800, loss=0.3951095759440448\n",
      "Current iteration=900, loss=0.39510954316358937\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.39642582483646327\n",
      "Current iteration=100, loss=0.39629898984033246\n",
      "Current iteration=200, loss=0.3962798033708397\n",
      "Current iteration=300, loss=0.3962705595670824\n",
      "Current iteration=400, loss=0.3962659553822909\n",
      "Current iteration=500, loss=0.3962636512998069\n",
      "Current iteration=600, loss=0.3962624983484122\n",
      "Current iteration=700, loss=0.39626192184520115\n",
      "Current iteration=800, loss=0.39626163377140333\n",
      "Current iteration=900, loss=0.39626148989511\n",
      "Current iteration=0, loss=0.39731149410288685\n",
      "Current iteration=100, loss=0.39725412848876535\n",
      "Current iteration=200, loss=0.3972534966816004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=300, loss=0.3972534326601422\n",
      "Current iteration=400, loss=0.39725342373103484\n",
      "Current iteration=500, loss=0.3972534215307473\n",
      "Current iteration=600, loss=0.3972534206725019\n",
      "Current iteration=700, loss=0.3972534202775778\n",
      "Current iteration=800, loss=0.3972534200884162\n",
      "Current iteration=900, loss=0.3972534199969643\n",
      "Current iteration=0, loss=0.39531559651701575\n",
      "Current iteration=100, loss=0.39521046132363585\n",
      "Current iteration=200, loss=0.3952031116555143\n",
      "Current iteration=300, loss=0.3952000987985116\n",
      "Current iteration=400, loss=0.3951988458565352\n",
      "Current iteration=500, loss=0.3951983238365756\n",
      "Current iteration=600, loss=0.3951981059505488\n",
      "Current iteration=700, loss=0.39519801479989775\n",
      "Current iteration=800, loss=0.3951979765603831\n",
      "Current iteration=900, loss=0.39519796046418215\n",
      "Current iteration=0, loss=0.3966929002426681\n",
      "Current iteration=100, loss=0.39660312528768665\n",
      "Current iteration=200, loss=0.3965964216530596\n",
      "Current iteration=300, loss=0.39659389042855675\n",
      "Current iteration=400, loss=0.3965928051531176\n",
      "Current iteration=500, loss=0.39659232232374136\n",
      "Current iteration=600, loss=0.396592104724011\n",
      "Current iteration=700, loss=0.3965920059366956\n",
      "Current iteration=800, loss=0.39659196081143305\n",
      "Current iteration=900, loss=0.3965919400736514\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.3983585613830054\n",
      "Current iteration=100, loss=0.39820482736268586\n",
      "Current iteration=200, loss=0.3981785223907546\n",
      "Current iteration=300, loss=0.39816637188440684\n",
      "Current iteration=400, loss=0.3981606527438193\n",
      "Current iteration=500, loss=0.39815795640310137\n",
      "Current iteration=600, loss=0.39815668617551053\n",
      "Current iteration=700, loss=0.39815608829606725\n",
      "Current iteration=800, loss=0.3981558070577745\n",
      "Current iteration=900, loss=0.3981556748194216\n",
      "Current iteration=0, loss=0.3992074124605289\n",
      "Current iteration=100, loss=0.39914998826015263\n",
      "Current iteration=200, loss=0.39914935743718216\n",
      "Current iteration=300, loss=0.3991492834714767\n",
      "Current iteration=400, loss=0.39914926806267864\n",
      "Current iteration=500, loss=0.39914926266777023\n",
      "Current iteration=600, loss=0.39914926034768267\n",
      "Current iteration=700, loss=0.3991492592986402\n",
      "Current iteration=800, loss=0.39914925881921554\n",
      "Current iteration=900, loss=0.39914925859959266\n",
      "Current iteration=0, loss=0.39717098098714165\n",
      "Current iteration=100, loss=0.3970669161485639\n",
      "Current iteration=200, loss=0.39706010132745534\n",
      "Current iteration=300, loss=0.3970574539827\n",
      "Current iteration=400, loss=0.3970564115344275\n",
      "Current iteration=500, loss=0.3970560005884419\n",
      "Current iteration=600, loss=0.39705583845784304\n",
      "Current iteration=700, loss=0.3970557744224902\n",
      "Current iteration=800, loss=0.39705574909395464\n",
      "Current iteration=900, loss=0.39705573905712005\n",
      "Current iteration=0, loss=0.39859037661055086\n",
      "Current iteration=100, loss=0.39849648018944245\n",
      "Current iteration=200, loss=0.3984898655571018\n",
      "Current iteration=300, loss=0.3984875484184311\n",
      "Current iteration=400, loss=0.3984866269960352\n",
      "Current iteration=500, loss=0.39848624734013255\n",
      "Current iteration=600, loss=0.39848608921895434\n",
      "Current iteration=700, loss=0.3984860230468172\n",
      "Current iteration=800, loss=0.3984859952567744\n",
      "Current iteration=900, loss=0.3984859835460837\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.4007982271818677\n",
      "Current iteration=100, loss=0.40060529151425084\n",
      "Current iteration=200, loss=0.40056977886294426\n",
      "Current iteration=300, loss=0.40055452904843797\n",
      "Current iteration=400, loss=0.4005479118343828\n",
      "Current iteration=500, loss=0.40054503926954926\n",
      "Current iteration=600, loss=0.4005437929482438\n",
      "Current iteration=700, loss=0.40054325237305116\n",
      "Current iteration=800, loss=0.4005430179128235\n",
      "Current iteration=900, loss=0.4005429162069079\n",
      "Current iteration=0, loss=0.4015986412574722\n",
      "Current iteration=100, loss=0.40154124648218614\n",
      "Current iteration=200, loss=0.4015405905061257\n",
      "Current iteration=300, loss=0.40154049675448866\n",
      "Current iteration=400, loss=0.40154047187215436\n",
      "Current iteration=500, loss=0.4015404625720171\n",
      "Current iteration=600, loss=0.4015404587343772\n",
      "Current iteration=700, loss=0.40154045711566844\n",
      "Current iteration=800, loss=0.4015404564296261\n",
      "Current iteration=900, loss=0.4015404561385095\n",
      "Current iteration=0, loss=0.39951326426731787\n",
      "Current iteration=100, loss=0.3994105003357658\n",
      "Current iteration=200, loss=0.3994043691721564\n",
      "Current iteration=300, loss=0.39940215330734413\n",
      "Current iteration=400, loss=0.3994013413772482\n",
      "Current iteration=500, loss=0.3994010436856432\n",
      "Current iteration=600, loss=0.39940093455021003\n",
      "Current iteration=700, loss=0.3994008945417607\n",
      "Current iteration=800, loss=0.399400879872575\n",
      "Current iteration=900, loss=0.3994008744923091\n",
      "Current iteration=0, loss=0.4009767693313321\n",
      "Current iteration=100, loss=0.4008747575292365\n",
      "Current iteration=200, loss=0.40086815595736564\n",
      "Current iteration=300, loss=0.40086604455331015\n",
      "Current iteration=400, loss=0.40086527581959674\n",
      "Current iteration=500, loss=0.40086498580757146\n",
      "Current iteration=600, loss=0.40086487537476156\n",
      "Current iteration=700, loss=0.40086483321296795\n",
      "Current iteration=800, loss=0.40086481710197763\n",
      "Current iteration=900, loss=0.40086481094320753\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.4038148772093051\n",
      "Current iteration=100, loss=0.4035737004110602\n",
      "Current iteration=200, loss=0.4035277081363216\n",
      "Current iteration=300, loss=0.4035099718400619\n",
      "Current iteration=400, loss=0.4035030843685439\n",
      "Current iteration=500, loss=0.4035004065376704\n",
      "Current iteration=600, loss=0.40349936431573663\n",
      "Current iteration=700, loss=0.40349895812438646\n",
      "Current iteration=800, loss=0.40349879957320217\n",
      "Current iteration=900, loss=0.40349873758889143\n",
      "Current iteration=0, loss=0.4045605217933825\n",
      "Current iteration=100, loss=0.4045034096238408\n",
      "Current iteration=200, loss=0.40450270992985266\n",
      "Current iteration=300, loss=0.40450259766169877\n",
      "Current iteration=400, loss=0.4045025667700431\n",
      "Current iteration=500, loss=0.4045025559014974\n",
      "Current iteration=600, loss=0.40450255180750655\n",
      "Current iteration=700, loss=0.40450255023958276\n",
      "Current iteration=800, loss=0.4045025496362742\n",
      "Current iteration=900, loss=0.4045025494036721\n",
      "Current iteration=0, loss=0.40241781235014096\n",
      "Current iteration=100, loss=0.40231651894286463\n",
      "Current iteration=200, loss=0.4023112603506833\n",
      "Current iteration=300, loss=0.4023095337821844\n",
      "Current iteration=400, loss=0.40230895622198276\n",
      "Current iteration=500, loss=0.402308762691821\n",
      "Current iteration=600, loss=0.40230869784469026\n",
      "Current iteration=700, loss=0.40230867611867926\n",
      "Current iteration=800, loss=0.40230866883948085\n",
      "Current iteration=900, loss=0.40230866640015245\n",
      "Current iteration=0, loss=0.4039200271368616\n",
      "Current iteration=100, loss=0.4038067753381559\n",
      "Current iteration=200, loss=0.40380026779910316\n",
      "Current iteration=300, loss=0.40379839122380723\n",
      "Current iteration=400, loss=0.40379777083139645\n",
      "Current iteration=500, loss=0.40379755756263147\n",
      "Current iteration=600, loss=0.4037974833839594\n",
      "Current iteration=700, loss=0.4037974574562651\n",
      "Current iteration=800, loss=0.4037974483629228\n",
      "Current iteration=900, loss=0.40379744516324456\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.4074707020961705\n",
      "Current iteration=100, loss=0.4071750287088163\n",
      "Current iteration=200, loss=0.40711908279061115\n",
      "Current iteration=300, loss=0.4071004236913343\n",
      "Current iteration=400, loss=0.4070941409924654\n",
      "Current iteration=500, loss=0.40709201194268274\n",
      "Current iteration=600, loss=0.4070912857298913\n",
      "Current iteration=700, loss=0.40709103637927135\n",
      "Current iteration=800, loss=0.40709095021938735\n",
      "Current iteration=900, loss=0.40709092027438337\n",
      "Current iteration=0, loss=0.40815874257334317\n",
      "Current iteration=100, loss=0.40810226913966646\n",
      "Current iteration=200, loss=0.40810150192894334\n",
      "Current iteration=300, loss=0.4081013878074669\n",
      "Current iteration=400, loss=0.40810136186199464\n",
      "Current iteration=500, loss=0.40810135430289235\n",
      "Current iteration=600, loss=0.4081013518800602\n",
      "Current iteration=700, loss=0.4081013510766409\n",
      "Current iteration=800, loss=0.4081013508060866\n",
      "Current iteration=900, loss=0.40810135071406434\n",
      "Current iteration=0, loss=0.4059501408719165\n",
      "Current iteration=100, loss=0.405850359018399\n",
      "Current iteration=200, loss=0.4058461299718517\n",
      "Current iteration=300, loss=0.40584492597551314\n",
      "Current iteration=400, loss=0.4058445697955933\n",
      "Current iteration=500, loss=0.40584446331549556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.4058444312989224\n",
      "Current iteration=700, loss=0.40584442162053136\n",
      "Current iteration=800, loss=0.4058444186771714\n",
      "Current iteration=900, loss=0.4058444177757736\n",
      "Current iteration=0, loss=0.4074682405750455\n",
      "Current iteration=100, loss=0.4073523598022015\n",
      "Current iteration=200, loss=0.4073467494386579\n",
      "Current iteration=300, loss=0.407345313471939\n",
      "Current iteration=400, loss=0.4073448894982948\n",
      "Current iteration=500, loss=0.4073447587901133\n",
      "Current iteration=600, loss=0.40734471782220566\n",
      "Current iteration=700, loss=0.4073447048471519\n",
      "Current iteration=800, loss=0.4073447006988178\n",
      "Current iteration=900, loss=0.4073446993596162\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.4118178807241236\n",
      "Current iteration=100, loss=0.4114594465912963\n",
      "Current iteration=200, loss=0.41139614580636247\n",
      "Current iteration=300, loss=0.4113785430933869\n",
      "Current iteration=400, loss=0.4113735815863656\n",
      "Current iteration=500, loss=0.4113721637458129\n",
      "Current iteration=600, loss=0.4113717527404063\n",
      "Current iteration=700, loss=0.4113716319262719\n",
      "Current iteration=800, loss=0.4113715959528258\n",
      "Current iteration=900, loss=0.41137158511819344\n",
      "Current iteration=0, loss=0.4124417878272428\n",
      "Current iteration=100, loss=0.4123870668089651\n",
      "Current iteration=200, loss=0.4123863722480465\n",
      "Current iteration=300, loss=0.41238627807822437\n",
      "Current iteration=400, loss=0.4123862595658656\n",
      "Current iteration=500, loss=0.41238625505525706\n",
      "Current iteration=600, loss=0.41238625385369465\n",
      "Current iteration=700, loss=0.41238625352128394\n",
      "Current iteration=800, loss=0.4123862534273456\n",
      "Current iteration=900, loss=0.412386253400371\n",
      "Current iteration=0, loss=0.41016095796648894\n",
      "Current iteration=100, loss=0.4100634518344242\n",
      "Current iteration=200, loss=0.4100601519211047\n",
      "Current iteration=300, loss=0.41005937814200843\n",
      "Current iteration=400, loss=0.410059186568576\n",
      "Current iteration=500, loss=0.41005913822665185\n",
      "Current iteration=600, loss=0.41005912587041865\n",
      "Current iteration=700, loss=0.41005912267170624\n",
      "Current iteration=800, loss=0.41005912183189924\n",
      "Current iteration=900, loss=0.4100591216079381\n",
      "Current iteration=0, loss=0.4116730351203117\n",
      "Current iteration=100, loss=0.4115636959103605\n",
      "Current iteration=200, loss=0.4115595322354021\n",
      "Current iteration=300, loss=0.41155861681009165\n",
      "Current iteration=400, loss=0.4115583834336981\n",
      "Current iteration=500, loss=0.4115583210554367\n",
      "Current iteration=600, loss=0.4115583040091245\n",
      "Current iteration=700, loss=0.411558299272845\n",
      "Current iteration=800, loss=0.4115582979364642\n",
      "Current iteration=900, loss=0.411558297553717\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.41690127602161303\n",
      "Current iteration=100, loss=0.41646647521540314\n",
      "Current iteration=200, loss=0.4164020234266521\n",
      "Current iteration=300, loss=0.4163879577710524\n",
      "Current iteration=400, loss=0.4163848334891572\n",
      "Current iteration=500, loss=0.41638412475494485\n",
      "Current iteration=600, loss=0.41638396040881537\n",
      "Current iteration=700, loss=0.41638392149328346\n",
      "Current iteration=800, loss=0.41638391210442216\n",
      "Current iteration=900, loss=0.41638390980265294\n",
      "Current iteration=0, loss=0.41745342445386424\n",
      "Current iteration=100, loss=0.4174014660373833\n",
      "Current iteration=200, loss=0.41740093210848095\n",
      "Current iteration=300, loss=0.4174008683442814\n",
      "Current iteration=400, loss=0.41740085767187207\n",
      "Current iteration=500, loss=0.41740085554136114\n",
      "Current iteration=600, loss=0.41740085508264174\n",
      "Current iteration=700, loss=0.41740085498009355\n",
      "Current iteration=800, loss=0.4174008549565124\n",
      "Current iteration=900, loss=0.4174008549510007\n",
      "Current iteration=0, loss=0.4150986384987338\n",
      "Current iteration=100, loss=0.41500376483624773\n",
      "Current iteration=200, loss=0.41500135678806027\n",
      "Current iteration=300, loss=0.41500091841794545\n",
      "Current iteration=400, loss=0.4150008324177059\n",
      "Current iteration=500, loss=0.41500081501653596\n",
      "Current iteration=600, loss=0.4150008114120648\n",
      "Current iteration=700, loss=0.4150008106475549\n",
      "Current iteration=800, loss=0.4150008104812844\n",
      "Current iteration=900, loss=0.41500081044417536\n",
      "Current iteration=0, loss=0.41658971267970085\n",
      "Current iteration=100, loss=0.41648798170343176\n",
      "Current iteration=200, loss=0.4164851573975365\n",
      "Current iteration=300, loss=0.4164846475785081\n",
      "Current iteration=400, loss=0.41648454003138863\n",
      "Current iteration=500, loss=0.4164845161111987\n",
      "Current iteration=600, loss=0.4164845106370955\n",
      "Current iteration=700, loss=0.41648450935621495\n",
      "Current iteration=800, loss=0.4164845090506692\n",
      "Current iteration=900, loss=0.4164845089765254\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.4227660756945713\n",
      "Current iteration=100, loss=0.4222437989651575\n",
      "Current iteration=200, loss=0.4221867121811553\n",
      "Current iteration=300, loss=0.4221776941508897\n",
      "Current iteration=400, loss=0.4221762285840934\n",
      "Current iteration=500, loss=0.4221759824865959\n",
      "Current iteration=600, loss=0.4221759397773323\n",
      "Current iteration=700, loss=0.42217593213901405\n",
      "Current iteration=800, loss=0.4221759307370892\n",
      "Current iteration=900, loss=0.42217593047454643\n",
      "Current iteration=0, loss=0.4232408328951728\n",
      "Current iteration=100, loss=0.4231921774745136\n",
      "Current iteration=200, loss=0.4231918080649013\n",
      "Current iteration=300, loss=0.42319177261160185\n",
      "Current iteration=400, loss=0.4231917680214269\n",
      "Current iteration=500, loss=0.4231917673309322\n",
      "Current iteration=600, loss=0.42319176721940427\n",
      "Current iteration=700, loss=0.4231917672005457\n",
      "Current iteration=800, loss=0.4231917671972165\n",
      "Current iteration=900, loss=0.4231917671966759\n",
      "Current iteration=0, loss=0.42081393127790867\n",
      "Current iteration=100, loss=0.4207219240057058\n",
      "Current iteration=200, loss=0.42072032198542897\n",
      "Current iteration=300, loss=0.4207201130374475\n",
      "Current iteration=400, loss=0.4207200828598319\n",
      "Current iteration=500, loss=0.4207200782883666\n",
      "Current iteration=600, loss=0.42072007756852164\n",
      "Current iteration=700, loss=0.4207200774507669\n",
      "Current iteration=800, loss=0.42072007743076956\n",
      "Current iteration=900, loss=0.4207200774272536\n",
      "Current iteration=0, loss=0.4222678960917936\n",
      "Current iteration=100, loss=0.42217409839091086\n",
      "Current iteration=200, loss=0.42217236714809386\n",
      "Current iteration=300, loss=0.4221721255552621\n",
      "Current iteration=400, loss=0.4221720858320015\n",
      "Current iteration=500, loss=0.42217207891088404\n",
      "Current iteration=600, loss=0.4221720776646475\n",
      "Current iteration=700, loss=0.4221720774346664\n",
      "Current iteration=800, loss=0.4221720773914638\n",
      "Current iteration=900, loss=0.42217207738314166\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.42946870557330424\n",
      "Current iteration=100, loss=0.42885399738779295\n",
      "Current iteration=200, loss=0.4288115065859789\n",
      "Current iteration=300, loss=0.4288071418625687\n",
      "Current iteration=400, loss=0.42880667233250014\n",
      "Current iteration=500, loss=0.42880661923564856\n",
      "Current iteration=600, loss=0.4288066129367027\n",
      "Current iteration=700, loss=0.42880661215759414\n",
      "Current iteration=800, loss=0.4288066120583333\n",
      "Current iteration=900, loss=0.42880661204519754\n",
      "Current iteration=0, loss=0.4298611444342298\n",
      "Current iteration=100, loss=0.4298161504026435\n",
      "Current iteration=200, loss=0.4298159270317809\n",
      "Current iteration=300, loss=0.4298159117590667\n",
      "Current iteration=400, loss=0.4298159103945156\n",
      "Current iteration=500, loss=0.42981591025463034\n",
      "Current iteration=600, loss=0.42981591023915117\n",
      "Current iteration=700, loss=0.4298159102371789\n",
      "Current iteration=800, loss=0.42981591023705634\n",
      "Current iteration=900, loss=0.4298159102370167\n",
      "Current iteration=0, loss=0.42736844897295856\n",
      "Current iteration=100, loss=0.42727971483831917\n",
      "Current iteration=200, loss=0.42727878152206494\n",
      "Current iteration=300, loss=0.4272787032318639\n",
      "Current iteration=400, loss=0.42727869570082433\n",
      "Current iteration=500, loss=0.4272786949231163\n",
      "Current iteration=600, loss=0.4272786948379109\n",
      "Current iteration=700, loss=0.4272786948280513\n",
      "Current iteration=800, loss=0.4272786948268542\n",
      "Current iteration=900, loss=0.4272786948267031\n",
      "Current iteration=0, loss=0.42876981135190423\n",
      "Current iteration=100, loss=0.42868403608331895\n",
      "Current iteration=200, loss=0.428683098684685\n",
      "Current iteration=300, loss=0.42868300582409724\n",
      "Current iteration=400, loss=0.4286829949299784\n",
      "Current iteration=500, loss=0.4286829935731371\n",
      "Current iteration=600, loss=0.4286829933983548\n",
      "Current iteration=700, loss=0.42868299337524635\n",
      "Current iteration=800, loss=0.4286829933722681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=900, loss=0.4286829933717862\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.4370886260546498\n",
      "Current iteration=100, loss=0.436382667914021\n",
      "Current iteration=200, loss=0.4363572406321052\n",
      "Current iteration=300, loss=0.4363557702370481\n",
      "Current iteration=400, loss=0.43635567876632486\n",
      "Current iteration=500, loss=0.43635567263736946\n",
      "Current iteration=600, loss=0.43635567219814425\n",
      "Current iteration=700, loss=0.43635567216543486\n",
      "Current iteration=800, loss=0.4363556721624432\n",
      "Current iteration=900, loss=0.4363556721620416\n",
      "Current iteration=0, loss=0.4373914681279342\n",
      "Current iteration=100, loss=0.4373503989008575\n",
      "Current iteration=200, loss=0.43735028749586385\n",
      "Current iteration=300, loss=0.43735028286160027\n",
      "Current iteration=400, loss=0.4373502826131213\n",
      "Current iteration=500, loss=0.43735028259769954\n",
      "Current iteration=600, loss=0.4373502825966933\n",
      "Current iteration=700, loss=0.4373502825969068\n",
      "Current iteration=800, loss=0.4373502825967796\n",
      "Current iteration=900, loss=0.4373502825965798\n",
      "Current iteration=0, loss=0.4348455062217473\n",
      "Current iteration=100, loss=0.43476073691355627\n",
      "Current iteration=200, loss=0.43476028723734517\n",
      "Current iteration=300, loss=0.43476026621681474\n",
      "Current iteration=400, loss=0.4347602650376526\n",
      "Current iteration=500, loss=0.4347602649643787\n",
      "Current iteration=600, loss=0.434760264959428\n",
      "Current iteration=700, loss=0.4347602649590694\n",
      "Current iteration=800, loss=0.434760264959042\n",
      "Current iteration=900, loss=0.4347602649590399\n",
      "Current iteration=0, loss=0.4361810850994346\n",
      "Current iteration=100, loss=0.436103280324838\n",
      "Current iteration=200, loss=0.43610284582492964\n",
      "Current iteration=300, loss=0.4361028188382847\n",
      "Current iteration=400, loss=0.436102816854828\n",
      "Current iteration=500, loss=0.43610281670020484\n",
      "Current iteration=600, loss=0.4361028166881014\n",
      "Current iteration=700, loss=0.4361028166868486\n",
      "Current iteration=800, loss=0.43610281668683415\n",
      "Current iteration=900, loss=0.43610281668685386\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.4457352173371375\n",
      "Current iteration=100, loss=0.4449408032648257\n",
      "Current iteration=200, loss=0.4449291597329648\n",
      "Current iteration=300, loss=0.44492884593736653\n",
      "Current iteration=400, loss=0.44492883650183723\n",
      "Current iteration=500, loss=0.44492883618674856\n",
      "Current iteration=600, loss=0.44492883617520396\n",
      "Current iteration=700, loss=0.44492883617471846\n",
      "Current iteration=800, loss=0.44492883617497975\n",
      "Current iteration=900, loss=0.44492883617517853\n",
      "Current iteration=0, loss=0.4459346400058989\n",
      "Current iteration=100, loss=0.44589759598808343\n",
      "Current iteration=200, loss=0.44589755263330066\n",
      "Current iteration=300, loss=0.4458975517342168\n",
      "Current iteration=400, loss=0.4458975517101915\n",
      "Current iteration=500, loss=0.44589755170926904\n",
      "Current iteration=600, loss=0.44589755170925904\n",
      "Current iteration=700, loss=0.44589755170933043\n",
      "Current iteration=800, loss=0.4458975517093765\n",
      "Current iteration=900, loss=0.44589755170936984\n",
      "Current iteration=0, loss=0.4433554749334733\n",
      "Current iteration=100, loss=0.44327550144392236\n",
      "Current iteration=200, loss=0.4432753326617532\n",
      "Current iteration=300, loss=0.4432753290162644\n",
      "Current iteration=400, loss=0.4432753289163674\n",
      "Current iteration=500, loss=0.4432753289132192\n",
      "Current iteration=600, loss=0.44327532891310883\n",
      "Current iteration=700, loss=0.44327532891310456\n",
      "Current iteration=800, loss=0.4432753289131045\n",
      "Current iteration=900, loss=0.44327532891310445\n",
      "Current iteration=0, loss=0.44461533427129885\n",
      "Current iteration=100, loss=0.44454537563254937\n",
      "Current iteration=200, loss=0.4445452104252042\n",
      "Current iteration=300, loss=0.44454520505409134\n",
      "Current iteration=400, loss=0.44454520484894255\n",
      "Current iteration=500, loss=0.4445452048408439\n",
      "Current iteration=600, loss=0.4445452048406363\n",
      "Current iteration=700, loss=0.4445452048405399\n",
      "Current iteration=800, loss=0.4445452048405263\n",
      "Current iteration=900, loss=0.44454520484049037\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.45554233519011095\n",
      "Current iteration=100, loss=0.4546568458767002\n",
      "Current iteration=200, loss=0.4546529933178665\n",
      "Current iteration=300, loss=0.45465295568516995\n",
      "Current iteration=400, loss=0.45465295525696675\n",
      "Current iteration=500, loss=0.4546529552514223\n",
      "Current iteration=600, loss=0.45465295525127875\n",
      "Current iteration=700, loss=0.45465295525128874\n",
      "Current iteration=800, loss=0.45465295525147387\n",
      "Current iteration=900, loss=0.45465295525145966\n",
      "Current iteration=0, loss=0.45561560686188174\n",
      "Current iteration=100, loss=0.4555824952947595\n",
      "Current iteration=200, loss=0.4555824826268495\n",
      "Current iteration=300, loss=0.45558248252503986\n",
      "Current iteration=400, loss=0.4555824825238911\n",
      "Current iteration=500, loss=0.4555824825238578\n",
      "Current iteration=600, loss=0.45558248252405226\n",
      "Current iteration=700, loss=0.45558248252391187\n",
      "Current iteration=800, loss=0.4555824825240621\n",
      "Current iteration=900, loss=0.45558248252385414\n",
      "Current iteration=0, loss=0.45303042351143086\n",
      "Current iteration=100, loss=0.45295600976423084\n",
      "Current iteration=200, loss=0.45295596318621506\n",
      "Current iteration=300, loss=0.4529559628241061\n",
      "Current iteration=400, loss=0.4529559628203182\n",
      "Current iteration=500, loss=0.45295596282027084\n",
      "Current iteration=600, loss=0.4529559628202701\n",
      "Current iteration=700, loss=0.45295596282027023\n",
      "Current iteration=800, loss=0.4529559628202701\n",
      "Current iteration=900, loss=0.45295596282027023\n",
      "Current iteration=0, loss=0.45420833591947807\n",
      "Current iteration=100, loss=0.4541460759705288\n",
      "Current iteration=200, loss=0.4541460275844263\n",
      "Current iteration=300, loss=0.4541460269477235\n",
      "Current iteration=400, loss=0.4541460269380005\n",
      "Current iteration=500, loss=0.45414602693798245\n",
      "Current iteration=600, loss=0.4541460269378581\n",
      "Current iteration=700, loss=0.45414602693794304\n",
      "Current iteration=800, loss=0.4541460269379338\n",
      "Current iteration=900, loss=0.4541460269379026\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.46664893523019735\n",
      "Current iteration=100, loss=0.4656607914729563\n",
      "Current iteration=200, loss=0.4656599467827487\n",
      "Current iteration=300, loss=0.4656599446721214\n",
      "Current iteration=400, loss=0.46565994466570687\n",
      "Current iteration=500, loss=0.4656599446656591\n",
      "Current iteration=600, loss=0.46565994466575\n",
      "Current iteration=700, loss=0.4656599446656329\n",
      "Current iteration=800, loss=0.4656599446657577\n",
      "Current iteration=900, loss=0.4656599446657564\n",
      "Current iteration=0, loss=0.46656600057103476\n",
      "Current iteration=100, loss=0.46653665613914724\n",
      "Current iteration=200, loss=0.46653665353009216\n",
      "Current iteration=300, loss=0.4665366535243838\n",
      "Current iteration=400, loss=0.46653665352431883\n",
      "Current iteration=500, loss=0.46653665352429696\n",
      "Current iteration=600, loss=0.4665366535243436\n",
      "Current iteration=700, loss=0.4665366535243642\n",
      "Current iteration=800, loss=0.46653665352436524\n",
      "Current iteration=900, loss=0.46653665352436535\n",
      "Current iteration=0, loss=0.46400719359226544\n",
      "Current iteration=100, loss=0.4639389655652767\n",
      "Current iteration=200, loss=0.4639389568159437\n",
      "Current iteration=300, loss=0.4639389567985917\n",
      "Current iteration=400, loss=0.4639389567985427\n",
      "Current iteration=500, loss=0.4639389567985426\n",
      "Current iteration=600, loss=0.46393895679854263\n",
      "Current iteration=700, loss=0.46393895679854263\n",
      "Current iteration=800, loss=0.4639389567985426\n",
      "Current iteration=900, loss=0.4639389567985426\n",
      "Current iteration=0, loss=0.46510061606993514\n",
      "Current iteration=100, loss=0.46504589426094073\n",
      "Current iteration=200, loss=0.4650458843088026\n",
      "Current iteration=300, loss=0.46504588427165594\n",
      "Current iteration=400, loss=0.4650458842715541\n",
      "Current iteration=500, loss=0.46504588427155563\n",
      "Current iteration=600, loss=0.4650458842715139\n",
      "Current iteration=700, loss=0.4650458842715976\n",
      "Current iteration=800, loss=0.46504588427159577\n",
      "Current iteration=900, loss=0.46504588427159554\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.47916921016045544\n",
      "Current iteration=100, loss=0.4780603807533296\n",
      "Current iteration=200, loss=0.47806027328004796\n",
      "Current iteration=300, loss=0.4780602732378276\n",
      "Current iteration=400, loss=0.478060273237809\n",
      "Current iteration=500, loss=0.47806027323780725\n",
      "Current iteration=600, loss=0.47806027323780237\n",
      "Current iteration=700, loss=0.478060273237801\n",
      "Current iteration=800, loss=0.4780602732378011\n",
      "Current iteration=900, loss=0.4780602732378011\n",
      "Current iteration=0, loss=0.4788973089508256\n",
      "Current iteration=100, loss=0.4788715877849676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=200, loss=0.4788715874524133\n",
      "Current iteration=300, loss=0.478871587452272\n",
      "Current iteration=400, loss=0.47887158745227987\n",
      "Current iteration=500, loss=0.47887158745224395\n",
      "Current iteration=600, loss=0.47887158745224706\n",
      "Current iteration=700, loss=0.4788715874522471\n",
      "Current iteration=800, loss=0.4788715874522472\n",
      "Current iteration=900, loss=0.4788715874522472\n",
      "Current iteration=0, loss=0.4764000668192174\n",
      "Current iteration=100, loss=0.47633851276717304\n",
      "Current iteration=200, loss=0.47633851177624914\n",
      "Current iteration=300, loss=0.4763385117759388\n",
      "Current iteration=400, loss=0.47633851177593867\n",
      "Current iteration=500, loss=0.4763385117759386\n",
      "Current iteration=600, loss=0.47633851177593867\n",
      "Current iteration=700, loss=0.4763385117759386\n",
      "Current iteration=800, loss=0.4763385117759386\n",
      "Current iteration=900, loss=0.4763385117759386\n",
      "Current iteration=0, loss=0.47740952338710485\n",
      "Current iteration=100, loss=0.4773621398711026\n",
      "Current iteration=200, loss=0.47736213861204657\n",
      "Current iteration=300, loss=0.47736213861126137\n",
      "Current iteration=400, loss=0.4773621386112366\n",
      "Current iteration=500, loss=0.4773621386112399\n",
      "Current iteration=600, loss=0.4773621386112374\n",
      "Current iteration=700, loss=0.47736213861123733\n",
      "Current iteration=800, loss=0.47736213861123716\n",
      "Current iteration=900, loss=0.47736213861123716\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.49315453056762915\n",
      "Current iteration=100, loss=0.49190828906096024\n",
      "Current iteration=200, loss=0.49190828250366475\n",
      "Current iteration=300, loss=0.4919082825034688\n",
      "Current iteration=400, loss=0.49190828250346\n",
      "Current iteration=500, loss=0.4919082825034645\n",
      "Current iteration=600, loss=0.49190828250346436\n",
      "Current iteration=700, loss=0.49190828250346436\n",
      "Current iteration=800, loss=0.49190828250346436\n",
      "Current iteration=900, loss=0.49190828250346436\n",
      "Current iteration=0, loss=0.49266572420312876\n",
      "Current iteration=100, loss=0.49264349834725424\n",
      "Current iteration=200, loss=0.4926434983259458\n",
      "Current iteration=300, loss=0.49264349832594145\n",
      "Current iteration=400, loss=0.4926434983259463\n",
      "Current iteration=500, loss=0.4926434983259469\n",
      "Current iteration=600, loss=0.49264349832594706\n",
      "Current iteration=700, loss=0.49264349832594706\n",
      "Current iteration=800, loss=0.49264349832594706\n",
      "Current iteration=900, loss=0.49264349832594706\n",
      "Current iteration=0, loss=0.4902655744341713\n",
      "Current iteration=100, loss=0.4902110477095223\n",
      "Current iteration=200, loss=0.49021104765325585\n",
      "Current iteration=300, loss=0.4902110476532546\n",
      "Current iteration=400, loss=0.4902110476532546\n",
      "Current iteration=500, loss=0.4902110476532546\n",
      "Current iteration=600, loss=0.4902110476532546\n",
      "Current iteration=700, loss=0.4902110476532546\n",
      "Current iteration=800, loss=0.4902110476532546\n",
      "Current iteration=900, loss=0.4902110476532546\n",
      "Current iteration=0, loss=0.4911936246908802\n",
      "Current iteration=100, loss=0.4911533116440474\n",
      "Current iteration=200, loss=0.49115331156324665\n",
      "Current iteration=300, loss=0.4911533115632472\n",
      "Current iteration=400, loss=0.4911533115632324\n",
      "Current iteration=500, loss=0.49115331156323216\n",
      "Current iteration=600, loss=0.4911533115632321\n",
      "Current iteration=700, loss=0.4911533115632321\n",
      "Current iteration=800, loss=0.4911533115632321\n",
      "Current iteration=900, loss=0.4911533115632321\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.5085530743176522\n",
      "Current iteration=100, loss=0.5071655408263361\n",
      "Current iteration=200, loss=0.5071655406803594\n",
      "Current iteration=300, loss=0.5071655406803578\n",
      "Current iteration=400, loss=0.5071655406803594\n",
      "Current iteration=500, loss=0.5071655406803592\n",
      "Current iteration=600, loss=0.5071655406803592\n",
      "Current iteration=700, loss=0.5071655406803592\n",
      "Current iteration=800, loss=0.5071655406803592\n",
      "Current iteration=900, loss=0.5071655406803592\n",
      "Current iteration=0, loss=0.507835257476872\n",
      "Current iteration=100, loss=0.5078163825006308\n",
      "Current iteration=200, loss=0.5078163825001246\n",
      "Current iteration=300, loss=0.50781638250012\n",
      "Current iteration=400, loss=0.5078163825001205\n",
      "Current iteration=500, loss=0.5078163825001205\n",
      "Current iteration=600, loss=0.5078163825001205\n",
      "Current iteration=700, loss=0.5078163825001205\n",
      "Current iteration=800, loss=0.5078163825001205\n",
      "Current iteration=900, loss=0.5078163825001205\n",
      "Current iteration=0, loss=0.5055657983527637\n",
      "Current iteration=100, loss=0.5055185245265993\n",
      "Current iteration=200, loss=0.5055185245253814\n",
      "Current iteration=300, loss=0.5055185245253814\n",
      "Current iteration=400, loss=0.5055185245253814\n",
      "Current iteration=500, loss=0.5055185245253814\n",
      "Current iteration=600, loss=0.5055185245253814\n",
      "Current iteration=700, loss=0.5055185245253814\n",
      "Current iteration=800, loss=0.5055185245253814\n",
      "Current iteration=900, loss=0.5055185245253814\n",
      "Current iteration=0, loss=0.5064159136719688\n",
      "Current iteration=100, loss=0.5063823274748368\n",
      "Current iteration=200, loss=0.5063823274728542\n",
      "Current iteration=300, loss=0.5063823274728553\n",
      "Current iteration=400, loss=0.5063823274728554\n",
      "Current iteration=500, loss=0.5063823274728554\n",
      "Current iteration=600, loss=0.5063823274728554\n",
      "Current iteration=700, loss=0.5063823274728554\n",
      "Current iteration=800, loss=0.5063823274728554\n",
      "Current iteration=900, loss=0.5063823274728554\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.52517833588018\n",
      "Current iteration=100, loss=0.5236714736780688\n",
      "Current iteration=200, loss=0.5236714736772736\n",
      "Current iteration=300, loss=0.5236714736772735\n",
      "Current iteration=400, loss=0.5236714736772734\n",
      "Current iteration=500, loss=0.5236714736772734\n",
      "Current iteration=600, loss=0.5236714736772734\n",
      "Current iteration=700, loss=0.5236714736772734\n",
      "Current iteration=800, loss=0.5236714736772734\n",
      "Current iteration=900, loss=0.5236714736772734\n",
      "Current iteration=0, loss=0.5242482702954874\n",
      "Current iteration=100, loss=0.5242325761638947\n",
      "Current iteration=200, loss=0.5242325761638924\n",
      "Current iteration=300, loss=0.5242325761638911\n",
      "Current iteration=400, loss=0.5242325761638912\n",
      "Current iteration=500, loss=0.5242325761638912\n",
      "Current iteration=600, loss=0.5242325761638912\n",
      "Current iteration=700, loss=0.5242325761638912\n",
      "Current iteration=800, loss=0.5242325761638912\n",
      "Current iteration=900, loss=0.5242325761638912\n",
      "Current iteration=0, loss=0.5221393520831812\n",
      "Current iteration=100, loss=0.5220994459764169\n",
      "Current iteration=200, loss=0.5220994459764102\n",
      "Current iteration=300, loss=0.5220994459764102\n",
      "Current iteration=400, loss=0.5220994459764102\n",
      "Current iteration=500, loss=0.5220994459764102\n",
      "Current iteration=600, loss=0.5220994459764102\n",
      "Current iteration=700, loss=0.5220994459764102\n",
      "Current iteration=800, loss=0.5220994459764102\n",
      "Current iteration=900, loss=0.5220994459764102\n",
      "Current iteration=0, loss=0.5229149062267\n",
      "Current iteration=100, loss=0.5228876424716271\n",
      "Current iteration=200, loss=0.5228876424716151\n",
      "Current iteration=300, loss=0.5228876424716153\n",
      "Current iteration=400, loss=0.5228876424716153\n",
      "Current iteration=500, loss=0.5228876424716153\n",
      "Current iteration=600, loss=0.5228876424716153\n",
      "Current iteration=700, loss=0.5228876424716153\n",
      "Current iteration=800, loss=0.5228876424716153\n",
      "Current iteration=900, loss=0.5228876424716153\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.5426979521782345\n",
      "Current iteration=100, loss=0.5411306930326533\n",
      "Current iteration=200, loss=0.5411306930326525\n",
      "Current iteration=300, loss=0.5411306930326524\n",
      "Current iteration=400, loss=0.5411306930326524\n",
      "Current iteration=500, loss=0.5411306930326524\n",
      "Current iteration=600, loss=0.5411306930326524\n",
      "Current iteration=700, loss=0.5411306930326524\n",
      "Current iteration=800, loss=0.5411306930326524\n",
      "Current iteration=900, loss=0.5411306930326524\n",
      "Current iteration=0, loss=0.5416126942297836\n",
      "Current iteration=100, loss=0.5416000006789816\n",
      "Current iteration=200, loss=0.5416000006789813\n",
      "Current iteration=300, loss=0.5416000006789813\n",
      "Current iteration=400, loss=0.5416000006789813\n",
      "Current iteration=500, loss=0.5416000006789813\n",
      "Current iteration=600, loss=0.5416000006789813\n",
      "Current iteration=700, loss=0.5416000006789813\n",
      "Current iteration=800, loss=0.5416000006789813\n",
      "Current iteration=900, loss=0.5416000006789813\n",
      "Current iteration=0, loss=0.5396891182151166\n",
      "Current iteration=100, loss=0.5396565981222317\n",
      "Current iteration=200, loss=0.5396565981222317\n",
      "Current iteration=300, loss=0.5396565981222317\n",
      "Current iteration=400, loss=0.5396565981222317\n",
      "Current iteration=500, loss=0.5396565981222317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.5396565981222317\n",
      "Current iteration=700, loss=0.5396565981222317\n",
      "Current iteration=800, loss=0.5396565981222317\n",
      "Current iteration=900, loss=0.5396565981222317\n",
      "Current iteration=0, loss=0.5403925908154686\n",
      "Current iteration=100, loss=0.5403712048953342\n",
      "Current iteration=200, loss=0.5403712048953344\n",
      "Current iteration=300, loss=0.5403712048953344\n",
      "Current iteration=400, loss=0.5403712048953344\n",
      "Current iteration=500, loss=0.5403712048953344\n",
      "Current iteration=600, loss=0.5403712048953344\n",
      "Current iteration=700, loss=0.5403712048953344\n",
      "Current iteration=800, loss=0.5403712048953344\n",
      "Current iteration=900, loss=0.5403712048953344\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.5606512732487148\n",
      "Current iteration=100, loss=0.5591237639114739\n",
      "Current iteration=200, loss=0.559123763911474\n",
      "Current iteration=300, loss=0.559123763911474\n",
      "Current iteration=400, loss=0.559123763911474\n",
      "Current iteration=500, loss=0.559123763911474\n",
      "Current iteration=600, loss=0.559123763911474\n",
      "Current iteration=700, loss=0.559123763911474\n",
      "Current iteration=800, loss=0.559123763911474\n",
      "Current iteration=900, loss=0.559123763911474\n",
      "Current iteration=0, loss=0.5595126306527332\n",
      "Current iteration=100, loss=0.5595027647584985\n",
      "Current iteration=200, loss=0.5595027647584987\n",
      "Current iteration=300, loss=0.5595027647584987\n",
      "Current iteration=400, loss=0.5595027647584987\n",
      "Current iteration=500, loss=0.5595027647584987\n",
      "Current iteration=600, loss=0.5595027647584987\n",
      "Current iteration=700, loss=0.5595027647584987\n",
      "Current iteration=800, loss=0.5595027647584987\n",
      "Current iteration=900, loss=0.5595027647584987\n",
      "Current iteration=0, loss=0.5577931435039761\n",
      "Current iteration=100, loss=0.5577679183381886\n",
      "Current iteration=200, loss=0.5577679183381887\n",
      "Current iteration=300, loss=0.5577679183381887\n",
      "Current iteration=400, loss=0.5577679183381887\n",
      "Current iteration=500, loss=0.5577679183381887\n",
      "Current iteration=600, loss=0.5577679183381887\n",
      "Current iteration=700, loss=0.5577679183381887\n",
      "Current iteration=800, loss=0.5577679183381887\n",
      "Current iteration=900, loss=0.5577679183381887\n",
      "Current iteration=0, loss=0.5584256724899556\n",
      "Current iteration=100, loss=0.5584096832250218\n",
      "Current iteration=200, loss=0.5584096832250216\n",
      "Current iteration=300, loss=0.5584096832250216\n",
      "Current iteration=400, loss=0.5584096832250216\n",
      "Current iteration=500, loss=0.5584096832250216\n",
      "Current iteration=600, loss=0.5584096832250216\n",
      "Current iteration=700, loss=0.5584096832250216\n",
      "Current iteration=800, loss=0.5584096832250216\n",
      "Current iteration=900, loss=0.5584096832250216\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.5784980735736456\n",
      "Current iteration=100, loss=0.5771428340928982\n",
      "Current iteration=200, loss=0.5771428340928981\n",
      "Current iteration=300, loss=0.5771428340928981\n",
      "Current iteration=400, loss=0.5771428340928981\n",
      "Current iteration=500, loss=0.5771428340928981\n",
      "Current iteration=600, loss=0.5771428340928981\n",
      "Current iteration=700, loss=0.5771428340928981\n",
      "Current iteration=800, loss=0.5771428340928981\n",
      "Current iteration=900, loss=0.5771428340928981\n",
      "Current iteration=0, loss=0.5774437573375207\n",
      "Current iteration=100, loss=0.577436549507121\n",
      "Current iteration=200, loss=0.577436549507121\n",
      "Current iteration=300, loss=0.577436549507121\n",
      "Current iteration=400, loss=0.577436549507121\n",
      "Current iteration=500, loss=0.577436549507121\n",
      "Current iteration=600, loss=0.577436549507121\n",
      "Current iteration=700, loss=0.577436549507121\n",
      "Current iteration=800, loss=0.577436549507121\n",
      "Current iteration=900, loss=0.577436549507121\n",
      "Current iteration=0, loss=0.5759400726154034\n",
      "Current iteration=100, loss=0.5759218839902269\n",
      "Current iteration=200, loss=0.5759218839902268\n",
      "Current iteration=300, loss=0.5759218839902268\n",
      "Current iteration=400, loss=0.5759218839902268\n",
      "Current iteration=500, loss=0.5759218839902268\n",
      "Current iteration=600, loss=0.5759218839902268\n",
      "Current iteration=700, loss=0.5759218839902268\n",
      "Current iteration=800, loss=0.5759218839902268\n",
      "Current iteration=900, loss=0.5759218839902268\n",
      "Current iteration=0, loss=0.5765015464733756\n",
      "Current iteration=100, loss=0.5764904114472368\n",
      "Current iteration=200, loss=0.5764904114472367\n",
      "Current iteration=300, loss=0.5764904114472367\n",
      "Current iteration=400, loss=0.5764904114472367\n",
      "Current iteration=500, loss=0.5764904114472367\n",
      "Current iteration=600, loss=0.5764904114472367\n",
      "Current iteration=700, loss=0.5764904114472367\n",
      "Current iteration=800, loss=0.5764904114472367\n",
      "Current iteration=900, loss=0.5764904114472367\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.5956919344755058\n",
      "Current iteration=100, loss=0.5946466157316677\n",
      "Current iteration=200, loss=0.5946466157316677\n",
      "Current iteration=300, loss=0.5946466157316677\n",
      "Current iteration=400, loss=0.5946466157316677\n",
      "Current iteration=500, loss=0.5946466157316677\n",
      "Current iteration=600, loss=0.5946466157316677\n",
      "Current iteration=700, loss=0.5946466157316677\n",
      "Current iteration=800, loss=0.5946466157316677\n",
      "Current iteration=900, loss=0.5946466157316677\n",
      "Current iteration=0, loss=0.5948680525475282\n",
      "Current iteration=100, loss=0.5948632983716123\n",
      "Current iteration=200, loss=0.5948632983716123\n",
      "Current iteration=300, loss=0.5948632983716123\n",
      "Current iteration=400, loss=0.5948632983716123\n",
      "Current iteration=500, loss=0.5948632983716123\n",
      "Current iteration=600, loss=0.5948632983716123\n",
      "Current iteration=700, loss=0.5948632983716123\n",
      "Current iteration=800, loss=0.5948632983716123\n",
      "Current iteration=900, loss=0.5948632983716123\n",
      "Current iteration=0, loss=0.5935838829478984\n",
      "Current iteration=100, loss=0.5935721988471154\n",
      "Current iteration=200, loss=0.5935721988471154\n",
      "Current iteration=300, loss=0.5935721988471154\n",
      "Current iteration=400, loss=0.5935721988471154\n",
      "Current iteration=500, loss=0.5935721988471154\n",
      "Current iteration=600, loss=0.5935721988471154\n",
      "Current iteration=700, loss=0.5935721988471154\n",
      "Current iteration=800, loss=0.5935721988471154\n",
      "Current iteration=900, loss=0.5935721988471154\n",
      "Current iteration=0, loss=0.5940736620397884\n",
      "Current iteration=100, loss=0.5940667285590723\n",
      "Current iteration=200, loss=0.5940667285590723\n",
      "Current iteration=300, loss=0.5940667285590723\n",
      "Current iteration=400, loss=0.5940667285590723\n",
      "Current iteration=500, loss=0.5940667285590723\n",
      "Current iteration=600, loss=0.5940667285590723\n",
      "Current iteration=700, loss=0.5940667285590723\n",
      "Current iteration=800, loss=0.5940667285590723\n",
      "Current iteration=900, loss=0.5940667285590723\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6117634123536736\n",
      "Current iteration=100, loss=0.6111233418109637\n",
      "Current iteration=200, loss=0.6111233418109637\n",
      "Current iteration=300, loss=0.6111233418109637\n",
      "Current iteration=400, loss=0.6111233418109637\n",
      "Current iteration=500, loss=0.6111233418109637\n",
      "Current iteration=600, loss=0.6111233418109637\n",
      "Current iteration=700, loss=0.6111233418109637\n",
      "Current iteration=800, loss=0.6111233418109637\n",
      "Current iteration=900, loss=0.6111233418109637\n",
      "Current iteration=0, loss=0.6112764666511603\n",
      "Current iteration=100, loss=0.611273856867328\n",
      "Current iteration=200, loss=0.611273856867328\n",
      "Current iteration=300, loss=0.611273856867328\n",
      "Current iteration=400, loss=0.611273856867328\n",
      "Current iteration=500, loss=0.611273856867328\n",
      "Current iteration=600, loss=0.611273856867328\n",
      "Current iteration=700, loss=0.611273856867328\n",
      "Current iteration=800, loss=0.611273856867328\n",
      "Current iteration=900, loss=0.611273856867328\n",
      "Current iteration=0, loss=0.6102069073427402\n",
      "Current iteration=100, loss=0.6102007800040293\n",
      "Current iteration=200, loss=0.6102007800040293\n",
      "Current iteration=300, loss=0.6102007800040293\n",
      "Current iteration=400, loss=0.6102007800040293\n",
      "Current iteration=500, loss=0.6102007800040293\n",
      "Current iteration=600, loss=0.6102007800040293\n",
      "Current iteration=700, loss=0.6102007800040293\n",
      "Current iteration=800, loss=0.6102007800040293\n",
      "Current iteration=900, loss=0.6102007800040293\n",
      "Current iteration=0, loss=0.6106249859120162\n",
      "Current iteration=100, loss=0.610621429381764\n",
      "Current iteration=200, loss=0.610621429381764\n",
      "Current iteration=300, loss=0.610621429381764\n",
      "Current iteration=400, loss=0.610621429381764\n",
      "Current iteration=500, loss=0.610621429381764\n",
      "Current iteration=600, loss=0.610621429381764\n",
      "Current iteration=700, loss=0.610621429381764\n",
      "Current iteration=800, loss=0.610621429381764\n",
      "Current iteration=900, loss=0.610621429381764\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6263950842956442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.6261484453177062\n",
      "Current iteration=200, loss=0.6261484453177062\n",
      "Current iteration=300, loss=0.6261484453177062\n",
      "Current iteration=400, loss=0.6261484453177062\n",
      "Current iteration=500, loss=0.6261484453177062\n",
      "Current iteration=600, loss=0.6261484453177062\n",
      "Current iteration=700, loss=0.6261484453177062\n",
      "Current iteration=800, loss=0.6261484453177062\n",
      "Current iteration=900, loss=0.6261484453177062\n",
      "Current iteration=0, loss=0.6262462981550494\n",
      "Current iteration=100, loss=0.6262453295712253\n",
      "Current iteration=200, loss=0.6262453295712253\n",
      "Current iteration=300, loss=0.6262453295712253\n",
      "Current iteration=400, loss=0.6262453295712253\n",
      "Current iteration=500, loss=0.6262453295712253\n",
      "Current iteration=600, loss=0.6262453295712253\n",
      "Current iteration=700, loss=0.6262453295712253\n",
      "Current iteration=800, loss=0.6262453295712253\n",
      "Current iteration=900, loss=0.6262453295712253\n",
      "Current iteration=0, loss=0.6253780990792089\n",
      "Current iteration=100, loss=0.6253760110836926\n",
      "Current iteration=200, loss=0.6253760110836926\n",
      "Current iteration=300, loss=0.6253760110836926\n",
      "Current iteration=400, loss=0.6253760110836926\n",
      "Current iteration=500, loss=0.6253760110836926\n",
      "Current iteration=600, loss=0.6253760110836926\n",
      "Current iteration=700, loss=0.6253760110836926\n",
      "Current iteration=800, loss=0.6253760110836926\n",
      "Current iteration=900, loss=0.6253760110836926\n",
      "Current iteration=0, loss=0.6257262318025787\n",
      "Current iteration=100, loss=0.6257249908419424\n",
      "Current iteration=200, loss=0.6257249908419424\n",
      "Current iteration=300, loss=0.6257249908419424\n",
      "Current iteration=400, loss=0.6257249908419424\n",
      "Current iteration=500, loss=0.6257249908419424\n",
      "Current iteration=600, loss=0.6257249908419424\n",
      "Current iteration=700, loss=0.6257249908419424\n",
      "Current iteration=800, loss=0.6257249908419424\n",
      "Current iteration=900, loss=0.6257249908419424\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.639474541992009\n",
      "Current iteration=100, loss=0.6394262073228856\n",
      "Current iteration=200, loss=0.6394262073228856\n",
      "Current iteration=300, loss=0.6394262073228856\n",
      "Current iteration=400, loss=0.6394262073228856\n",
      "Current iteration=500, loss=0.6394262073228856\n",
      "Current iteration=600, loss=0.6394262073228856\n",
      "Current iteration=700, loss=0.6394262073228856\n",
      "Current iteration=800, loss=0.6394262073228856\n",
      "Current iteration=900, loss=0.6394262073228856\n",
      "Current iteration=0, loss=0.6394825808358873\n",
      "Current iteration=100, loss=0.6394824622406909\n",
      "Current iteration=200, loss=0.6394824622406909\n",
      "Current iteration=300, loss=0.6394824622406909\n",
      "Current iteration=400, loss=0.6394824622406909\n",
      "Current iteration=500, loss=0.6394824622406909\n",
      "Current iteration=600, loss=0.6394824622406909\n",
      "Current iteration=700, loss=0.6394824622406909\n",
      "Current iteration=800, loss=0.6394824622406909\n",
      "Current iteration=900, loss=0.6394824622406909\n",
      "Current iteration=0, loss=0.6387956758997522\n",
      "Current iteration=100, loss=0.6387953957537341\n",
      "Current iteration=200, loss=0.6387953957537341\n",
      "Current iteration=300, loss=0.6387953957537341\n",
      "Current iteration=400, loss=0.6387953957537341\n",
      "Current iteration=500, loss=0.6387953957537341\n",
      "Current iteration=600, loss=0.6387953957537341\n",
      "Current iteration=700, loss=0.6387953957537341\n",
      "Current iteration=800, loss=0.6387953957537341\n",
      "Current iteration=900, loss=0.6387953957537341\n",
      "Current iteration=0, loss=0.6390779375993331\n",
      "Current iteration=100, loss=0.639077645321078\n",
      "Current iteration=200, loss=0.639077645321078\n",
      "Current iteration=300, loss=0.639077645321078\n",
      "Current iteration=400, loss=0.639077645321078\n",
      "Current iteration=500, loss=0.639077645321078\n",
      "Current iteration=600, loss=0.639077645321078\n",
      "Current iteration=700, loss=0.639077645321078\n",
      "Current iteration=800, loss=0.639077645321078\n",
      "Current iteration=900, loss=0.639077645321078\n",
      "Iteration 28\n",
      "Current iteration=0, loss=0.6511187688429863\n",
      "Current iteration=100, loss=0.6508091208221918\n",
      "Current iteration=200, loss=0.6508091208221918\n",
      "Current iteration=300, loss=0.6508091208221918\n",
      "Current iteration=400, loss=0.6508091208221918\n",
      "Current iteration=500, loss=0.6508091208221918\n",
      "Current iteration=600, loss=0.6508091208221918\n",
      "Current iteration=700, loss=0.6508091208221918\n",
      "Current iteration=800, loss=0.6508091208221918\n",
      "Current iteration=900, loss=0.6508091208221918\n",
      "Current iteration=0, loss=0.650837363893765\n",
      "Current iteration=100, loss=0.6508369233617661\n",
      "Current iteration=200, loss=0.6508369233617661\n",
      "Current iteration=300, loss=0.6508369233617661\n",
      "Current iteration=400, loss=0.6508369233617661\n",
      "Current iteration=500, loss=0.6508369233617661\n",
      "Current iteration=600, loss=0.6508369233617661\n",
      "Current iteration=700, loss=0.6508369233617661\n",
      "Current iteration=800, loss=0.6508369233617661\n",
      "Current iteration=900, loss=0.6508369233617661\n",
      "Current iteration=0, loss=0.6503075210929803\n",
      "Current iteration=100, loss=0.6503059694179517\n",
      "Current iteration=200, loss=0.6503059694179517\n",
      "Current iteration=300, loss=0.6503059694179517\n",
      "Current iteration=400, loss=0.6503059694179517\n",
      "Current iteration=500, loss=0.6503059694179517\n",
      "Current iteration=600, loss=0.6503059694179517\n",
      "Current iteration=700, loss=0.6503059694179517\n",
      "Current iteration=800, loss=0.6503059694179517\n",
      "Current iteration=900, loss=0.6503059694179517\n",
      "Current iteration=0, loss=0.6505300392393636\n",
      "Current iteration=100, loss=0.650528941946489\n",
      "Current iteration=200, loss=0.650528941946489\n",
      "Current iteration=300, loss=0.650528941946489\n",
      "Current iteration=400, loss=0.650528941946489\n",
      "Current iteration=500, loss=0.650528941946489\n",
      "Current iteration=600, loss=0.650528941946489\n",
      "Current iteration=700, loss=0.650528941946489\n",
      "Current iteration=800, loss=0.650528941946489\n",
      "Current iteration=900, loss=0.650528941946489\n",
      "Iteration 29\n",
      "Current iteration=0, loss=0.6616706837885825\n",
      "Current iteration=100, loss=0.6692693701970609\n",
      "Current iteration=200, loss=0.6815490249842444\n",
      "Current iteration=300, loss=0.6816294718561566\n",
      "Current iteration=400, loss=0.6816297412638209\n",
      "Current iteration=500, loss=0.6816297421633467\n",
      "Current iteration=600, loss=0.6816297421663505\n",
      "Current iteration=700, loss=0.6816297421663612\n",
      "Current iteration=800, loss=0.6816297421663612\n",
      "Current iteration=900, loss=0.6816297421663612\n",
      "Current iteration=0, loss=0.6814337935203938\n",
      "Current iteration=100, loss=0.6792807690737225\n",
      "Current iteration=200, loss=0.6792666622883827\n",
      "Current iteration=300, loss=0.6792665609460757\n",
      "Current iteration=400, loss=0.6792665602175987\n",
      "Current iteration=500, loss=0.679266560212362\n",
      "Current iteration=600, loss=0.6792665602123239\n",
      "Current iteration=700, loss=0.6792665602123238\n",
      "Current iteration=800, loss=0.6792665602123238\n",
      "Current iteration=900, loss=0.6792665602123238\n",
      "Current iteration=0, loss=0.6788192281262477\n",
      "Current iteration=100, loss=0.675238833683361\n",
      "Current iteration=200, loss=0.6751902438186739\n",
      "Current iteration=300, loss=0.6751894535315341\n",
      "Current iteration=400, loss=0.6751894406428183\n",
      "Current iteration=500, loss=0.6751894404326083\n",
      "Current iteration=600, loss=0.6751894404291796\n",
      "Current iteration=700, loss=0.6751894404291243\n",
      "Current iteration=800, loss=0.6751894404291234\n",
      "Current iteration=900, loss=0.6751894404291234\n",
      "Current iteration=0, loss=0.6757778701252215\n",
      "Current iteration=100, loss=0.6804424643985594\n",
      "Current iteration=200, loss=0.6804716296410392\n",
      "Current iteration=300, loss=0.6804717772137631\n",
      "Current iteration=400, loss=0.6804717779595937\n",
      "Current iteration=500, loss=0.6804717779633627\n",
      "Current iteration=600, loss=0.6804717779633819\n",
      "Current iteration=700, loss=0.6804717779633819\n",
      "Current iteration=800, loss=0.6804717779633819\n",
      "Current iteration=900, loss=0.6804717779633819\n",
      "Iteration 0\n",
      "Current iteration=0, loss=0.6372057644955702\n",
      "Current iteration=100, loss=0.5438416813162126\n",
      "Current iteration=200, loss=0.5417860172541333\n",
      "Current iteration=300, loss=0.5412739964189548\n",
      "Current iteration=400, loss=0.5411155008625274\n",
      "Current iteration=500, loss=0.5410624806793088\n",
      "Current iteration=600, loss=0.5410441097741868\n",
      "Current iteration=700, loss=0.5410376273364207\n",
      "Current iteration=800, loss=0.5410353169273785\n",
      "Current iteration=900, loss=0.5410344888071127\n",
      "Current iteration=0, loss=0.5402710034704941\n",
      "Current iteration=100, loss=0.5401491740633918\n",
      "Current iteration=200, loss=0.5401456342098525\n",
      "Current iteration=300, loss=0.540144626220765\n",
      "Current iteration=400, loss=0.5401443155648891\n",
      "Current iteration=500, loss=0.5401442147776271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.5401441809988903\n",
      "Current iteration=700, loss=0.5401441694555147\n",
      "Current iteration=800, loss=0.5401441654661228\n",
      "Current iteration=900, loss=0.5401441640785665\n",
      "Current iteration=0, loss=0.5435851922412778\n",
      "Current iteration=100, loss=0.543481453775012\n",
      "Current iteration=200, loss=0.5434775173827054\n",
      "Current iteration=300, loss=0.5434767324417722\n",
      "Current iteration=400, loss=0.5434765591240369\n",
      "Current iteration=500, loss=0.5434765160227757\n",
      "Current iteration=600, loss=0.5434765040077166\n",
      "Current iteration=700, loss=0.5434765003482915\n",
      "Current iteration=800, loss=0.5434764991674258\n",
      "Current iteration=900, loss=0.543476498773352\n",
      "Current iteration=0, loss=0.5408307996758551\n",
      "Current iteration=100, loss=0.540704210946884\n",
      "Current iteration=200, loss=0.5406979188136236\n",
      "Current iteration=300, loss=0.5406958391884862\n",
      "Current iteration=400, loss=0.5406951095652036\n",
      "Current iteration=500, loss=0.5406948475694567\n",
      "Current iteration=600, loss=0.5406947523846017\n",
      "Current iteration=700, loss=0.5406947175980727\n",
      "Current iteration=800, loss=0.5406947048468652\n",
      "Current iteration=900, loss=0.540694700165764\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.541282420932952\n",
      "Current iteration=100, loss=0.5412119432229089\n",
      "Current iteration=200, loss=0.5412116518060163\n",
      "Current iteration=300, loss=0.5412115925082742\n",
      "Current iteration=400, loss=0.5412115759350113\n",
      "Current iteration=500, loss=0.5412115709219676\n",
      "Current iteration=600, loss=0.5412115693202075\n",
      "Current iteration=700, loss=0.5412115687879943\n",
      "Current iteration=800, loss=0.5412115686064832\n",
      "Current iteration=900, loss=0.5412115685435469\n",
      "Current iteration=0, loss=0.5404441001405256\n",
      "Current iteration=100, loss=0.5403207911392224\n",
      "Current iteration=200, loss=0.540316725033974\n",
      "Current iteration=300, loss=0.5403155486978234\n",
      "Current iteration=400, loss=0.5403151839644788\n",
      "Current iteration=500, loss=0.5403150658476146\n",
      "Current iteration=600, loss=0.5403150265530979\n",
      "Current iteration=700, loss=0.5403150132712559\n",
      "Current iteration=800, loss=0.5403150087407138\n",
      "Current iteration=900, loss=0.5403150071873049\n",
      "Current iteration=0, loss=0.5437541055913715\n",
      "Current iteration=100, loss=0.5436506643423592\n",
      "Current iteration=200, loss=0.5436468008598189\n",
      "Current iteration=300, loss=0.5436460397506835\n",
      "Current iteration=400, loss=0.5436458737733765\n",
      "Current iteration=500, loss=0.5436458330427856\n",
      "Current iteration=600, loss=0.5436458218510322\n",
      "Current iteration=700, loss=0.5436458184942514\n",
      "Current iteration=800, loss=0.5436458174281328\n",
      "Current iteration=900, loss=0.5436458170780598\n",
      "Current iteration=0, loss=0.5410076615421425\n",
      "Current iteration=100, loss=0.5408815027627814\n",
      "Current iteration=200, loss=0.5408753869786279\n",
      "Current iteration=300, loss=0.5408733983934365\n",
      "Current iteration=400, loss=0.540872711964397\n",
      "Current iteration=500, loss=0.540872469448476\n",
      "Current iteration=600, loss=0.5408723827571845\n",
      "Current iteration=700, loss=0.540872351583544\n",
      "Current iteration=800, loss=0.540872340340102\n",
      "Current iteration=900, loss=0.5408723362787813\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.5415235030410289\n",
      "Current iteration=100, loss=0.541452346832895\n",
      "Current iteration=200, loss=0.5414519496860754\n",
      "Current iteration=300, loss=0.5414518546181939\n",
      "Current iteration=400, loss=0.5414518255966496\n",
      "Current iteration=500, loss=0.5414518162643027\n",
      "Current iteration=600, loss=0.5414518131716713\n",
      "Current iteration=700, loss=0.5414518121272669\n",
      "Current iteration=800, loss=0.541451811770466\n",
      "Current iteration=900, loss=0.5414518116477248\n",
      "Current iteration=0, loss=0.5406745812263692\n",
      "Current iteration=100, loss=0.5405518647863408\n",
      "Current iteration=200, loss=0.5405479568439178\n",
      "Current iteration=300, loss=0.5405468532633066\n",
      "Current iteration=400, loss=0.5405465191126456\n",
      "Current iteration=500, loss=0.5405464133679102\n",
      "Current iteration=600, loss=0.5405463789728803\n",
      "Current iteration=700, loss=0.5405463676017888\n",
      "Current iteration=800, loss=0.5405463638070896\n",
      "Current iteration=900, loss=0.5405463625339972\n",
      "Current iteration=0, loss=0.543982867210144\n",
      "Current iteration=100, loss=0.5438798293121296\n",
      "Current iteration=200, loss=0.5438760653648194\n",
      "Current iteration=300, loss=0.5438753364333556\n",
      "Current iteration=400, loss=0.5438751802586919\n",
      "Current iteration=500, loss=0.5438751426507896\n",
      "Current iteration=600, loss=0.5438751325246985\n",
      "Current iteration=700, loss=0.5438751295517751\n",
      "Current iteration=800, loss=0.5438751286280854\n",
      "Current iteration=900, loss=0.5438751283314439\n",
      "Current iteration=0, loss=0.5412469838226049\n",
      "Current iteration=100, loss=0.5411213976733227\n",
      "Current iteration=200, loss=0.5411155139177406\n",
      "Current iteration=300, loss=0.5411136430428005\n",
      "Current iteration=400, loss=0.5411130114350674\n",
      "Current iteration=500, loss=0.5411127931806188\n",
      "Current iteration=600, loss=0.5411127168691698\n",
      "Current iteration=700, loss=0.541112690027752\n",
      "Current iteration=800, loss=0.5411126805582729\n",
      "Current iteration=900, loss=0.5411126772124365\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.5418484445567722\n",
      "Current iteration=100, loss=0.5417760897636742\n",
      "Current iteration=200, loss=0.5417754838081049\n",
      "Current iteration=300, loss=0.5417753215964211\n",
      "Current iteration=400, loss=0.5417752704346703\n",
      "Current iteration=500, loss=0.541775253811414\n",
      "Current iteration=600, loss=0.5417752483280416\n",
      "Current iteration=700, loss=0.5417752465032895\n",
      "Current iteration=800, loss=0.5417752458929245\n",
      "Current iteration=900, loss=0.5417752456881528\n",
      "Current iteration=0, loss=0.5409852339585974\n",
      "Current iteration=100, loss=0.5408632967095284\n",
      "Current iteration=200, loss=0.5408595920844665\n",
      "Current iteration=300, loss=0.5408585796902496\n",
      "Current iteration=400, loss=0.5408582828657292\n",
      "Current iteration=500, loss=0.5408581918286001\n",
      "Current iteration=600, loss=0.5408581631088077\n",
      "Current iteration=700, loss=0.5408581538950665\n",
      "Current iteration=800, loss=0.5408581509103748\n",
      "Current iteration=900, loss=0.5408581499381748\n",
      "Current iteration=0, loss=0.5442912139785205\n",
      "Current iteration=100, loss=0.5441887076193866\n",
      "Current iteration=200, loss=0.5441850749394683\n",
      "Current iteration=300, loss=0.5441843877584832\n",
      "Current iteration=400, loss=0.5441842440657019\n",
      "Current iteration=500, loss=0.5441842103503097\n",
      "Current iteration=600, loss=0.5441842015214968\n",
      "Current iteration=700, loss=0.5441841990041579\n",
      "Current iteration=800, loss=0.5441841982451421\n",
      "Current iteration=900, loss=0.5441841980086642\n",
      "Current iteration=0, loss=0.5415691848500942\n",
      "Current iteration=100, loss=0.5414443535192234\n",
      "Current iteration=200, loss=0.5414387705395751\n",
      "Current iteration=300, loss=0.5414370486592514\n",
      "Current iteration=400, loss=0.541436484710713\n",
      "Current iteration=500, loss=0.5414362956400314\n",
      "Current iteration=600, loss=0.5414362314964204\n",
      "Current iteration=700, loss=0.5414362096040491\n",
      "Current iteration=800, loss=0.5414362021094631\n",
      "Current iteration=900, loss=0.5414361995398672\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.542283678034169\n",
      "Current iteration=100, loss=0.5422092310193062\n",
      "Current iteration=200, loss=0.542208246578843\n",
      "Current iteration=300, loss=0.5422079704046242\n",
      "Current iteration=400, loss=0.5422078841815667\n",
      "Current iteration=500, loss=0.5422078568015554\n",
      "Current iteration=600, loss=0.5422078480399447\n",
      "Current iteration=700, loss=0.5422078452244045\n",
      "Current iteration=800, loss=0.5422078443175048\n",
      "Current iteration=900, loss=0.5422078440250014\n",
      "Current iteration=0, loss=0.5414013585695865\n",
      "Current iteration=100, loss=0.5412804280299689\n",
      "Current iteration=200, loss=0.5412769783413203\n",
      "Current iteration=300, loss=0.5412760765206892\n",
      "Current iteration=400, loss=0.5412758233804807\n",
      "Current iteration=500, loss=0.5412757489587339\n",
      "Current iteration=600, loss=0.5412757264308223\n",
      "Current iteration=700, loss=0.5412757194912138\n",
      "Current iteration=800, loss=0.5412757173317475\n",
      "Current iteration=900, loss=0.5412757166558764\n",
      "Current iteration=0, loss=0.5447042696010045\n",
      "Current iteration=100, loss=0.5446024545701097\n",
      "Current iteration=200, loss=0.5445989928486985\n",
      "Current iteration=300, loss=0.5445983588331288\n",
      "Current iteration=400, loss=0.5445982306297399\n",
      "Current iteration=500, loss=0.5445982016059814\n",
      "Current iteration=600, loss=0.5445981942908984\n",
      "Current iteration=700, loss=0.5445981922870521\n",
      "Current iteration=800, loss=0.5445981917071319\n",
      "Current iteration=900, loss=0.5445981915337716\n",
      "Current iteration=0, loss=0.5420001454652854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.5418762956923697\n",
      "Current iteration=200, loss=0.5418710949458013\n",
      "Current iteration=300, loss=0.5418695563863778\n",
      "Current iteration=400, loss=0.5418690728763806\n",
      "Current iteration=500, loss=0.5418689173131297\n",
      "Current iteration=600, loss=0.5418688666596562\n",
      "Current iteration=700, loss=0.5418688500653871\n",
      "Current iteration=800, loss=0.5418688446123009\n",
      "Current iteration=900, loss=0.5418688428175769\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.5428620153448722\n",
      "Current iteration=100, loss=0.542783981619084\n",
      "Current iteration=200, loss=0.5427823631333341\n",
      "Current iteration=300, loss=0.5427819126805629\n",
      "Current iteration=400, loss=0.5427817778563582\n",
      "Current iteration=500, loss=0.5427817370677308\n",
      "Current iteration=600, loss=0.5427817246738352\n",
      "Current iteration=700, loss=0.5427817208994505\n",
      "Current iteration=800, loss=0.5427817197486609\n",
      "Current iteration=900, loss=0.5427817193975715\n",
      "Current iteration=0, loss=0.54195441800947\n",
      "Current iteration=100, loss=0.5418347556773586\n",
      "Current iteration=200, loss=0.5418316150458762\n",
      "Current iteration=300, loss=0.5418308415518345\n",
      "Current iteration=400, loss=0.5418306367797772\n",
      "Current iteration=500, loss=0.5418305799091584\n",
      "Current iteration=600, loss=0.5418305636246878\n",
      "Current iteration=700, loss=0.5418305588751142\n",
      "Current iteration=800, loss=0.5418305574749331\n",
      "Current iteration=900, loss=0.5418305570596258\n",
      "Current iteration=0, loss=0.5452532860077642\n",
      "Current iteration=100, loss=0.5451523554592678\n",
      "Current iteration=200, loss=0.5451491129569501\n",
      "Current iteration=300, loss=0.5451485450158771\n",
      "Current iteration=400, loss=0.5451484353882716\n",
      "Current iteration=500, loss=0.5451484117694414\n",
      "Current iteration=600, loss=0.5451484061223348\n",
      "Current iteration=700, loss=0.5451484046581259\n",
      "Current iteration=800, loss=0.5451484042574779\n",
      "Current iteration=900, loss=0.5451484041442772\n",
      "Current iteration=0, loss=0.5425718686919454\n",
      "Current iteration=100, loss=0.5424492735600975\n",
      "Current iteration=200, loss=0.5424445461125418\n",
      "Current iteration=300, loss=0.54244322481907\n",
      "Current iteration=400, loss=0.5424428323125231\n",
      "Current iteration=500, loss=0.5424427129102095\n",
      "Current iteration=600, loss=0.5424426761418962\n",
      "Current iteration=700, loss=0.5424426647487309\n",
      "Current iteration=800, loss=0.5424426612072313\n",
      "Current iteration=900, loss=0.5424426601046237\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.5436229693414834\n",
      "Current iteration=100, loss=0.5435389384768975\n",
      "Current iteration=200, loss=0.5435363458236013\n",
      "Current iteration=300, loss=0.5435356610569108\n",
      "Current iteration=400, loss=0.5435354701631947\n",
      "Current iteration=500, loss=0.5435354165144135\n",
      "Current iteration=600, loss=0.5435354013892129\n",
      "Current iteration=700, loss=0.5435353971183331\n",
      "Current iteration=800, loss=0.5435353959114224\n",
      "Current iteration=900, loss=0.5435353955702233\n",
      "Current iteration=0, loss=0.5426824231189572\n",
      "Current iteration=100, loss=0.542564300395399\n",
      "Current iteration=200, loss=0.5425615179106806\n",
      "Current iteration=300, loss=0.542560885058994\n",
      "Current iteration=400, loss=0.5425607301231363\n",
      "Current iteration=500, loss=0.5425606902462606\n",
      "Current iteration=600, loss=0.5425606796458449\n",
      "Current iteration=700, loss=0.5425606767721205\n",
      "Current iteration=800, loss=0.5425606759840904\n",
      "Current iteration=900, loss=0.5425606757665746\n",
      "Current iteration=0, loss=0.5459760404396573\n",
      "Current iteration=100, loss=0.5458762187086554\n",
      "Current iteration=200, loss=0.545873251954488\n",
      "Current iteration=300, loss=0.5458727635454802\n",
      "Current iteration=400, loss=0.5458726751892596\n",
      "Current iteration=500, loss=0.545872657423326\n",
      "Current iteration=600, loss=0.5458726534748809\n",
      "Current iteration=700, loss=0.545872652525703\n",
      "Current iteration=800, loss=0.5458726522851763\n",
      "Current iteration=900, loss=0.545872652222253\n",
      "Current iteration=0, loss=0.5433227582264785\n",
      "Current iteration=100, loss=0.5432017331789614\n",
      "Current iteration=200, loss=0.5431975722917823\n",
      "Current iteration=300, loss=0.5431964960954911\n",
      "Current iteration=400, loss=0.5431961999959649\n",
      "Current iteration=500, loss=0.5431961165351744\n",
      "Current iteration=600, loss=0.5431960927131017\n",
      "Current iteration=700, loss=0.5431960858693416\n",
      "Current iteration=800, loss=0.5431960838966953\n",
      "Current iteration=900, loss=0.5431960833271445\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.5446124363870569\n",
      "Current iteration=100, loss=0.5445186990230197\n",
      "Current iteration=200, loss=0.544514762071238\n",
      "Current iteration=300, loss=0.5445138154307589\n",
      "Current iteration=400, loss=0.5445135774065442\n",
      "Current iteration=500, loss=0.5445135170994364\n",
      "Current iteration=600, loss=0.5445135017708352\n",
      "Current iteration=700, loss=0.5445134978682875\n",
      "Current iteration=800, loss=0.5445134968738746\n",
      "Current iteration=900, loss=0.5445134966203727\n",
      "Current iteration=0, loss=0.5436297561325436\n",
      "Current iteration=100, loss=0.5435134007585698\n",
      "Current iteration=200, loss=0.5435110095392256\n",
      "Current iteration=300, loss=0.5435105200274896\n",
      "Current iteration=400, loss=0.5435104119771235\n",
      "Current iteration=500, loss=0.5435103868385442\n",
      "Current iteration=600, loss=0.5435103807845852\n",
      "Current iteration=700, loss=0.5435103792955199\n",
      "Current iteration=800, loss=0.5435103789246934\n",
      "Current iteration=900, loss=0.5435103788316858\n",
      "Current iteration=0, loss=0.5469166971321495\n",
      "Current iteration=100, loss=0.546818230791197\n",
      "Current iteration=200, loss=0.5468156023041473\n",
      "Current iteration=300, loss=0.5468152054966555\n",
      "Current iteration=400, loss=0.5468151399629427\n",
      "Current iteration=500, loss=0.5468151280015874\n",
      "Current iteration=600, loss=0.5468151256001189\n",
      "Current iteration=700, loss=0.5468151250800347\n",
      "Current iteration=800, loss=0.5468151249614003\n",
      "Current iteration=900, loss=0.5468151249334584\n",
      "Current iteration=0, loss=0.544297329368529\n",
      "Current iteration=100, loss=0.5441782205110117\n",
      "Current iteration=200, loss=0.5441747083491622\n",
      "Current iteration=300, loss=0.5441738910859347\n",
      "Current iteration=400, loss=0.5441736885383419\n",
      "Current iteration=500, loss=0.544173637078036\n",
      "Current iteration=600, loss=0.5441736238308602\n",
      "Current iteration=700, loss=0.544173620397057\n",
      "Current iteration=800, loss=0.544173619503784\n",
      "Current iteration=900, loss=0.544173619270977\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.5458816243484205\n",
      "Current iteration=100, loss=0.5457728002169369\n",
      "Current iteration=200, loss=0.5457672630507422\n",
      "Current iteration=300, loss=0.5457661056837052\n",
      "Current iteration=400, loss=0.5457658535619262\n",
      "Current iteration=500, loss=0.5457657981543044\n",
      "Current iteration=600, loss=0.5457657859256523\n",
      "Current iteration=700, loss=0.545765783220323\n",
      "Current iteration=800, loss=0.5457657826210291\n",
      "Current iteration=900, loss=0.5457657824881738\n",
      "Current iteration=0, loss=0.5448463007472251\n",
      "Current iteration=100, loss=0.5447318040583747\n",
      "Current iteration=200, loss=0.544729810114799\n",
      "Current iteration=300, loss=0.5447294544655003\n",
      "Current iteration=400, loss=0.5447293859343704\n",
      "Current iteration=500, loss=0.544729371973946\n",
      "Current iteration=600, loss=0.5447293690228365\n",
      "Current iteration=700, loss=0.5447293683845755\n",
      "Current iteration=800, loss=0.5447293682446627\n",
      "Current iteration=900, loss=0.5447293682137541\n",
      "Current iteration=0, loss=0.5481250201800307\n",
      "Current iteration=100, loss=0.5480281581858477\n",
      "Current iteration=200, loss=0.548025929548117\n",
      "Current iteration=300, loss=0.5480256315510275\n",
      "Current iteration=400, loss=0.5480255882460054\n",
      "Current iteration=500, loss=0.5480255813414525\n",
      "Current iteration=600, loss=0.5480255801370895\n",
      "Current iteration=700, loss=0.5480255799110135\n",
      "Current iteration=800, loss=0.5480255798663144\n",
      "Current iteration=900, loss=0.5480255798571788\n",
      "Current iteration=0, loss=0.5455452913966531\n",
      "Current iteration=100, loss=0.5454284569633621\n",
      "Current iteration=200, loss=0.5454256446403323\n",
      "Current iteration=300, loss=0.545425077632194\n",
      "Current iteration=400, loss=0.5454249556774602\n",
      "Current iteration=500, loss=0.5454249287630056\n",
      "Current iteration=600, loss=0.5454249227392759\n",
      "Current iteration=700, loss=0.5454249213808262\n",
      "Current iteration=800, loss=0.5454249210732298\n",
      "Current iteration=900, loss=0.5454249210034304\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.5474853737189338\n",
      "Current iteration=100, loss=0.5473542042416715\n",
      "Current iteration=200, loss=0.5473471544408864\n",
      "Current iteration=300, loss=0.5473459438569193\n",
      "Current iteration=400, loss=0.5473457268594963\n",
      "Current iteration=500, loss=0.5473456874925895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.5473456803031757\n",
      "Current iteration=700, loss=0.5473456789850272\n",
      "Current iteration=800, loss=0.547345678742795\n",
      "Current iteration=900, loss=0.5473456786982217\n",
      "Current iteration=0, loss=0.5463859214568625\n",
      "Current iteration=100, loss=0.5462731382666509\n",
      "Current iteration=200, loss=0.5462715183339114\n",
      "Current iteration=300, loss=0.5462712766518696\n",
      "Current iteration=400, loss=0.5462712376166797\n",
      "Current iteration=500, loss=0.546271230931066\n",
      "Current iteration=600, loss=0.5462712297398192\n",
      "Current iteration=700, loss=0.5462712295222832\n",
      "Current iteration=800, loss=0.5462712294819787\n",
      "Current iteration=900, loss=0.5462712294744485\n",
      "Current iteration=0, loss=0.549654955757343\n",
      "Current iteration=100, loss=0.5495599205634861\n",
      "Current iteration=200, loss=0.5495581367544139\n",
      "Current iteration=300, loss=0.5495579351204801\n",
      "Current iteration=400, loss=0.5495579105538579\n",
      "Current iteration=500, loss=0.5495579072963938\n",
      "Current iteration=600, loss=0.5495579068262874\n",
      "Current iteration=700, loss=0.5495579067533665\n",
      "Current iteration=800, loss=0.5495579067414345\n",
      "Current iteration=900, loss=0.549557906739411\n",
      "Current iteration=0, loss=0.5471201265169955\n",
      "Current iteration=100, loss=0.5470059202566137\n",
      "Current iteration=200, loss=0.5470038052564099\n",
      "Current iteration=300, loss=0.5470034527172365\n",
      "Current iteration=400, loss=0.5470033899007725\n",
      "Current iteration=500, loss=0.5470033784019714\n",
      "Current iteration=600, loss=0.5470033762645493\n",
      "Current iteration=700, loss=0.5470033758637869\n",
      "Current iteration=800, loss=0.5470033757882825\n",
      "Current iteration=900, loss=0.5470033757740201\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.549480225587762\n",
      "Current iteration=100, loss=0.5493177271687976\n",
      "Current iteration=200, loss=0.5493097819829439\n",
      "Current iteration=300, loss=0.5493087330764199\n",
      "Current iteration=400, loss=0.5493085874112432\n",
      "Current iteration=500, loss=0.5493085668131841\n",
      "Current iteration=600, loss=0.5493085638692865\n",
      "Current iteration=700, loss=0.5493085634458349\n",
      "Current iteration=800, loss=0.5493085633846949\n",
      "Current iteration=900, loss=0.5493085633758474\n",
      "Current iteration=0, loss=0.5483045108802445\n",
      "Current iteration=100, loss=0.5481931269066526\n",
      "Current iteration=200, loss=0.5481918487208687\n",
      "Current iteration=300, loss=0.5481916974266924\n",
      "Current iteration=400, loss=0.5481916779904162\n",
      "Current iteration=500, loss=0.5481916753347066\n",
      "Current iteration=600, loss=0.5481916749563441\n",
      "Current iteration=700, loss=0.5481916749010193\n",
      "Current iteration=800, loss=0.548191674892805\n",
      "Current iteration=900, loss=0.5481916748915746\n",
      "Current iteration=0, loss=0.5515626116907969\n",
      "Current iteration=100, loss=0.5514696097339027\n",
      "Current iteration=200, loss=0.5514682785860295\n",
      "Current iteration=300, loss=0.5514681585993003\n",
      "Current iteration=400, loss=0.5514681470343715\n",
      "Current iteration=500, loss=0.5514681458297481\n",
      "Current iteration=600, loss=0.5514681456936621\n",
      "Current iteration=700, loss=0.5514681456771269\n",
      "Current iteration=800, loss=0.5514681456750007\n",
      "Current iteration=900, loss=0.551468145674716\n",
      "Current iteration=0, loss=0.5490773081534862\n",
      "Current iteration=100, loss=0.5489660872009144\n",
      "Current iteration=200, loss=0.5489646054500367\n",
      "Current iteration=300, loss=0.5489644118238464\n",
      "Current iteration=400, loss=0.5489643846897878\n",
      "Current iteration=500, loss=0.5489643807756108\n",
      "Current iteration=600, loss=0.5489643802011475\n",
      "Current iteration=700, loss=0.5489643801159735\n",
      "Current iteration=800, loss=0.5489643801032701\n",
      "Current iteration=900, loss=0.5489643801013689\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.5519223550494164\n",
      "Current iteration=100, loss=0.5517184856335754\n",
      "Current iteration=200, loss=0.5517107049848968\n",
      "Current iteration=300, loss=0.5517099683839216\n",
      "Current iteration=400, loss=0.5517098939892596\n",
      "Current iteration=500, loss=0.5517098862767476\n",
      "Current iteration=600, loss=0.55170988546475\n",
      "Current iteration=700, loss=0.5517098853784712\n",
      "Current iteration=800, loss=0.5517098853692545\n",
      "Current iteration=900, loss=0.5517098853682668\n",
      "Current iteration=0, loss=0.5506580801634676\n",
      "Current iteration=100, loss=0.5505480968042921\n",
      "Current iteration=200, loss=0.5505471517513719\n",
      "Current iteration=300, loss=0.5505470692226386\n",
      "Current iteration=400, loss=0.5505470613702282\n",
      "Current iteration=500, loss=0.550547060572772\n",
      "Current iteration=600, loss=0.5505470604881355\n",
      "Current iteration=700, loss=0.5505470604789052\n",
      "Current iteration=800, loss=0.5505470604778824\n",
      "Current iteration=900, loss=0.550547060477768\n",
      "Current iteration=0, loss=0.5539038047033066\n",
      "Current iteration=100, loss=0.5538131604188612\n",
      "Current iteration=200, loss=0.553812246977848\n",
      "Current iteration=300, loss=0.5538121858247926\n",
      "Current iteration=400, loss=0.553812181471242\n",
      "Current iteration=500, loss=0.5538121811378033\n",
      "Current iteration=600, loss=0.5538121811101419\n",
      "Current iteration=700, loss=0.5538121811076682\n",
      "Current iteration=800, loss=0.5538121811074329\n",
      "Current iteration=900, loss=0.5538121811074094\n",
      "Current iteration=0, loss=0.5514722244564768\n",
      "Current iteration=100, loss=0.551364399033628\n",
      "Current iteration=200, loss=0.5513634465560111\n",
      "Current iteration=300, loss=0.5513633550340246\n",
      "Current iteration=400, loss=0.5513633455456255\n",
      "Current iteration=500, loss=0.5513633445293593\n",
      "Current iteration=600, loss=0.5513633444182956\n",
      "Current iteration=700, loss=0.5513633444060085\n",
      "Current iteration=800, loss=0.5513633444046392\n",
      "Current iteration=900, loss=0.5513633444044859\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.554865465437241\n",
      "Current iteration=100, loss=0.5546103300583702\n",
      "Current iteration=200, loss=0.5546038620793962\n",
      "Current iteration=300, loss=0.5546034580556622\n",
      "Current iteration=400, loss=0.5546034306832415\n",
      "Current iteration=500, loss=0.5546034287648944\n",
      "Current iteration=600, loss=0.5546034286277681\n",
      "Current iteration=700, loss=0.5546034286178525\n",
      "Current iteration=800, loss=0.5546034286171307\n",
      "Current iteration=900, loss=0.554603428617078\n",
      "Current iteration=0, loss=0.5535019566132208\n",
      "Current iteration=100, loss=0.5533942032690117\n",
      "Current iteration=200, loss=0.553393592028896\n",
      "Current iteration=300, loss=0.5533935564474918\n",
      "Current iteration=400, loss=0.5533935541766839\n",
      "Current iteration=500, loss=0.553393554021233\n",
      "Current iteration=600, loss=0.5533935540100791\n",
      "Current iteration=700, loss=0.5533935540092556\n",
      "Current iteration=800, loss=0.5533935540091938\n",
      "Current iteration=900, loss=0.5533935540091892\n",
      "Current iteration=0, loss=0.5567323897704378\n",
      "Current iteration=100, loss=0.5566446580288643\n",
      "Current iteration=200, loss=0.5566440964671332\n",
      "Current iteration=300, loss=0.556644070988855\n",
      "Current iteration=400, loss=0.5566440697624757\n",
      "Current iteration=500, loss=0.5566440696991016\n",
      "Current iteration=600, loss=0.5566440696955551\n",
      "Current iteration=700, loss=0.5566440696953407\n",
      "Current iteration=800, loss=0.556644069695327\n",
      "Current iteration=900, loss=0.556644069695326\n",
      "Current iteration=0, loss=0.5543586606107547\n",
      "Current iteration=100, loss=0.5542547537031473\n",
      "Current iteration=200, loss=0.5542542101402967\n",
      "Current iteration=300, loss=0.5542541752139067\n",
      "Current iteration=400, loss=0.5542541727696825\n",
      "Current iteration=500, loss=0.5542541725919766\n",
      "Current iteration=600, loss=0.5542541725787399\n",
      "Current iteration=700, loss=0.554254172577739\n",
      "Current iteration=800, loss=0.5542541725776626\n",
      "Current iteration=900, loss=0.5542541725776569\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.558360319219892\n",
      "Current iteration=100, loss=0.558045577065713\n",
      "Current iteration=200, loss=0.5580412193276935\n",
      "Current iteration=300, loss=0.5580410615648027\n",
      "Current iteration=400, loss=0.5580410552608849\n",
      "Current iteration=500, loss=0.558041054998268\n",
      "Current iteration=600, loss=0.5580410549870612\n",
      "Current iteration=700, loss=0.5580410549865765\n",
      "Current iteration=800, loss=0.5580410549865553\n",
      "Current iteration=900, loss=0.5580410549865544\n",
      "Current iteration=0, loss=0.5568914327994029\n",
      "Current iteration=100, loss=0.5567872085536074\n",
      "Current iteration=200, loss=0.5567868828084902\n",
      "Current iteration=300, loss=0.5567868717953426\n",
      "Current iteration=400, loss=0.5567868713835389\n",
      "Current iteration=500, loss=0.5567868713669147\n",
      "Current iteration=600, loss=0.5567868713662087\n",
      "Current iteration=700, loss=0.5567868713661778\n",
      "Current iteration=800, loss=0.5567868713661764\n",
      "Current iteration=900, loss=0.5567868713661764\n",
      "Current iteration=0, loss=0.5601004928975859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.560016342688295\n",
      "Current iteration=200, loss=0.5600160462500188\n",
      "Current iteration=300, loss=0.5600160382295588\n",
      "Current iteration=400, loss=0.5600160379992529\n",
      "Current iteration=500, loss=0.5600160379921587\n",
      "Current iteration=600, loss=0.5600160379919222\n",
      "Current iteration=700, loss=0.5600160379919137\n",
      "Current iteration=800, loss=0.5600160379919134\n",
      "Current iteration=900, loss=0.5600160379919132\n",
      "Current iteration=0, loss=0.5577891819361571\n",
      "Current iteration=100, loss=0.5576898619437511\n",
      "Current iteration=200, loss=0.5576895982264795\n",
      "Current iteration=300, loss=0.5576895883883872\n",
      "Current iteration=400, loss=0.5576895879841735\n",
      "Current iteration=500, loss=0.5576895879667995\n",
      "Current iteration=600, loss=0.5576895879660302\n",
      "Current iteration=700, loss=0.5576895879659955\n",
      "Current iteration=800, loss=0.557689587965994\n",
      "Current iteration=900, loss=0.5576895879659939\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.5624565446284316\n",
      "Current iteration=100, loss=0.5620761389970261\n",
      "Current iteration=200, loss=0.5620739015908971\n",
      "Current iteration=300, loss=0.5620738628982108\n",
      "Current iteration=400, loss=0.5620738621441204\n",
      "Current iteration=500, loss=0.5620738621286505\n",
      "Current iteration=600, loss=0.5620738621283236\n",
      "Current iteration=700, loss=0.5620738621283167\n",
      "Current iteration=800, loss=0.5620738621283167\n",
      "Current iteration=900, loss=0.5620738621283167\n",
      "Current iteration=0, loss=0.5608817658897137\n",
      "Current iteration=100, loss=0.560782100500181\n",
      "Current iteration=200, loss=0.560781962948552\n",
      "Current iteration=300, loss=0.5607819607045277\n",
      "Current iteration=400, loss=0.5607819606635929\n",
      "Current iteration=500, loss=0.5607819606627807\n",
      "Current iteration=600, loss=0.5607819606627638\n",
      "Current iteration=700, loss=0.5607819606627632\n",
      "Current iteration=800, loss=0.5607819606627633\n",
      "Current iteration=900, loss=0.5607819606627633\n",
      "Current iteration=0, loss=0.5640591490216352\n",
      "Current iteration=100, loss=0.5639792258602321\n",
      "Current iteration=200, loss=0.5639790989662864\n",
      "Current iteration=300, loss=0.5639790972605278\n",
      "Current iteration=400, loss=0.5639790972361547\n",
      "Current iteration=500, loss=0.5639790972357814\n",
      "Current iteration=600, loss=0.5639790972357753\n",
      "Current iteration=700, loss=0.5639790972357752\n",
      "Current iteration=800, loss=0.5639790972357753\n",
      "Current iteration=900, loss=0.5639790972357751\n",
      "Current iteration=0, loss=0.5618162428221072\n",
      "Current iteration=100, loss=0.5617223328447493\n",
      "Current iteration=200, loss=0.5617222292607568\n",
      "Current iteration=300, loss=0.5617222274111253\n",
      "Current iteration=400, loss=0.5617222273743457\n",
      "Current iteration=500, loss=0.5617222273735749\n",
      "Current iteration=600, loss=0.5617222273735583\n",
      "Current iteration=700, loss=0.5617222273735578\n",
      "Current iteration=800, loss=0.5617222273735578\n",
      "Current iteration=900, loss=0.5617222273735578\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.5672029137298363\n",
      "Current iteration=100, loss=0.5667528684884365\n",
      "Current iteration=200, loss=0.5667520501300232\n",
      "Current iteration=300, loss=0.5667520449435288\n",
      "Current iteration=400, loss=0.566752044905534\n",
      "Current iteration=500, loss=0.5667520449052376\n",
      "Current iteration=600, loss=0.566752044905235\n",
      "Current iteration=700, loss=0.5667520449052351\n",
      "Current iteration=800, loss=0.566752044905235\n",
      "Current iteration=900, loss=0.5667520449052351\n",
      "Current iteration=0, loss=0.5655263137530484\n",
      "Current iteration=100, loss=0.5654318137048957\n",
      "Current iteration=200, loss=0.5654317698990895\n",
      "Current iteration=300, loss=0.5654317696312076\n",
      "Current iteration=400, loss=0.5654317696293524\n",
      "Current iteration=500, loss=0.5654317696293383\n",
      "Current iteration=600, loss=0.565431769629338\n",
      "Current iteration=700, loss=0.5654317696293382\n",
      "Current iteration=800, loss=0.565431769629338\n",
      "Current iteration=900, loss=0.5654317696293379\n",
      "Current iteration=0, loss=0.5686573855276202\n",
      "Current iteration=100, loss=0.5685823008808328\n",
      "Current iteration=200, loss=0.5685822600179854\n",
      "Current iteration=300, loss=0.5685822598069104\n",
      "Current iteration=400, loss=0.5685822598057496\n",
      "Current iteration=500, loss=0.5685822598057427\n",
      "Current iteration=600, loss=0.5685822598057427\n",
      "Current iteration=700, loss=0.5685822598057427\n",
      "Current iteration=800, loss=0.5685822598057428\n",
      "Current iteration=900, loss=0.5685822598057427\n",
      "Current iteration=0, loss=0.5664914002549483\n",
      "Current iteration=100, loss=0.5664038520004625\n",
      "Current iteration=200, loss=0.5664038211374153\n",
      "Current iteration=300, loss=0.5664038209336862\n",
      "Current iteration=400, loss=0.5664038209321739\n",
      "Current iteration=500, loss=0.566403820932162\n",
      "Current iteration=600, loss=0.5664038209321618\n",
      "Current iteration=700, loss=0.5664038209321618\n",
      "Current iteration=800, loss=0.5664038209321619\n",
      "Current iteration=900, loss=0.5664038209321618\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.5726438016651355\n",
      "Current iteration=100, loss=0.5721219626916091\n",
      "Current iteration=200, loss=0.572121767129115\n",
      "Current iteration=300, loss=0.5721217668119901\n",
      "Current iteration=400, loss=0.5721217668113778\n",
      "Current iteration=500, loss=0.5721217668113765\n",
      "Current iteration=600, loss=0.5721217668113766\n",
      "Current iteration=700, loss=0.5721217668113765\n",
      "Current iteration=800, loss=0.5721217668113765\n",
      "Current iteration=900, loss=0.5721217668113765\n",
      "Current iteration=0, loss=0.5708731935180897\n",
      "Current iteration=100, loss=0.5707843044318365\n",
      "Current iteration=200, loss=0.5707842947688039\n",
      "Current iteration=300, loss=0.5707842947531792\n",
      "Current iteration=400, loss=0.5707842947531502\n",
      "Current iteration=500, loss=0.5707842947531501\n",
      "Current iteration=600, loss=0.5707842947531501\n",
      "Current iteration=700, loss=0.5707842947531501\n",
      "Current iteration=800, loss=0.5707842947531501\n",
      "Current iteration=900, loss=0.5707842947531502\n",
      "Current iteration=0, loss=0.5739391996604285\n",
      "Current iteration=100, loss=0.5738695700035022\n",
      "Current iteration=200, loss=0.5738695610520126\n",
      "Current iteration=300, loss=0.5738695610395805\n",
      "Current iteration=400, loss=0.5738695610395621\n",
      "Current iteration=500, loss=0.573869561039562\n",
      "Current iteration=600, loss=0.5738695610395622\n",
      "Current iteration=700, loss=0.573869561039562\n",
      "Current iteration=800, loss=0.5738695610395621\n",
      "Current iteration=900, loss=0.5738695610395621\n",
      "Current iteration=0, loss=0.5718617267861429\n",
      "Current iteration=100, loss=0.5717815406496438\n",
      "Current iteration=200, loss=0.5717815343065464\n",
      "Current iteration=300, loss=0.571781534295649\n",
      "Current iteration=400, loss=0.5717815342956277\n",
      "Current iteration=500, loss=0.5717815342956278\n",
      "Current iteration=600, loss=0.5717815342956278\n",
      "Current iteration=700, loss=0.5717815342956278\n",
      "Current iteration=800, loss=0.5717815342956276\n",
      "Current iteration=900, loss=0.5717815342956278\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.5788124737711355\n",
      "Current iteration=100, loss=0.5782190022694496\n",
      "Current iteration=200, loss=0.5782189753385629\n",
      "Current iteration=300, loss=0.578218975331739\n",
      "Current iteration=400, loss=0.5782189753317369\n",
      "Current iteration=500, loss=0.5782189753317368\n",
      "Current iteration=600, loss=0.5782189753317368\n",
      "Current iteration=700, loss=0.5782189753317368\n",
      "Current iteration=800, loss=0.5782189753317369\n",
      "Current iteration=900, loss=0.5782189753317369\n",
      "Current iteration=0, loss=0.5769598120164485\n",
      "Current iteration=100, loss=0.5768770835746883\n",
      "Current iteration=200, loss=0.576877082283239\n",
      "Current iteration=300, loss=0.5768770822828994\n",
      "Current iteration=400, loss=0.5768770822828991\n",
      "Current iteration=500, loss=0.5768770822828992\n",
      "Current iteration=600, loss=0.5768770822828992\n",
      "Current iteration=700, loss=0.5768770822828991\n",
      "Current iteration=800, loss=0.5768770822828994\n",
      "Current iteration=900, loss=0.5768770822828994\n",
      "Current iteration=0, loss=0.5799381201517428\n",
      "Current iteration=100, loss=0.5798745877317587\n",
      "Current iteration=200, loss=0.5798745865707685\n",
      "Current iteration=300, loss=0.5798745865705042\n",
      "Current iteration=400, loss=0.5798745865705041\n",
      "Current iteration=500, loss=0.5798745865705043\n",
      "Current iteration=600, loss=0.5798745865705042\n",
      "Current iteration=700, loss=0.5798745865705042\n",
      "Current iteration=800, loss=0.5798745865705042\n",
      "Current iteration=900, loss=0.5798745865705042\n",
      "Current iteration=0, loss=0.5779634181935578\n",
      "Current iteration=100, loss=0.5778915204498916\n",
      "Current iteration=200, loss=0.5778915196669708\n",
      "Current iteration=300, loss=0.5778915196667553\n",
      "Current iteration=400, loss=0.5778915196667553\n",
      "Current iteration=500, loss=0.5778915196667552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.5778915196667553\n",
      "Current iteration=700, loss=0.5778915196667553\n",
      "Current iteration=800, loss=0.5778915196667552\n",
      "Current iteration=900, loss=0.5778915196667553\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.5857213524871508\n",
      "Current iteration=100, loss=0.5850600593464093\n",
      "Current iteration=200, loss=0.5850600575720886\n",
      "Current iteration=300, loss=0.5850600575720533\n",
      "Current iteration=400, loss=0.585060057572053\n",
      "Current iteration=500, loss=0.5850600575720531\n",
      "Current iteration=600, loss=0.5850600575720533\n",
      "Current iteration=700, loss=0.5850600575720533\n",
      "Current iteration=800, loss=0.5850600575720533\n",
      "Current iteration=900, loss=0.5850600575720533\n",
      "Current iteration=0, loss=0.5838040968261997\n",
      "Current iteration=100, loss=0.5837283149318189\n",
      "Current iteration=200, loss=0.5837283148459248\n",
      "Current iteration=300, loss=0.5837283148459229\n",
      "Current iteration=400, loss=0.5837283148459229\n",
      "Current iteration=500, loss=0.5837283148459228\n",
      "Current iteration=600, loss=0.583728314845923\n",
      "Current iteration=700, loss=0.583728314845923\n",
      "Current iteration=800, loss=0.583728314845923\n",
      "Current iteration=900, loss=0.583728314845923\n",
      "Current iteration=0, loss=0.5866686923608012\n",
      "Current iteration=100, loss=0.5866119091883596\n",
      "Current iteration=200, loss=0.586611909115083\n",
      "Current iteration=300, loss=0.5866119091150815\n",
      "Current iteration=400, loss=0.5866119091150817\n",
      "Current iteration=500, loss=0.5866119091150815\n",
      "Current iteration=600, loss=0.5866119091150815\n",
      "Current iteration=700, loss=0.5866119091150815\n",
      "Current iteration=800, loss=0.5866119091150815\n",
      "Current iteration=900, loss=0.5866119091150815\n",
      "Current iteration=0, loss=0.5848123887749846\n",
      "Current iteration=100, loss=0.5847495066104502\n",
      "Current iteration=200, loss=0.5847495065628666\n",
      "Current iteration=300, loss=0.5847495065628656\n",
      "Current iteration=400, loss=0.5847495065628655\n",
      "Current iteration=500, loss=0.5847495065628655\n",
      "Current iteration=600, loss=0.5847495065628656\n",
      "Current iteration=700, loss=0.5847495065628656\n",
      "Current iteration=800, loss=0.5847495065628656\n",
      "Current iteration=900, loss=0.5847495065628656\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.593349048157518\n",
      "Current iteration=100, loss=0.5926294075279052\n",
      "Current iteration=200, loss=0.5926294074854024\n",
      "Current iteration=300, loss=0.5926294074854024\n",
      "Current iteration=400, loss=0.5926294074854024\n",
      "Current iteration=500, loss=0.5926294074854023\n",
      "Current iteration=600, loss=0.5926294074854023\n",
      "Current iteration=700, loss=0.5926294074854023\n",
      "Current iteration=800, loss=0.5926294074854023\n",
      "Current iteration=900, loss=0.5926294074854023\n",
      "Current iteration=0, loss=0.5913921065669419\n",
      "Current iteration=100, loss=0.5913242945167927\n",
      "Current iteration=200, loss=0.5913242945146522\n",
      "Current iteration=300, loss=0.5913242945146521\n",
      "Current iteration=400, loss=0.5913242945146522\n",
      "Current iteration=500, loss=0.5913242945146521\n",
      "Current iteration=600, loss=0.5913242945146521\n",
      "Current iteration=700, loss=0.5913242945146521\n",
      "Current iteration=800, loss=0.5913242945146521\n",
      "Current iteration=900, loss=0.5913242945146521\n",
      "Current iteration=0, loss=0.5941146401584364\n",
      "Current iteration=100, loss=0.5940652153826782\n",
      "Current iteration=200, loss=0.5940652153809789\n",
      "Current iteration=300, loss=0.5940652153809788\n",
      "Current iteration=400, loss=0.5940652153809789\n",
      "Current iteration=500, loss=0.5940652153809789\n",
      "Current iteration=600, loss=0.5940652153809789\n",
      "Current iteration=700, loss=0.5940652153809789\n",
      "Current iteration=800, loss=0.5940652153809789\n",
      "Current iteration=900, loss=0.5940652153809789\n",
      "Current iteration=0, loss=0.59239194185448\n",
      "Current iteration=100, loss=0.5923385123612647\n",
      "Current iteration=200, loss=0.5923385123601922\n",
      "Current iteration=300, loss=0.5923385123601923\n",
      "Current iteration=400, loss=0.5923385123601924\n",
      "Current iteration=500, loss=0.5923385123601924\n",
      "Current iteration=600, loss=0.5923385123601924\n",
      "Current iteration=700, loss=0.5923385123601924\n",
      "Current iteration=800, loss=0.5923385123601924\n",
      "Current iteration=900, loss=0.5923385123601924\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.6016254914307265\n",
      "Current iteration=100, loss=0.600865504994933\n",
      "Current iteration=200, loss=0.6008655049946862\n",
      "Current iteration=300, loss=0.6008655049946862\n",
      "Current iteration=400, loss=0.600865504994686\n",
      "Current iteration=500, loss=0.600865504994686\n",
      "Current iteration=600, loss=0.600865504994686\n",
      "Current iteration=700, loss=0.600865504994686\n",
      "Current iteration=800, loss=0.600865504994686\n",
      "Current iteration=900, loss=0.600865504994686\n",
      "Current iteration=0, loss=0.5996637141019302\n",
      "Current iteration=100, loss=0.5996050251528018\n",
      "Current iteration=200, loss=0.5996050251527886\n",
      "Current iteration=300, loss=0.5996050251527886\n",
      "Current iteration=400, loss=0.5996050251527887\n",
      "Current iteration=500, loss=0.5996050251527887\n",
      "Current iteration=600, loss=0.5996050251527887\n",
      "Current iteration=700, loss=0.5996050251527887\n",
      "Current iteration=800, loss=0.5996050251527887\n",
      "Current iteration=900, loss=0.5996050251527887\n",
      "Current iteration=0, loss=0.6022152137129759\n",
      "Current iteration=100, loss=0.6021736324703006\n",
      "Current iteration=200, loss=0.6021736324702912\n",
      "Current iteration=300, loss=0.6021736324702911\n",
      "Current iteration=400, loss=0.6021736324702911\n",
      "Current iteration=500, loss=0.6021736324702911\n",
      "Current iteration=600, loss=0.6021736324702911\n",
      "Current iteration=700, loss=0.6021736324702911\n",
      "Current iteration=800, loss=0.6021736324702911\n",
      "Current iteration=900, loss=0.6021736324702911\n",
      "Current iteration=0, loss=0.6006391160310464\n",
      "Current iteration=100, loss=0.600595240515179\n",
      "Current iteration=200, loss=0.6005952405151731\n",
      "Current iteration=300, loss=0.6005952405151731\n",
      "Current iteration=400, loss=0.6005952405151731\n",
      "Current iteration=500, loss=0.6005952405151731\n",
      "Current iteration=600, loss=0.6005952405151731\n",
      "Current iteration=700, loss=0.6005952405151731\n",
      "Current iteration=800, loss=0.6005952405151731\n",
      "Current iteration=900, loss=0.6005952405151731\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.6104197050114747\n",
      "Current iteration=100, loss=0.6096494574037074\n",
      "Current iteration=200, loss=0.6096494574037071\n",
      "Current iteration=300, loss=0.6096494574037072\n",
      "Current iteration=400, loss=0.6096494574037072\n",
      "Current iteration=500, loss=0.6096494574037072\n",
      "Current iteration=600, loss=0.6096494574037072\n",
      "Current iteration=700, loss=0.6096494574037072\n",
      "Current iteration=800, loss=0.6096494574037072\n",
      "Current iteration=900, loss=0.6096494574037072\n",
      "Current iteration=0, loss=0.6085006059967114\n",
      "Current iteration=100, loss=0.6084521278740112\n",
      "Current iteration=200, loss=0.6084521278740113\n",
      "Current iteration=300, loss=0.6084521278740112\n",
      "Current iteration=400, loss=0.6084521278740112\n",
      "Current iteration=500, loss=0.6084521278740112\n",
      "Current iteration=600, loss=0.6084521278740112\n",
      "Current iteration=700, loss=0.6084521278740112\n",
      "Current iteration=800, loss=0.6084521278740112\n",
      "Current iteration=900, loss=0.6084521278740112\n",
      "Current iteration=0, loss=0.610853717494639\n",
      "Current iteration=100, loss=0.6108202476553016\n",
      "Current iteration=200, loss=0.6108202476553017\n",
      "Current iteration=300, loss=0.6108202476553016\n",
      "Current iteration=400, loss=0.6108202476553016\n",
      "Current iteration=500, loss=0.6108202476553016\n",
      "Current iteration=600, loss=0.6108202476553016\n",
      "Current iteration=700, loss=0.6108202476553016\n",
      "Current iteration=800, loss=0.6108202476553016\n",
      "Current iteration=900, loss=0.6108202476553016\n",
      "Current iteration=0, loss=0.6094336095491204\n",
      "Current iteration=100, loss=0.609399046668502\n",
      "Current iteration=200, loss=0.6093990466685019\n",
      "Current iteration=300, loss=0.6093990466685018\n",
      "Current iteration=400, loss=0.6093990466685018\n",
      "Current iteration=500, loss=0.6093990466685018\n",
      "Current iteration=600, loss=0.6093990466685018\n",
      "Current iteration=700, loss=0.6093990466685018\n",
      "Current iteration=800, loss=0.6093990466685018\n",
      "Current iteration=900, loss=0.6093990466685018\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.6195372100602046\n",
      "Current iteration=100, loss=0.6188013534932472\n",
      "Current iteration=200, loss=0.6188013534932473\n",
      "Current iteration=300, loss=0.6188013534932473\n",
      "Current iteration=400, loss=0.6188013534932473\n",
      "Current iteration=500, loss=0.6188013534932473\n",
      "Current iteration=600, loss=0.6188013534932473\n",
      "Current iteration=700, loss=0.6188013534932473\n",
      "Current iteration=800, loss=0.6188013534932473\n",
      "Current iteration=900, loss=0.6188013534932473\n",
      "Current iteration=0, loss=0.6177222263550177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.6176847189060796\n",
      "Current iteration=200, loss=0.6176847189060796\n",
      "Current iteration=300, loss=0.6176847189060796\n",
      "Current iteration=400, loss=0.6176847189060796\n",
      "Current iteration=500, loss=0.6176847189060796\n",
      "Current iteration=600, loss=0.6176847189060796\n",
      "Current iteration=700, loss=0.6176847189060796\n",
      "Current iteration=800, loss=0.6176847189060796\n",
      "Current iteration=900, loss=0.6176847189060796\n",
      "Current iteration=0, loss=0.6198536716707944\n",
      "Current iteration=100, loss=0.6198282753555321\n",
      "Current iteration=200, loss=0.619828275355532\n",
      "Current iteration=300, loss=0.619828275355532\n",
      "Current iteration=400, loss=0.619828275355532\n",
      "Current iteration=500, loss=0.619828275355532\n",
      "Current iteration=600, loss=0.619828275355532\n",
      "Current iteration=700, loss=0.619828275355532\n",
      "Current iteration=800, loss=0.619828275355532\n",
      "Current iteration=900, loss=0.619828275355532\n",
      "Current iteration=0, loss=0.6185945452523036\n",
      "Current iteration=100, loss=0.6185687279831036\n",
      "Current iteration=200, loss=0.6185687279831036\n",
      "Current iteration=300, loss=0.6185687279831036\n",
      "Current iteration=400, loss=0.6185687279831036\n",
      "Current iteration=500, loss=0.6185687279831036\n",
      "Current iteration=600, loss=0.6185687279831036\n",
      "Current iteration=700, loss=0.6185687279831036\n",
      "Current iteration=800, loss=0.6185687279831036\n",
      "Current iteration=900, loss=0.6185687279831036\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.6287329628194802\n",
      "Current iteration=100, loss=0.6280885870968632\n",
      "Current iteration=200, loss=0.6280885870968631\n",
      "Current iteration=300, loss=0.6280885870968631\n",
      "Current iteration=400, loss=0.6280885870968631\n",
      "Current iteration=500, loss=0.6280885870968631\n",
      "Current iteration=600, loss=0.6280885870968631\n",
      "Current iteration=700, loss=0.6280885870968631\n",
      "Current iteration=800, loss=0.6280885870968631\n",
      "Current iteration=900, loss=0.6280885870968631\n",
      "Current iteration=0, loss=0.6270939815447025\n",
      "Current iteration=100, loss=0.6270675736878755\n",
      "Current iteration=200, loss=0.6270675736878754\n",
      "Current iteration=300, loss=0.6270675736878754\n",
      "Current iteration=400, loss=0.6270675736878754\n",
      "Current iteration=500, loss=0.6270675736878754\n",
      "Current iteration=600, loss=0.6270675736878754\n",
      "Current iteration=700, loss=0.6270675736878754\n",
      "Current iteration=800, loss=0.6270675736878754\n",
      "Current iteration=900, loss=0.6270675736878754\n",
      "Current iteration=0, loss=0.6289868687089141\n",
      "Current iteration=100, loss=0.6289691269280829\n",
      "Current iteration=200, loss=0.6289691269280829\n",
      "Current iteration=300, loss=0.6289691269280829\n",
      "Current iteration=400, loss=0.6289691269280829\n",
      "Current iteration=500, loss=0.6289691269280829\n",
      "Current iteration=600, loss=0.6289691269280829\n",
      "Current iteration=700, loss=0.6289691269280829\n",
      "Current iteration=800, loss=0.6289691269280829\n",
      "Current iteration=900, loss=0.6289691269280829\n",
      "Current iteration=0, loss=0.6278891148946588\n",
      "Current iteration=100, loss=0.6278711760480353\n",
      "Current iteration=200, loss=0.6278711760480354\n",
      "Current iteration=300, loss=0.6278711760480354\n",
      "Current iteration=400, loss=0.6278711760480354\n",
      "Current iteration=500, loss=0.6278711760480354\n",
      "Current iteration=600, loss=0.6278711760480354\n",
      "Current iteration=700, loss=0.6278711760480354\n",
      "Current iteration=800, loss=0.6278711760480354\n",
      "Current iteration=900, loss=0.6278711760480354\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.6377408002814486\n",
      "Current iteration=100, loss=0.637246635320663\n",
      "Current iteration=200, loss=0.637246635320663\n",
      "Current iteration=300, loss=0.637246635320663\n",
      "Current iteration=400, loss=0.637246635320663\n",
      "Current iteration=500, loss=0.637246635320663\n",
      "Current iteration=600, loss=0.637246635320663\n",
      "Current iteration=700, loss=0.637246635320663\n",
      "Current iteration=800, loss=0.637246635320663\n",
      "Current iteration=900, loss=0.637246635320663\n",
      "Current iteration=0, loss=0.6363482369735481\n",
      "Current iteration=100, loss=0.6363321155924013\n",
      "Current iteration=200, loss=0.6363321155924013\n",
      "Current iteration=300, loss=0.6363321155924013\n",
      "Current iteration=400, loss=0.6363321155924013\n",
      "Current iteration=500, loss=0.6363321155924013\n",
      "Current iteration=600, loss=0.6363321155924013\n",
      "Current iteration=700, loss=0.6363321155924013\n",
      "Current iteration=800, loss=0.6363321155924013\n",
      "Current iteration=900, loss=0.6363321155924013\n",
      "Current iteration=0, loss=0.6379938590395858\n",
      "Current iteration=100, loss=0.6379829085602134\n",
      "Current iteration=200, loss=0.6379829085602134\n",
      "Current iteration=300, loss=0.6379829085602134\n",
      "Current iteration=400, loss=0.6379829085602134\n",
      "Current iteration=500, loss=0.6379829085602134\n",
      "Current iteration=600, loss=0.6379829085602134\n",
      "Current iteration=700, loss=0.6379829085602134\n",
      "Current iteration=800, loss=0.6379829085602134\n",
      "Current iteration=900, loss=0.6379829085602134\n",
      "Current iteration=0, loss=0.6370534777775451\n",
      "Current iteration=100, loss=0.6370422731187811\n",
      "Current iteration=200, loss=0.6370422731187811\n",
      "Current iteration=300, loss=0.6370422731187811\n",
      "Current iteration=400, loss=0.6370422731187811\n",
      "Current iteration=500, loss=0.6370422731187811\n",
      "Current iteration=600, loss=0.6370422731187811\n",
      "Current iteration=700, loss=0.6370422731187811\n",
      "Current iteration=800, loss=0.6370422731187811\n",
      "Current iteration=900, loss=0.6370422731187811\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6463143759833989\n",
      "Current iteration=100, loss=0.6460085114604761\n",
      "Current iteration=200, loss=0.6460085114604761\n",
      "Current iteration=300, loss=0.6460085114604761\n",
      "Current iteration=400, loss=0.6460085114604761\n",
      "Current iteration=500, loss=0.6460085114604761\n",
      "Current iteration=600, loss=0.6460085114604761\n",
      "Current iteration=700, loss=0.6460085114604761\n",
      "Current iteration=800, loss=0.6460085114604761\n",
      "Current iteration=900, loss=0.6460085114604761\n",
      "Current iteration=0, loss=0.6452142764265109\n",
      "Current iteration=100, loss=0.6452063996449293\n",
      "Current iteration=200, loss=0.6452063996449293\n",
      "Current iteration=300, loss=0.6452063996449293\n",
      "Current iteration=400, loss=0.6452063996449293\n",
      "Current iteration=500, loss=0.6452063996449293\n",
      "Current iteration=600, loss=0.6452063996449293\n",
      "Current iteration=700, loss=0.6452063996449293\n",
      "Current iteration=800, loss=0.6452063996449293\n",
      "Current iteration=900, loss=0.6452063996449293\n",
      "Current iteration=0, loss=0.6466130472404509\n",
      "Current iteration=100, loss=0.6466075250521706\n",
      "Current iteration=200, loss=0.6466075250521706\n",
      "Current iteration=300, loss=0.6466075250521706\n",
      "Current iteration=400, loss=0.6466075250521706\n",
      "Current iteration=500, loss=0.6466075250521706\n",
      "Current iteration=600, loss=0.6466075250521706\n",
      "Current iteration=700, loss=0.6466075250521706\n",
      "Current iteration=800, loss=0.6466075250521706\n",
      "Current iteration=900, loss=0.6466075250521706\n",
      "Current iteration=0, loss=0.6458220685895536\n",
      "Current iteration=100, loss=0.6458161891288045\n",
      "Current iteration=200, loss=0.6458161891288045\n",
      "Current iteration=300, loss=0.6458161891288045\n",
      "Current iteration=400, loss=0.6458161891288045\n",
      "Current iteration=500, loss=0.6458161891288045\n",
      "Current iteration=600, loss=0.6458161891288045\n",
      "Current iteration=700, loss=0.6458161891288045\n",
      "Current iteration=800, loss=0.6458161891288045\n",
      "Current iteration=900, loss=0.6458161891288045\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6542707572855115\n",
      "Current iteration=100, loss=0.6541362946562619\n",
      "Current iteration=200, loss=0.6541362946562619\n",
      "Current iteration=300, loss=0.6541362946562619\n",
      "Current iteration=400, loss=0.6541362946562619\n",
      "Current iteration=500, loss=0.6541362946562619\n",
      "Current iteration=600, loss=0.6541362946562619\n",
      "Current iteration=700, loss=0.6541362946562619\n",
      "Current iteration=800, loss=0.6541362946562619\n",
      "Current iteration=900, loss=0.6541362946562619\n",
      "Current iteration=0, loss=0.6534504894034583\n",
      "Current iteration=100, loss=0.6534473410351451\n",
      "Current iteration=200, loss=0.6534473410351451\n",
      "Current iteration=300, loss=0.6534473410351451\n",
      "Current iteration=400, loss=0.6534473410351451\n",
      "Current iteration=500, loss=0.6534473410351451\n",
      "Current iteration=600, loss=0.6534473410351451\n",
      "Current iteration=700, loss=0.6534473410351451\n",
      "Current iteration=800, loss=0.6534473410351451\n",
      "Current iteration=900, loss=0.6534473410351451\n",
      "Current iteration=0, loss=0.6546117295999532\n",
      "Current iteration=100, loss=0.6546097182860966\n",
      "Current iteration=200, loss=0.6546097182860966\n",
      "Current iteration=300, loss=0.6546097182860966\n",
      "Current iteration=400, loss=0.6546097182860966\n",
      "Current iteration=500, loss=0.6546097182860966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.6546097182860966\n",
      "Current iteration=700, loss=0.6546097182860966\n",
      "Current iteration=800, loss=0.6546097182860966\n",
      "Current iteration=900, loss=0.6546097182860966\n",
      "Current iteration=0, loss=0.6539587272609223\n",
      "Current iteration=100, loss=0.6539564914211109\n",
      "Current iteration=200, loss=0.6539564914211109\n",
      "Current iteration=300, loss=0.6539564914211109\n",
      "Current iteration=400, loss=0.6539564914211109\n",
      "Current iteration=500, loss=0.6539564914211109\n",
      "Current iteration=600, loss=0.6539564914211109\n",
      "Current iteration=700, loss=0.6539564914211109\n",
      "Current iteration=800, loss=0.6539564914211109\n",
      "Current iteration=900, loss=0.6539564914211109\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.6615274813517454\n",
      "Current iteration=100, loss=0.6614475971260532\n",
      "Current iteration=200, loss=0.6614475971260532\n",
      "Current iteration=300, loss=0.6614475971260532\n",
      "Current iteration=400, loss=0.6614475971260532\n",
      "Current iteration=500, loss=0.6614475971260532\n",
      "Current iteration=600, loss=0.6614475971260532\n",
      "Current iteration=700, loss=0.6614475971260532\n",
      "Current iteration=800, loss=0.6614475971260532\n",
      "Current iteration=900, loss=0.6614475971260532\n",
      "Current iteration=0, loss=0.6608714763429269\n",
      "Current iteration=100, loss=0.6608678454286601\n",
      "Current iteration=200, loss=0.6608678454286601\n",
      "Current iteration=300, loss=0.6608678454286601\n",
      "Current iteration=400, loss=0.6608678454286601\n",
      "Current iteration=500, loss=0.6608678454286601\n",
      "Current iteration=600, loss=0.6608678454286601\n",
      "Current iteration=700, loss=0.6608678454286601\n",
      "Current iteration=800, loss=0.6608678454286601\n",
      "Current iteration=900, loss=0.6608678454286601\n",
      "Current iteration=0, loss=0.6618119466350199\n",
      "Current iteration=100, loss=0.6618109069956569\n",
      "Current iteration=200, loss=0.6618109069956569\n",
      "Current iteration=300, loss=0.6618109069956569\n",
      "Current iteration=400, loss=0.6618109069956569\n",
      "Current iteration=500, loss=0.6618109069956569\n",
      "Current iteration=600, loss=0.6618109069956569\n",
      "Current iteration=700, loss=0.6618109069956569\n",
      "Current iteration=800, loss=0.6618109069956569\n",
      "Current iteration=900, loss=0.6618109069956569\n",
      "Current iteration=0, loss=0.6612826349293037\n",
      "Current iteration=100, loss=0.6612820499283217\n",
      "Current iteration=200, loss=0.6612820499283217\n",
      "Current iteration=300, loss=0.6612820499283217\n",
      "Current iteration=400, loss=0.6612820499283217\n",
      "Current iteration=500, loss=0.6612820499283217\n",
      "Current iteration=600, loss=0.6612820499283217\n",
      "Current iteration=700, loss=0.6612820499283217\n",
      "Current iteration=800, loss=0.6612820499283217\n",
      "Current iteration=900, loss=0.6612820499283217\n",
      "Iteration 28\n",
      "Current iteration=0, loss=0.6681262628180092\n",
      "Current iteration=100, loss=0.6678313637531179\n",
      "Current iteration=200, loss=0.6678313637531056\n",
      "Current iteration=300, loss=0.6678313637531056\n",
      "Current iteration=400, loss=0.6678313637531056\n",
      "Current iteration=500, loss=0.6678313637531056\n",
      "Current iteration=600, loss=0.6678313637531056\n",
      "Current iteration=700, loss=0.6678313637531056\n",
      "Current iteration=800, loss=0.6678313637531056\n",
      "Current iteration=900, loss=0.6678313637531056\n",
      "Current iteration=0, loss=0.6673643468628686\n",
      "Current iteration=100, loss=0.6673530774635068\n",
      "Current iteration=200, loss=0.6673530774635065\n",
      "Current iteration=300, loss=0.6673530774635067\n",
      "Current iteration=400, loss=0.6673530774635067\n",
      "Current iteration=500, loss=0.6673530774635067\n",
      "Current iteration=600, loss=0.6673530774635067\n",
      "Current iteration=700, loss=0.6673530774635067\n",
      "Current iteration=800, loss=0.6673530774635067\n",
      "Current iteration=900, loss=0.6673530774635067\n",
      "Current iteration=0, loss=0.6681057126506642\n",
      "Current iteration=100, loss=0.6681023803687396\n",
      "Current iteration=200, loss=0.6681023803687394\n",
      "Current iteration=300, loss=0.6681023803687394\n",
      "Current iteration=400, loss=0.6681023803687394\n",
      "Current iteration=500, loss=0.6681023803687394\n",
      "Current iteration=600, loss=0.6681023803687394\n",
      "Current iteration=700, loss=0.6681023803687394\n",
      "Current iteration=800, loss=0.6681023803687394\n",
      "Current iteration=900, loss=0.6681023803687394\n",
      "Current iteration=0, loss=0.6676836807801839\n",
      "Current iteration=100, loss=0.6676823622080577\n",
      "Current iteration=200, loss=0.6676823622080577\n",
      "Current iteration=300, loss=0.6676823622080575\n",
      "Current iteration=400, loss=0.6676823622080575\n",
      "Current iteration=500, loss=0.6676823622080575\n",
      "Current iteration=600, loss=0.6676823622080575\n",
      "Current iteration=700, loss=0.6676823622080575\n",
      "Current iteration=800, loss=0.6676823622080575\n",
      "Current iteration=900, loss=0.6676823622080575\n",
      "Iteration 29\n",
      "Current iteration=0, loss=0.6742410430262624\n",
      "Current iteration=100, loss=0.9670563837465316\n",
      "Current iteration=200, loss=0.9670563838049007\n",
      "Current iteration=300, loss=0.9670563838049007\n",
      "Current iteration=400, loss=0.9670563838049007\n",
      "Current iteration=500, loss=0.9670563838049007\n",
      "Current iteration=600, loss=0.9670563838049007\n",
      "Current iteration=700, loss=0.9670563838049007\n",
      "Current iteration=800, loss=0.9670563838049007\n",
      "Current iteration=900, loss=0.9670563838049007\n",
      "Current iteration=0, loss=0.9647307340281532\n",
      "Current iteration=100, loss=0.968635536656127\n",
      "Current iteration=200, loss=0.968635536656159\n",
      "Current iteration=300, loss=0.968635536656159\n",
      "Current iteration=400, loss=0.968635536656159\n",
      "Current iteration=500, loss=0.968635536656159\n",
      "Current iteration=600, loss=0.968635536656159\n",
      "Current iteration=700, loss=0.968635536656159\n",
      "Current iteration=800, loss=0.968635536656159\n",
      "Current iteration=900, loss=0.968635536656159\n",
      "Current iteration=0, loss=0.9709871707031261\n",
      "Current iteration=100, loss=0.9732761677613053\n",
      "Current iteration=200, loss=0.9732761677612753\n",
      "Current iteration=300, loss=0.9732761677612753\n",
      "Current iteration=400, loss=0.9732761677612753\n",
      "Current iteration=500, loss=0.9732761677612753\n",
      "Current iteration=600, loss=0.9732761677612753\n",
      "Current iteration=700, loss=0.9732761677612753\n",
      "Current iteration=800, loss=0.9732761677612753\n",
      "Current iteration=900, loss=0.9732761677612753\n",
      "Current iteration=0, loss=0.9709272266435132\n",
      "Current iteration=100, loss=0.9669196728715439\n",
      "Current iteration=200, loss=0.9669196728714868\n",
      "Current iteration=300, loss=0.9669196728714868\n",
      "Current iteration=400, loss=0.9669196728714868\n",
      "Current iteration=500, loss=0.9669196728714868\n",
      "Current iteration=600, loss=0.9669196728714868\n",
      "Current iteration=700, loss=0.9669196728714868\n",
      "Current iteration=800, loss=0.9669196728714868\n",
      "Current iteration=900, loss=0.9669196728714868\n",
      "Iteration 0\n",
      "Current iteration=0, loss=0.6054504860332675\n",
      "Current iteration=100, loss=0.5284642005880328\n",
      "Current iteration=200, loss=0.5261497396016063\n",
      "Current iteration=300, loss=0.5256326736678651\n",
      "Current iteration=400, loss=0.525481283388357\n",
      "Current iteration=500, loss=0.5254303468429427\n",
      "Current iteration=600, loss=0.5254115195509004\n",
      "Current iteration=700, loss=0.525404051685491\n",
      "Current iteration=800, loss=0.5254009107571885\n",
      "Current iteration=900, loss=0.5253995175197769\n",
      "Current iteration=0, loss=0.5215526131166799\n",
      "Current iteration=100, loss=0.5213214528069677\n",
      "Current iteration=200, loss=0.5213137534371381\n",
      "Current iteration=300, loss=0.5213119603916325\n",
      "Current iteration=400, loss=0.52131129903689\n",
      "Current iteration=500, loss=0.5213109812930167\n",
      "Current iteration=600, loss=0.5213108097407189\n",
      "Current iteration=700, loss=0.5213107127456866\n",
      "Current iteration=800, loss=0.5213106568968107\n",
      "Current iteration=900, loss=0.5213106244994383\n",
      "Current iteration=0, loss=0.5258767705828854\n",
      "Current iteration=100, loss=0.5256480762428353\n",
      "Current iteration=200, loss=0.525640690512773\n",
      "Current iteration=300, loss=0.5256389929984981\n",
      "Current iteration=400, loss=0.5256383698440729\n",
      "Current iteration=500, loss=0.5256380753781781\n",
      "Current iteration=600, loss=0.5256379203175051\n",
      "Current iteration=700, loss=0.5256378347536995\n",
      "Current iteration=800, loss=0.5256377864514717\n",
      "Current iteration=900, loss=0.5256377588434984\n",
      "Current iteration=0, loss=0.5252773368944078\n",
      "Current iteration=100, loss=0.5251379892781947\n",
      "Current iteration=200, loss=0.5251341666555781\n",
      "Current iteration=300, loss=0.5251330701907767\n",
      "Current iteration=400, loss=0.5251325500353335\n",
      "Current iteration=500, loss=0.5251322667360624\n",
      "Current iteration=600, loss=0.5251321059242915\n",
      "Current iteration=700, loss=0.525132013275966\n",
      "Current iteration=800, loss=0.5251319595504481\n",
      "Current iteration=900, loss=0.525131928291492\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.5258185843013279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.5255851045962932\n",
      "Current iteration=200, loss=0.5255790806502978\n",
      "Current iteration=300, loss=0.5255773233424786\n",
      "Current iteration=400, loss=0.5255765239722331\n",
      "Current iteration=500, loss=0.5255760998006285\n",
      "Current iteration=600, loss=0.5255758619701634\n",
      "Current iteration=700, loss=0.5255757259133841\n",
      "Current iteration=800, loss=0.5255756474927329\n",
      "Current iteration=900, loss=0.5255756021625196\n",
      "Current iteration=0, loss=0.5217383083656199\n",
      "Current iteration=100, loss=0.5215063340318691\n",
      "Current iteration=200, loss=0.5214980589971172\n",
      "Current iteration=300, loss=0.5214959113405145\n",
      "Current iteration=400, loss=0.5214950466921384\n",
      "Current iteration=500, loss=0.5214946154110396\n",
      "Current iteration=600, loss=0.5214943809643946\n",
      "Current iteration=700, loss=0.5214942491859645\n",
      "Current iteration=800, loss=0.5214941740930934\n",
      "Current iteration=900, loss=0.5214941310416461\n",
      "Current iteration=0, loss=0.5260542036914048\n",
      "Current iteration=100, loss=0.5258264454493501\n",
      "Current iteration=200, loss=0.5258192473239278\n",
      "Current iteration=300, loss=0.5258176153631806\n",
      "Current iteration=400, loss=0.5258170240418268\n",
      "Current iteration=500, loss=0.5258167482253674\n",
      "Current iteration=600, loss=0.5258166048222175\n",
      "Current iteration=700, loss=0.5258165266637971\n",
      "Current iteration=800, loss=0.525816483069844\n",
      "Current iteration=900, loss=0.5258164584445063\n",
      "Current iteration=0, loss=0.5254542993214344\n",
      "Current iteration=100, loss=0.5253156212670649\n",
      "Current iteration=200, loss=0.5253118726689261\n",
      "Current iteration=300, loss=0.5253108045394206\n",
      "Current iteration=400, loss=0.5253103020923805\n",
      "Current iteration=500, loss=0.5253100312444331\n",
      "Current iteration=600, loss=0.5253098791820484\n",
      "Current iteration=700, loss=0.5253097925502512\n",
      "Current iteration=800, loss=0.5253097428753308\n",
      "Current iteration=900, loss=0.525309714296169\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.526058797521761\n",
      "Current iteration=100, loss=0.5258250912743082\n",
      "Current iteration=200, loss=0.5258189989662767\n",
      "Current iteration=300, loss=0.5258172771948013\n",
      "Current iteration=400, loss=0.5258165225095762\n",
      "Current iteration=500, loss=0.5258161332472175\n",
      "Current iteration=600, loss=0.5258159197513409\n",
      "Current iteration=700, loss=0.5258157998910904\n",
      "Current iteration=800, loss=0.5258157319835333\n",
      "Current iteration=900, loss=0.5258156933672693\n",
      "Current iteration=0, loss=0.5219851283567506\n",
      "Current iteration=100, loss=0.52175434036063\n",
      "Current iteration=200, loss=0.5217462958175509\n",
      "Current iteration=300, loss=0.5217442274071136\n",
      "Current iteration=400, loss=0.521743403051839\n",
      "Current iteration=500, loss=0.5217429970768378\n",
      "Current iteration=600, loss=0.5217427795253271\n",
      "Current iteration=700, loss=0.5217426590638313\n",
      "Current iteration=800, loss=0.5217425914592869\n",
      "Current iteration=900, loss=0.5217425532912918\n",
      "Current iteration=0, loss=0.5262946594879241\n",
      "Current iteration=100, loss=0.5260680596456405\n",
      "Current iteration=200, loss=0.526061060300633\n",
      "Current iteration=300, loss=0.5260594868673024\n",
      "Current iteration=400, loss=0.5260589215287416\n",
      "Current iteration=500, loss=0.5260586609892953\n",
      "Current iteration=600, loss=0.5260585274496613\n",
      "Current iteration=700, loss=0.526058455760463\n",
      "Current iteration=800, loss=0.5260584163856964\n",
      "Current iteration=900, loss=0.5260583944845187\n",
      "Current iteration=0, loss=0.5256938558628671\n",
      "Current iteration=100, loss=0.5255560853422627\n",
      "Current iteration=200, loss=0.525552439038712\n",
      "Current iteration=300, loss=0.5255514106548648\n",
      "Current iteration=400, loss=0.5255509327693976\n",
      "Current iteration=500, loss=0.5255506788410818\n",
      "Current iteration=600, loss=0.5255505384275462\n",
      "Current iteration=700, loss=0.5255504596562846\n",
      "Current iteration=800, loss=0.5255504151814652\n",
      "Current iteration=900, loss=0.5255503899861717\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.526382767531567\n",
      "Current iteration=100, loss=0.5261484878733205\n",
      "Current iteration=200, loss=0.5261422484630487\n",
      "Current iteration=300, loss=0.5261405561697394\n",
      "Current iteration=400, loss=0.5261398521872707\n",
      "Current iteration=500, loss=0.5261395037911534\n",
      "Current iteration=600, loss=0.5261393187627451\n",
      "Current iteration=700, loss=0.5261392176613415\n",
      "Current iteration=800, loss=0.5261391617641239\n",
      "Current iteration=900, loss=0.5261391307002241\n",
      "Current iteration=0, loss=0.5223176728230929\n",
      "Current iteration=100, loss=0.5220884569398063\n",
      "Current iteration=200, loss=0.5220807168537632\n",
      "Current iteration=300, loss=0.5220787532537031\n",
      "Current iteration=400, loss=0.5220779819258242\n",
      "Current iteration=500, loss=0.5220776087833052\n",
      "Current iteration=600, loss=0.5220774127513551\n",
      "Current iteration=700, loss=0.5220773064257154\n",
      "Current iteration=800, loss=0.522077247993352\n",
      "Current iteration=900, loss=0.5220772156921081\n",
      "Current iteration=0, loss=0.5266186090237068\n",
      "Current iteration=100, loss=0.5263935520674773\n",
      "Current iteration=200, loss=0.526386814249153\n",
      "Current iteration=300, loss=0.5263853177599028\n",
      "Current iteration=400, loss=0.5263847865666519\n",
      "Current iteration=500, loss=0.526384545876242\n",
      "Current iteration=600, loss=0.5263844249273558\n",
      "Current iteration=700, loss=0.5263843613372033\n",
      "Current iteration=800, loss=0.5263843271420874\n",
      "Current iteration=900, loss=0.526384308521064\n",
      "Current iteration=0, loss=0.5260165416995699\n",
      "Current iteration=100, loss=0.525879985011137\n",
      "Current iteration=200, loss=0.525876474015524\n",
      "Current iteration=300, loss=0.5258754980040042\n",
      "Current iteration=400, loss=0.5258750521165353\n",
      "Current iteration=500, loss=0.5258748198518958\n",
      "Current iteration=600, loss=0.5258746940737751\n",
      "Current iteration=700, loss=0.5258746249915648\n",
      "Current iteration=800, loss=0.5258745868062427\n",
      "Current iteration=900, loss=0.5258745656277186\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.526816991764841\n",
      "Current iteration=100, loss=0.5265814817898496\n",
      "Current iteration=200, loss=0.5265749626980372\n",
      "Current iteration=300, loss=0.5265732843318356\n",
      "Current iteration=400, loss=0.526572634833594\n",
      "Current iteration=500, loss=0.5265723321383645\n",
      "Current iteration=600, loss=0.5265721787967688\n",
      "Current iteration=700, loss=0.5265720982424473\n",
      "Current iteration=800, loss=0.5265720552359984\n",
      "Current iteration=900, loss=0.5265720321003655\n",
      "Current iteration=0, loss=0.522762829429993\n",
      "Current iteration=100, loss=0.5225356717684458\n",
      "Current iteration=200, loss=0.5225283280225316\n",
      "Current iteration=300, loss=0.5225265007564528\n",
      "Current iteration=400, loss=0.5225257977855982\n",
      "Current iteration=500, loss=0.5225254661216203\n",
      "Current iteration=600, loss=0.5225252966020635\n",
      "Current iteration=700, loss=0.5225252072382377\n",
      "Current iteration=800, loss=0.5225251595240579\n",
      "Current iteration=900, loss=0.5225251339008413\n",
      "Current iteration=0, loss=0.5270522282322131\n",
      "Current iteration=100, loss=0.526829204377446\n",
      "Current iteration=200, loss=0.5268228056518853\n",
      "Current iteration=300, loss=0.5268214087498465\n",
      "Current iteration=400, loss=0.5268209216311546\n",
      "Current iteration=500, loss=0.5268207061321588\n",
      "Current iteration=600, loss=0.5268206007753887\n",
      "Current iteration=700, loss=0.526820546952006\n",
      "Current iteration=800, loss=0.526820518838545\n",
      "Current iteration=900, loss=0.5268205039686351\n",
      "Current iteration=0, loss=0.5264483735355517\n",
      "Current iteration=100, loss=0.5263134260692863\n",
      "Current iteration=200, loss=0.5263100917040363\n",
      "Current iteration=300, loss=0.5263091836156056\n",
      "Current iteration=400, loss=0.5263087785441918\n",
      "Current iteration=500, loss=0.5263085732579025\n",
      "Current iteration=600, loss=0.5263084652393346\n",
      "Current iteration=700, loss=0.5263084076117676\n",
      "Current iteration=800, loss=0.5263083766722735\n",
      "Current iteration=900, loss=0.5263083600043643\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.5273943559206681\n",
      "Current iteration=100, loss=0.5271564374665526\n",
      "Current iteration=200, loss=0.527149434680083\n",
      "Current iteration=300, loss=0.5271477443080377\n",
      "Current iteration=400, loss=0.5271471502349812\n",
      "Current iteration=500, loss=0.5271468960344209\n",
      "Current iteration=600, loss=0.527146775837253\n",
      "Current iteration=700, loss=0.5271467162136025\n",
      "Current iteration=800, loss=0.5271466859450179\n",
      "Current iteration=900, loss=0.527146670397233\n",
      "Current iteration=0, loss=0.5233538282716064\n",
      "Current iteration=100, loss=0.52312932344729\n",
      "Current iteration=200, loss=0.5231224855652467\n",
      "Current iteration=300, loss=0.5231208314460997\n",
      "Current iteration=400, loss=0.523120213946864\n",
      "Current iteration=500, loss=0.523119932685779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.5231197943004393\n",
      "Current iteration=700, loss=0.5231197241576175\n",
      "Current iteration=800, loss=0.5231196881626057\n",
      "Current iteration=900, loss=0.523119669586584\n",
      "Current iteration=0, loss=0.5276278643915682\n",
      "Current iteration=100, loss=0.5274074820903861\n",
      "Current iteration=200, loss=0.5274015146962816\n",
      "Current iteration=300, loss=0.5274002439586905\n",
      "Current iteration=400, loss=0.5273998122686089\n",
      "Current iteration=500, loss=0.5273996276638465\n",
      "Current iteration=600, loss=0.5273995407896261\n",
      "Current iteration=700, loss=0.527399498131812\n",
      "Current iteration=800, loss=0.527399476723361\n",
      "Current iteration=900, loss=0.527399465843521\n",
      "Current iteration=0, loss=0.5270214637293028\n",
      "Current iteration=100, loss=0.5268886256053631\n",
      "Current iteration=200, loss=0.5268855177795629\n",
      "Current iteration=300, loss=0.5268846958402413\n",
      "Current iteration=400, loss=0.5268843412955475\n",
      "Current iteration=500, loss=0.5268841683150063\n",
      "Current iteration=600, loss=0.5268840808230072\n",
      "Current iteration=700, loss=0.5268840359725586\n",
      "Current iteration=800, loss=0.5268840128358029\n",
      "Current iteration=900, loss=0.5268840008588106\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.5281543378038702\n",
      "Current iteration=100, loss=0.5279120104391708\n",
      "Current iteration=200, loss=0.527904247081355\n",
      "Current iteration=300, loss=0.5279025150587505\n",
      "Current iteration=400, loss=0.527901976113338\n",
      "Current iteration=500, loss=0.5279017708528133\n",
      "Current iteration=600, loss=0.5279016828973226\n",
      "Current iteration=700, loss=0.5279016427432952\n",
      "Current iteration=800, loss=0.5279016237861679\n",
      "Current iteration=900, loss=0.5279016146700757\n",
      "Current iteration=0, loss=0.5241303776009509\n",
      "Current iteration=100, loss=0.523909224788383\n",
      "Current iteration=200, loss=0.5239030155435166\n",
      "Current iteration=300, loss=0.5239015739171216\n",
      "Current iteration=400, loss=0.5239010586380114\n",
      "Current iteration=500, loss=0.5239008352731555\n",
      "Current iteration=600, loss=0.5239007310267231\n",
      "Current iteration=700, loss=0.5239006809702488\n",
      "Current iteration=800, loss=0.5239006566458002\n",
      "Current iteration=900, loss=0.5239006447597465\n",
      "Current iteration=0, loss=0.5283841733796159\n",
      "Current iteration=100, loss=0.5281671606121149\n",
      "Current iteration=200, loss=0.528161728330951\n",
      "Current iteration=300, loss=0.528160612751584\n",
      "Current iteration=400, loss=0.5281602481573981\n",
      "Current iteration=500, loss=0.5281600995837742\n",
      "Current iteration=600, loss=0.5281600332766088\n",
      "Current iteration=700, loss=0.5281600024472716\n",
      "Current iteration=800, loss=0.5281599878015844\n",
      "Current iteration=900, loss=0.5281599807557152\n",
      "Current iteration=0, loss=0.527774122219677\n",
      "Current iteration=100, loss=0.5276440095997046\n",
      "Current iteration=200, loss=0.5276411855164079\n",
      "Current iteration=300, loss=0.527640469443997\n",
      "Current iteration=400, loss=0.5276401748257206\n",
      "Current iteration=500, loss=0.5276400384443244\n",
      "Current iteration=600, loss=0.5276399731118558\n",
      "Current iteration=700, loss=0.5276399414050151\n",
      "Current iteration=800, loss=0.5276399259200465\n",
      "Current iteration=900, loss=0.5276399183305293\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.5291423642562071\n",
      "Current iteration=100, loss=0.5288924303819601\n",
      "Current iteration=200, loss=0.52888359996224\n",
      "Current iteration=300, loss=0.5288818131078571\n",
      "Current iteration=400, loss=0.5288813324821491\n",
      "Current iteration=500, loss=0.52888117486787\n",
      "Current iteration=600, loss=0.5288811158493726\n",
      "Current iteration=700, loss=0.5288810918952688\n",
      "Current iteration=800, loss=0.528881081701396\n",
      "Current iteration=900, loss=0.5288810772391357\n",
      "Current iteration=0, loss=0.525137958821776\n",
      "Current iteration=100, loss=0.5249209380350993\n",
      "Current iteration=200, loss=0.524915482582245\n",
      "Current iteration=300, loss=0.524914289461091\n",
      "Current iteration=400, loss=0.5249138889140996\n",
      "Current iteration=500, loss=0.5249137269493981\n",
      "Current iteration=600, loss=0.5249136566923672\n",
      "Current iteration=700, loss=0.5249136253789386\n",
      "Current iteration=800, loss=0.5249136112603938\n",
      "Current iteration=900, loss=0.52491360485942\n",
      "Current iteration=0, loss=0.5293654519732781\n",
      "Current iteration=100, loss=0.5291526365744041\n",
      "Current iteration=200, loss=0.5291478468238551\n",
      "Current iteration=300, loss=0.5291469142650375\n",
      "Current iteration=400, loss=0.529146626465664\n",
      "Current iteration=500, loss=0.5291465169456272\n",
      "Current iteration=600, loss=0.5291464715382596\n",
      "Current iteration=700, loss=0.5291464519549229\n",
      "Current iteration=800, loss=0.5291464433270173\n",
      "Current iteration=900, loss=0.529146439476839\n",
      "Current iteration=0, loss=0.528750143873261\n",
      "Current iteration=100, loss=0.528623490503361\n",
      "Current iteration=200, loss=0.5286210105902411\n",
      "Current iteration=300, loss=0.5286204188851829\n",
      "Current iteration=400, loss=0.528620191127539\n",
      "Current iteration=500, loss=0.528620093088372\n",
      "Current iteration=600, loss=0.5286200495005355\n",
      "Current iteration=700, loss=0.5286200298756453\n",
      "Current iteration=800, loss=0.5286200209837052\n",
      "Current iteration=900, loss=0.5286200169399494\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.53040801969773\n",
      "Current iteration=100, loss=0.5301457193055791\n",
      "Current iteration=200, loss=0.5301356102369343\n",
      "Current iteration=300, loss=0.530133805769937\n",
      "Current iteration=400, loss=0.5301333959728702\n",
      "Current iteration=500, loss=0.5301332838586776\n",
      "Current iteration=600, loss=0.5301332486038407\n",
      "Current iteration=700, loss=0.5301332364133602\n",
      "Current iteration=800, loss=0.530133231927177\n",
      "Current iteration=900, loss=0.5301332302074643\n",
      "Current iteration=0, loss=0.5264260189977668\n",
      "Current iteration=100, loss=0.5262139409848833\n",
      "Current iteration=200, loss=0.526209347957305\n",
      "Current iteration=300, loss=0.5262084268557309\n",
      "Current iteration=400, loss=0.5262081442243854\n",
      "Current iteration=500, loss=0.5262080405531818\n",
      "Current iteration=600, loss=0.5262079999131537\n",
      "Current iteration=700, loss=0.5262079835651182\n",
      "Current iteration=800, loss=0.5262079769142334\n",
      "Current iteration=900, loss=0.5262079741932856\n",
      "Current iteration=0, loss=0.5306199239942052\n",
      "Current iteration=100, loss=0.5304121822501524\n",
      "Current iteration=200, loss=0.5304081317990159\n",
      "Current iteration=300, loss=0.5304074028094283\n",
      "Current iteration=400, loss=0.5304071960597375\n",
      "Current iteration=500, loss=0.5304071246457327\n",
      "Current iteration=600, loss=0.5304070979112341\n",
      "Current iteration=700, loss=0.530407087513685\n",
      "Current iteration=800, loss=0.5304070833826013\n",
      "Current iteration=900, loss=0.5304070817195498\n",
      "Current iteration=0, loss=0.529997048041322\n",
      "Current iteration=100, loss=0.5298746900511944\n",
      "Current iteration=200, loss=0.5298726098169374\n",
      "Current iteration=300, loss=0.5298721551641472\n",
      "Current iteration=400, loss=0.5298719958230054\n",
      "Current iteration=500, loss=0.5298719337843173\n",
      "Current iteration=600, loss=0.5298719088860598\n",
      "Current iteration=700, loss=0.5298718987702378\n",
      "Current iteration=800, loss=0.5298718946338583\n",
      "Current iteration=900, loss=0.5298718929359661\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.5320020611258309\n",
      "Current iteration=100, loss=0.5317209009184841\n",
      "Current iteration=200, loss=0.5317096144633431\n",
      "Current iteration=300, loss=0.5317079097444691\n",
      "Current iteration=400, loss=0.5317075924357562\n",
      "Current iteration=500, loss=0.5317075222718158\n",
      "Current iteration=600, loss=0.5317075044777908\n",
      "Current iteration=700, loss=0.5317074994819554\n",
      "Current iteration=800, loss=0.5317074979717279\n",
      "Current iteration=900, loss=0.5317074974899844\n",
      "Current iteration=0, loss=0.528045048986834\n",
      "Current iteration=100, loss=0.5278386786328141\n",
      "Current iteration=200, loss=0.5278350148470686\n",
      "Current iteration=300, loss=0.5278343663955097\n",
      "Current iteration=400, loss=0.5278341913686152\n",
      "Current iteration=500, loss=0.5278341353396657\n",
      "Current iteration=600, loss=0.5278341162432264\n",
      "Current iteration=700, loss=0.527834109571411\n",
      "Current iteration=800, loss=0.5278341072141043\n",
      "Current iteration=900, loss=0.5278341063763424\n",
      "Current iteration=0, loss=0.5321969849451962\n",
      "Current iteration=100, loss=0.5319951534734617\n",
      "Current iteration=200, loss=0.5319919079583706\n",
      "Current iteration=300, loss=0.5319913876348155\n",
      "Current iteration=400, loss=0.5319912571796895\n",
      "Current iteration=500, loss=0.5319912178599666\n",
      "Current iteration=600, loss=0.5319912050782705\n",
      "Current iteration=700, loss=0.5319912007653095\n",
      "Current iteration=800, loss=0.531991199277988\n",
      "Current iteration=900, loss=0.5319911987579932\n",
      "Current iteration=0, loss=0.5315632968923123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.5314461343172332\n",
      "Current iteration=200, loss=0.5314444917955161\n",
      "Current iteration=300, loss=0.5314441752985436\n",
      "Current iteration=400, loss=0.5314440780421728\n",
      "Current iteration=500, loss=0.5314440450679228\n",
      "Current iteration=600, loss=0.5314440335661581\n",
      "Current iteration=700, loss=0.5314440295057085\n",
      "Current iteration=800, loss=0.531444028062788\n",
      "Current iteration=900, loss=0.531444027547948\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.5339726587749054\n",
      "Current iteration=100, loss=0.5336647047870021\n",
      "Current iteration=200, loss=0.5336528896258381\n",
      "Current iteration=300, loss=0.5336514672349844\n",
      "Current iteration=400, loss=0.5336512597354977\n",
      "Current iteration=500, loss=0.5336512241090964\n",
      "Current iteration=600, loss=0.5336512171388712\n",
      "Current iteration=700, loss=0.5336512156317795\n",
      "Current iteration=800, loss=0.5336512152794319\n",
      "Current iteration=900, loss=0.5336512151917046\n",
      "Current iteration=0, loss=0.5300429522358169\n",
      "Current iteration=100, loss=0.5298429223685186\n",
      "Current iteration=200, loss=0.529840188514679\n",
      "Current iteration=300, loss=0.5298397839277591\n",
      "Current iteration=400, loss=0.5298396928675263\n",
      "Current iteration=500, loss=0.529839668752207\n",
      "Current iteration=600, loss=0.529839661975566\n",
      "Current iteration=700, loss=0.5298396600247822\n",
      "Current iteration=800, loss=0.5298396594566873\n",
      "Current iteration=900, loss=0.5298396592901976\n",
      "Current iteration=0, loss=0.5341438024959317\n",
      "Current iteration=100, loss=0.5339485698233272\n",
      "Current iteration=200, loss=0.5339461415567631\n",
      "Current iteration=300, loss=0.533945812747051\n",
      "Current iteration=400, loss=0.5339457437232451\n",
      "Current iteration=500, loss=0.5339457265277876\n",
      "Current iteration=600, loss=0.5339457219265525\n",
      "Current iteration=700, loss=0.5339457206487113\n",
      "Current iteration=800, loss=0.5339457202857175\n",
      "Current iteration=900, loss=0.5339457201810817\n",
      "Current iteration=0, loss=0.5334949335145593\n",
      "Current iteration=100, loss=0.5333838670149893\n",
      "Current iteration=200, loss=0.5333826682939675\n",
      "Current iteration=300, loss=0.5333824752464593\n",
      "Current iteration=400, loss=0.5333824258706804\n",
      "Current iteration=500, loss=0.5333824120305616\n",
      "Current iteration=600, loss=0.5333824080462995\n",
      "Current iteration=700, loss=0.5333824068855629\n",
      "Current iteration=800, loss=0.5333824065450884\n",
      "Current iteration=900, loss=0.5333824064447876\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.5363617791518812\n",
      "Current iteration=100, loss=0.5360186301996355\n",
      "Current iteration=200, loss=0.5360075214272408\n",
      "Current iteration=300, loss=0.5360065395441399\n",
      "Current iteration=400, loss=0.5360064345906982\n",
      "Current iteration=500, loss=0.5360064214000674\n",
      "Current iteration=600, loss=0.5360064195214712\n",
      "Current iteration=700, loss=0.5360064192278782\n",
      "Current iteration=800, loss=0.5360064191784533\n",
      "Current iteration=900, loss=0.5360064191695735\n",
      "Current iteration=0, loss=0.5324615456766639\n",
      "Current iteration=100, loss=0.5322683102947318\n",
      "Current iteration=200, loss=0.5322664299976058\n",
      "Current iteration=300, loss=0.5322662143137796\n",
      "Current iteration=400, loss=0.5322661767396653\n",
      "Current iteration=500, loss=0.5322661690926364\n",
      "Current iteration=600, loss=0.5322661674455115\n",
      "Current iteration=700, loss=0.5322661670820403\n",
      "Current iteration=800, loss=0.5322661670008303\n",
      "Current iteration=900, loss=0.5322661669825535\n",
      "Current iteration=0, loss=0.5365020385911088\n",
      "Current iteration=100, loss=0.5363138768607676\n",
      "Current iteration=200, loss=0.5363122106362744\n",
      "Current iteration=300, loss=0.5363120338793911\n",
      "Current iteration=400, loss=0.5363120050571041\n",
      "Current iteration=500, loss=0.5363119995459397\n",
      "Current iteration=600, loss=0.5363119984174091\n",
      "Current iteration=700, loss=0.5363119981773949\n",
      "Current iteration=800, loss=0.5363119981251044\n",
      "Current iteration=900, loss=0.5363119981135293\n",
      "Current iteration=0, loss=0.535832475902434\n",
      "Current iteration=100, loss=0.5357283275448039\n",
      "Current iteration=200, loss=0.535727536773672\n",
      "Current iteration=300, loss=0.5357274379007037\n",
      "Current iteration=400, loss=0.5357274183043218\n",
      "Current iteration=500, loss=0.5357274140744335\n",
      "Current iteration=600, loss=0.5357274131380315\n",
      "Current iteration=700, loss=0.5357274129282301\n",
      "Current iteration=800, loss=0.5357274128808867\n",
      "Current iteration=900, loss=0.5357274128701542\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.5392028167818813\n",
      "Current iteration=100, loss=0.538817169125455\n",
      "Current iteration=200, loss=0.5388081976113643\n",
      "Current iteration=300, loss=0.5388076754853951\n",
      "Current iteration=400, loss=0.5388076383161059\n",
      "Current iteration=500, loss=0.5388076351808416\n",
      "Current iteration=600, loss=0.5388076348818572\n",
      "Current iteration=700, loss=0.5388076348508474\n",
      "Current iteration=800, loss=0.5388076348474158\n",
      "Current iteration=900, loss=0.5388076348470127\n",
      "Current iteration=0, loss=0.5353342767240481\n",
      "Current iteration=100, loss=0.5351481801543486\n",
      "Current iteration=200, loss=0.5351470115228967\n",
      "Current iteration=300, loss=0.5351469180407205\n",
      "Current iteration=400, loss=0.5351469066704116\n",
      "Current iteration=500, loss=0.5351469050634281\n",
      "Current iteration=600, loss=0.5351469048233521\n",
      "Current iteration=700, loss=0.5351469047865655\n",
      "Current iteration=800, loss=0.5351469047808487\n",
      "Current iteration=900, loss=0.5351469047799526\n",
      "Current iteration=0, loss=0.5393055876432784\n",
      "Current iteration=100, loss=0.5391248226711427\n",
      "Current iteration=200, loss=0.5391237992112389\n",
      "Current iteration=300, loss=0.5391237226111979\n",
      "Current iteration=400, loss=0.5391237138531891\n",
      "Current iteration=500, loss=0.5391237126909989\n",
      "Current iteration=600, loss=0.5391237125261092\n",
      "Current iteration=700, loss=0.5391237125017706\n",
      "Current iteration=800, loss=0.5391237124980824\n",
      "Current iteration=900, loss=0.5391237124975138\n",
      "Current iteration=0, loss=0.5386090304909159\n",
      "Current iteration=100, loss=0.5385124674471494\n",
      "Current iteration=200, loss=0.5385120089048683\n",
      "Current iteration=300, loss=0.5385119686712571\n",
      "Current iteration=400, loss=0.5385119630694193\n",
      "Current iteration=500, loss=0.5385119622245224\n",
      "Current iteration=600, loss=0.5385119620939487\n",
      "Current iteration=700, loss=0.5385119620735203\n",
      "Current iteration=800, loss=0.5385119620702999\n",
      "Current iteration=900, loss=0.5385119620697897\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.5425202760025793\n",
      "Current iteration=100, loss=0.5420875529433745\n",
      "Current iteration=200, loss=0.5420816147843979\n",
      "Current iteration=300, loss=0.5420814175245723\n",
      "Current iteration=400, loss=0.5420814093231892\n",
      "Current iteration=500, loss=0.5420814089131326\n",
      "Current iteration=600, loss=0.5420814088899389\n",
      "Current iteration=700, loss=0.5420814088885246\n",
      "Current iteration=800, loss=0.5420814088884337\n",
      "Current iteration=900, loss=0.5420814088884276\n",
      "Current iteration=0, loss=0.5386861758525574\n",
      "Current iteration=100, loss=0.5385076602688289\n",
      "Current iteration=200, loss=0.5385070243073315\n",
      "Current iteration=300, loss=0.5385069936229196\n",
      "Current iteration=400, loss=0.5385069913605363\n",
      "Current iteration=500, loss=0.5385069911671961\n",
      "Current iteration=600, loss=0.5385069911497204\n",
      "Current iteration=700, loss=0.5385069911480964\n",
      "Current iteration=800, loss=0.538506991147943\n",
      "Current iteration=900, loss=0.5385069911479282\n",
      "Current iteration=0, loss=0.5425801559074359\n",
      "Current iteration=100, loss=0.5424072005800535\n",
      "Current iteration=200, loss=0.5424066579833619\n",
      "Current iteration=300, loss=0.5424066331643389\n",
      "Current iteration=400, loss=0.5424066314323384\n",
      "Current iteration=500, loss=0.5424066312931909\n",
      "Current iteration=600, loss=0.5424066312812429\n",
      "Current iteration=700, loss=0.542406631280173\n",
      "Current iteration=800, loss=0.5424066312800743\n",
      "Current iteration=900, loss=0.5424066312800648\n",
      "Current iteration=0, loss=0.5418503948751034\n",
      "Current iteration=100, loss=0.5417618745521842\n",
      "Current iteration=200, loss=0.5417616492719535\n",
      "Current iteration=300, loss=0.5417616371940748\n",
      "Current iteration=400, loss=0.5417616361613061\n",
      "Current iteration=500, loss=0.5417616360660253\n",
      "Current iteration=600, loss=0.5417616360570221\n",
      "Current iteration=700, loss=0.5417616360561606\n",
      "Current iteration=800, loss=0.5417616360560774\n",
      "Current iteration=900, loss=0.5417616360560693\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.5463318847489265\n",
      "Current iteration=100, loss=0.5458512688449856\n",
      "Current iteration=200, loss=0.5458482184367643\n",
      "Current iteration=300, loss=0.5458481706233221\n",
      "Current iteration=400, loss=0.5458481696544678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=500, loss=0.5458481696303821\n",
      "Current iteration=600, loss=0.5458481696297028\n",
      "Current iteration=700, loss=0.5458481696296826\n",
      "Current iteration=800, loss=0.5458481696296819\n",
      "Current iteration=900, loss=0.5458481696296817\n",
      "Current iteration=0, loss=0.542536630047612\n",
      "Current iteration=100, loss=0.5423664671134453\n",
      "Current iteration=200, loss=0.5423661789697052\n",
      "Current iteration=300, loss=0.542366172078055\n",
      "Current iteration=400, loss=0.5423661718237773\n",
      "Current iteration=500, loss=0.5423661718128941\n",
      "Current iteration=600, loss=0.5423661718124003\n",
      "Current iteration=700, loss=0.5423661718123772\n",
      "Current iteration=800, loss=0.542366171812376\n",
      "Current iteration=900, loss=0.542366171812376\n",
      "Current iteration=0, loss=0.5463453757971216\n",
      "Current iteration=100, loss=0.5461809818577855\n",
      "Current iteration=200, loss=0.5461807468929841\n",
      "Current iteration=300, loss=0.5461807414836578\n",
      "Current iteration=400, loss=0.5461807412925936\n",
      "Current iteration=500, loss=0.5461807412848718\n",
      "Current iteration=600, loss=0.5461807412845381\n",
      "Current iteration=700, loss=0.546180741284523\n",
      "Current iteration=800, loss=0.5461807412845223\n",
      "Current iteration=900, loss=0.5461807412845222\n",
      "Current iteration=0, loss=0.5455775895921134\n",
      "Current iteration=100, loss=0.5454973355744134\n",
      "Current iteration=200, loss=0.545497246360382\n",
      "Current iteration=300, loss=0.545497243941806\n",
      "Current iteration=400, loss=0.545497243836139\n",
      "Current iteration=500, loss=0.5454972438311703\n",
      "Current iteration=600, loss=0.5454972438309311\n",
      "Current iteration=700, loss=0.5454972438309192\n",
      "Current iteration=800, loss=0.5454972438309188\n",
      "Current iteration=900, loss=0.5454972438309187\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.5506532398886435\n",
      "Current iteration=100, loss=0.5501277012419465\n",
      "Current iteration=200, loss=0.5501265657670782\n",
      "Current iteration=300, loss=0.5501265592740134\n",
      "Current iteration=400, loss=0.5501265592240775\n",
      "Current iteration=500, loss=0.5501265592235952\n",
      "Current iteration=600, loss=0.5501265592235899\n",
      "Current iteration=700, loss=0.5501265592235898\n",
      "Current iteration=800, loss=0.5501265592235899\n",
      "Current iteration=900, loss=0.5501265592235898\n",
      "Current iteration=0, loss=0.5469046557468726\n",
      "Current iteration=100, loss=0.5467441106466953\n",
      "Current iteration=200, loss=0.5467440098929455\n",
      "Current iteration=300, loss=0.5467440089744188\n",
      "Current iteration=400, loss=0.5467440089613317\n",
      "Current iteration=500, loss=0.5467440089611146\n",
      "Current iteration=600, loss=0.5467440089611108\n",
      "Current iteration=700, loss=0.5467440089611106\n",
      "Current iteration=800, loss=0.5467440089611106\n",
      "Current iteration=900, loss=0.5467440089611106\n",
      "Current iteration=0, loss=0.550619477735916\n",
      "Current iteration=100, loss=0.5504649090423271\n",
      "Current iteration=200, loss=0.5504648320181647\n",
      "Current iteration=300, loss=0.5504648313306191\n",
      "Current iteration=400, loss=0.5504648313210875\n",
      "Current iteration=500, loss=0.550464831320937\n",
      "Current iteration=600, loss=0.5504648313209344\n",
      "Current iteration=700, loss=0.5504648313209345\n",
      "Current iteration=800, loss=0.5504648313209344\n",
      "Current iteration=900, loss=0.5504648313209345\n",
      "Current iteration=0, loss=0.5498116621188128\n",
      "Current iteration=100, loss=0.5497396763678496\n",
      "Current iteration=200, loss=0.5497396497422228\n",
      "Current iteration=300, loss=0.5497396494602595\n",
      "Current iteration=400, loss=0.5497396494553694\n",
      "Current iteration=500, loss=0.5497396494552783\n",
      "Current iteration=600, loss=0.5497396494552765\n",
      "Current iteration=700, loss=0.5497396494552764\n",
      "Current iteration=800, loss=0.5497396494552764\n",
      "Current iteration=900, loss=0.5497396494552765\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.5555041002115538\n",
      "Current iteration=100, loss=0.5549395863369212\n",
      "Current iteration=200, loss=0.5549393065671652\n",
      "Current iteration=300, loss=0.5549393061561197\n",
      "Current iteration=400, loss=0.5549393061552708\n",
      "Current iteration=500, loss=0.5549393061552684\n",
      "Current iteration=600, loss=0.5549393061552685\n",
      "Current iteration=700, loss=0.5549393061552685\n",
      "Current iteration=800, loss=0.5549393061552685\n",
      "Current iteration=900, loss=0.5549393061552683\n",
      "Current iteration=0, loss=0.551815384858271\n",
      "Current iteration=100, loss=0.5516663067469216\n",
      "Current iteration=200, loss=0.5516662824210034\n",
      "Current iteration=300, loss=0.5516662823615545\n",
      "Current iteration=400, loss=0.5516662823613243\n",
      "Current iteration=500, loss=0.5516662823613233\n",
      "Current iteration=600, loss=0.5516662823613233\n",
      "Current iteration=700, loss=0.5516662823613234\n",
      "Current iteration=800, loss=0.5516662823613233\n",
      "Current iteration=900, loss=0.5516662823613232\n",
      "Current iteration=0, loss=0.5554254663839541\n",
      "Current iteration=100, loss=0.5552825555062824\n",
      "Current iteration=200, loss=0.5552825382096803\n",
      "Current iteration=300, loss=0.5552825381675972\n",
      "Current iteration=400, loss=0.5552825381674357\n",
      "Current iteration=500, loss=0.5552825381674349\n",
      "Current iteration=600, loss=0.555282538167435\n",
      "Current iteration=700, loss=0.5552825381674349\n",
      "Current iteration=800, loss=0.5552825381674349\n",
      "Current iteration=900, loss=0.5552825381674349\n",
      "Current iteration=0, loss=0.5545795922247831\n",
      "Current iteration=100, loss=0.5545157054030004\n",
      "Current iteration=200, loss=0.5545156999398108\n",
      "Current iteration=300, loss=0.5545156999239196\n",
      "Current iteration=400, loss=0.5545156999238422\n",
      "Current iteration=500, loss=0.5545156999238419\n",
      "Current iteration=600, loss=0.5545156999238419\n",
      "Current iteration=700, loss=0.5545156999238419\n",
      "Current iteration=800, loss=0.5545156999238419\n",
      "Current iteration=900, loss=0.5545156999238419\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.5609141469311583\n",
      "Current iteration=100, loss=0.5603187625549684\n",
      "Current iteration=200, loss=0.5603187224631612\n",
      "Current iteration=300, loss=0.5603187224538375\n",
      "Current iteration=400, loss=0.5603187224538341\n",
      "Current iteration=500, loss=0.5603187224538343\n",
      "Current iteration=600, loss=0.5603187224538341\n",
      "Current iteration=700, loss=0.5603187224538342\n",
      "Current iteration=800, loss=0.5603187224538343\n",
      "Current iteration=900, loss=0.5603187224538343\n",
      "Current iteration=0, loss=0.5573056910380246\n",
      "Current iteration=100, loss=0.5571703393727669\n",
      "Current iteration=200, loss=0.5571703358985861\n",
      "Current iteration=300, loss=0.557170335897176\n",
      "Current iteration=400, loss=0.557170335897175\n",
      "Current iteration=500, loss=0.557170335897175\n",
      "Current iteration=600, loss=0.557170335897175\n",
      "Current iteration=700, loss=0.557170335897175\n",
      "Current iteration=800, loss=0.5571703358971751\n",
      "Current iteration=900, loss=0.5571703358971751\n",
      "Current iteration=0, loss=0.5607969234616225\n",
      "Current iteration=100, loss=0.5606677880010994\n",
      "Current iteration=200, loss=0.5606677856854155\n",
      "Current iteration=300, loss=0.5606677856844667\n",
      "Current iteration=400, loss=0.5606677856844661\n",
      "Current iteration=500, loss=0.5606677856844661\n",
      "Current iteration=600, loss=0.560667785684466\n",
      "Current iteration=700, loss=0.5606677856844661\n",
      "Current iteration=800, loss=0.5606677856844661\n",
      "Current iteration=900, loss=0.5606677856844661\n",
      "Current iteration=0, loss=0.5599192778393604\n",
      "Current iteration=100, loss=0.5598632246907275\n",
      "Current iteration=200, loss=0.5598632240138023\n",
      "Current iteration=300, loss=0.5598632240134687\n",
      "Current iteration=400, loss=0.5598632240134683\n",
      "Current iteration=500, loss=0.5598632240134684\n",
      "Current iteration=600, loss=0.5598632240134684\n",
      "Current iteration=700, loss=0.5598632240134683\n",
      "Current iteration=800, loss=0.5598632240134686\n",
      "Current iteration=900, loss=0.5598632240134686\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.5669254861242614\n",
      "Current iteration=100, loss=0.5663090482813655\n",
      "Current iteration=200, loss=0.5663090455223078\n",
      "Current iteration=300, loss=0.566309045522256\n",
      "Current iteration=400, loss=0.5663090455222562\n",
      "Current iteration=500, loss=0.5663090455222561\n",
      "Current iteration=600, loss=0.5663090455222561\n",
      "Current iteration=700, loss=0.5663090455222562\n",
      "Current iteration=800, loss=0.5663090455222562\n",
      "Current iteration=900, loss=0.5663090455222562\n",
      "Current iteration=0, loss=0.5634257154411494\n",
      "Current iteration=100, loss=0.563306256701793\n",
      "Current iteration=200, loss=0.5633062564631415\n",
      "Current iteration=300, loss=0.5633062564631331\n",
      "Current iteration=400, loss=0.5633062564631331\n",
      "Current iteration=500, loss=0.5633062564631331\n",
      "Current iteration=600, loss=0.5633062564631331\n",
      "Current iteration=700, loss=0.5633062564631331\n",
      "Current iteration=800, loss=0.5633062564631331\n",
      "Current iteration=900, loss=0.5633062564631331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5667802023299107\n",
      "Current iteration=100, loss=0.566666701725021\n",
      "Current iteration=200, loss=0.5666667015736111\n",
      "Current iteration=300, loss=0.5666667015736059\n",
      "Current iteration=400, loss=0.5666667015736059\n",
      "Current iteration=500, loss=0.5666667015736058\n",
      "Current iteration=600, loss=0.566666701573606\n",
      "Current iteration=700, loss=0.566666701573606\n",
      "Current iteration=800, loss=0.566666701573606\n",
      "Current iteration=900, loss=0.566666701573606\n",
      "Current iteration=0, loss=0.5658808814610086\n",
      "Current iteration=100, loss=0.5658323736939335\n",
      "Current iteration=200, loss=0.5658323736519565\n",
      "Current iteration=300, loss=0.5658323736519546\n",
      "Current iteration=400, loss=0.5658323736519546\n",
      "Current iteration=500, loss=0.5658323736519547\n",
      "Current iteration=600, loss=0.5658323736519546\n",
      "Current iteration=700, loss=0.5658323736519546\n",
      "Current iteration=800, loss=0.5658323736519546\n",
      "Current iteration=900, loss=0.5658323736519546\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.5735883437567931\n",
      "Current iteration=100, loss=0.5729622526994667\n",
      "Current iteration=200, loss=0.5729622526305774\n",
      "Current iteration=300, loss=0.5729622526305772\n",
      "Current iteration=400, loss=0.5729622526305773\n",
      "Current iteration=500, loss=0.5729622526305772\n",
      "Current iteration=600, loss=0.5729622526305772\n",
      "Current iteration=700, loss=0.5729622526305772\n",
      "Current iteration=800, loss=0.5729622526305772\n",
      "Current iteration=900, loss=0.5729622526305772\n",
      "Current iteration=0, loss=0.5702329287082544\n",
      "Current iteration=100, loss=0.5701309271924044\n",
      "Current iteration=200, loss=0.5701309271864649\n",
      "Current iteration=300, loss=0.5701309271864646\n",
      "Current iteration=400, loss=0.5701309271864649\n",
      "Current iteration=500, loss=0.5701309271864647\n",
      "Current iteration=600, loss=0.5701309271864647\n",
      "Current iteration=700, loss=0.5701309271864647\n",
      "Current iteration=800, loss=0.5701309271864647\n",
      "Current iteration=900, loss=0.5701309271864647\n",
      "Current iteration=0, loss=0.5734293919497827\n",
      "Current iteration=100, loss=0.5733327193128241\n",
      "Current iteration=200, loss=0.5733327193091828\n",
      "Current iteration=300, loss=0.5733327193091828\n",
      "Current iteration=400, loss=0.573332719309183\n",
      "Current iteration=500, loss=0.573332719309183\n",
      "Current iteration=600, loss=0.573332719309183\n",
      "Current iteration=700, loss=0.573332719309183\n",
      "Current iteration=800, loss=0.573332719309183\n",
      "Current iteration=900, loss=0.573332719309183\n",
      "Current iteration=0, loss=0.5725214491267194\n",
      "Current iteration=100, loss=0.5724802176951996\n",
      "Current iteration=200, loss=0.5724802176942095\n",
      "Current iteration=300, loss=0.5724802176942095\n",
      "Current iteration=400, loss=0.5724802176942095\n",
      "Current iteration=500, loss=0.5724802176942096\n",
      "Current iteration=600, loss=0.5724802176942096\n",
      "Current iteration=700, loss=0.5724802176942096\n",
      "Current iteration=800, loss=0.5724802176942096\n",
      "Current iteration=900, loss=0.5724802176942096\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.58094722648122\n",
      "Current iteration=100, loss=0.5803253300948438\n",
      "Current iteration=200, loss=0.5803253300944295\n",
      "Current iteration=300, loss=0.5803253300944295\n",
      "Current iteration=400, loss=0.5803253300944295\n",
      "Current iteration=500, loss=0.5803253300944295\n",
      "Current iteration=600, loss=0.5803253300944295\n",
      "Current iteration=700, loss=0.5803253300944295\n",
      "Current iteration=800, loss=0.5803253300944295\n",
      "Current iteration=900, loss=0.5803253300944295\n",
      "Current iteration=0, loss=0.5777775615955794\n",
      "Current iteration=100, loss=0.5776937099660064\n",
      "Current iteration=200, loss=0.5776937099659706\n",
      "Current iteration=300, loss=0.5776937099659706\n",
      "Current iteration=400, loss=0.5776937099659705\n",
      "Current iteration=500, loss=0.5776937099659705\n",
      "Current iteration=600, loss=0.5776937099659705\n",
      "Current iteration=700, loss=0.5776937099659705\n",
      "Current iteration=800, loss=0.5776937099659705\n",
      "Current iteration=900, loss=0.5776937099659705\n",
      "Current iteration=0, loss=0.5807925794733269\n",
      "Current iteration=100, loss=0.5807131211014503\n",
      "Current iteration=200, loss=0.5807131211014289\n",
      "Current iteration=300, loss=0.5807131211014289\n",
      "Current iteration=400, loss=0.5807131211014289\n",
      "Current iteration=500, loss=0.5807131211014289\n",
      "Current iteration=600, loss=0.5807131211014289\n",
      "Current iteration=700, loss=0.5807131211014289\n",
      "Current iteration=800, loss=0.5807131211014289\n",
      "Current iteration=900, loss=0.5807131211014289\n",
      "Current iteration=0, loss=0.5798911321209144\n",
      "Current iteration=100, loss=0.5798569259997096\n",
      "Current iteration=200, loss=0.5798569259997038\n",
      "Current iteration=300, loss=0.5798569259997038\n",
      "Current iteration=400, loss=0.5798569259997038\n",
      "Current iteration=500, loss=0.5798569259997038\n",
      "Current iteration=600, loss=0.5798569259997038\n",
      "Current iteration=700, loss=0.5798569259997038\n",
      "Current iteration=800, loss=0.5798569259997038\n",
      "Current iteration=900, loss=0.5798569259997038\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.5890189931520539\n",
      "Current iteration=100, loss=0.588420150782458\n",
      "Current iteration=200, loss=0.5884201507824579\n",
      "Current iteration=300, loss=0.5884201507824577\n",
      "Current iteration=400, loss=0.5884201507824577\n",
      "Current iteration=500, loss=0.5884201507824577\n",
      "Current iteration=600, loss=0.5884201507824577\n",
      "Current iteration=700, loss=0.5884201507824577\n",
      "Current iteration=800, loss=0.5884201507824577\n",
      "Current iteration=900, loss=0.5884201507824577\n",
      "Current iteration=0, loss=0.5860812869635073\n",
      "Current iteration=100, loss=0.5860153651646357\n",
      "Current iteration=200, loss=0.5860153651646358\n",
      "Current iteration=300, loss=0.5860153651646358\n",
      "Current iteration=400, loss=0.5860153651646358\n",
      "Current iteration=500, loss=0.5860153651646358\n",
      "Current iteration=600, loss=0.5860153651646358\n",
      "Current iteration=700, loss=0.5860153651646358\n",
      "Current iteration=800, loss=0.5860153651646358\n",
      "Current iteration=900, loss=0.5860153651646358\n",
      "Current iteration=0, loss=0.5888911104049488\n",
      "Current iteration=100, loss=0.5888284733514475\n",
      "Current iteration=200, loss=0.5888284733514475\n",
      "Current iteration=300, loss=0.5888284733514475\n",
      "Current iteration=400, loss=0.5888284733514475\n",
      "Current iteration=500, loss=0.5888284733514475\n",
      "Current iteration=600, loss=0.5888284733514475\n",
      "Current iteration=700, loss=0.5888284733514475\n",
      "Current iteration=800, loss=0.5888284733514475\n",
      "Current iteration=900, loss=0.5888284733514475\n",
      "Current iteration=0, loss=0.588012409682089\n",
      "Current iteration=100, loss=0.5879849557038388\n",
      "Current iteration=200, loss=0.5879849557038389\n",
      "Current iteration=300, loss=0.5879849557038388\n",
      "Current iteration=400, loss=0.5879849557038388\n",
      "Current iteration=500, loss=0.5879849557038388\n",
      "Current iteration=600, loss=0.5879849557038388\n",
      "Current iteration=700, loss=0.5879849557038388\n",
      "Current iteration=800, loss=0.5879849557038388\n",
      "Current iteration=900, loss=0.5879849557038388\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.5977687091892736\n",
      "Current iteration=100, loss=0.5972201837341208\n",
      "Current iteration=200, loss=0.5972201837341209\n",
      "Current iteration=300, loss=0.5972201837341209\n",
      "Current iteration=400, loss=0.5972201837341209\n",
      "Current iteration=500, loss=0.5972201837341209\n",
      "Current iteration=600, loss=0.5972201837341209\n",
      "Current iteration=700, loss=0.5972201837341209\n",
      "Current iteration=800, loss=0.5972201837341209\n",
      "Current iteration=900, loss=0.5972201837341209\n",
      "Current iteration=0, loss=0.5951135928002541\n",
      "Current iteration=100, loss=0.5950645626538199\n",
      "Current iteration=200, loss=0.59506456265382\n",
      "Current iteration=300, loss=0.59506456265382\n",
      "Current iteration=400, loss=0.59506456265382\n",
      "Current iteration=500, loss=0.59506456265382\n",
      "Current iteration=600, loss=0.59506456265382\n",
      "Current iteration=700, loss=0.59506456265382\n",
      "Current iteration=800, loss=0.59506456265382\n",
      "Current iteration=900, loss=0.59506456265382\n",
      "Current iteration=0, loss=0.5976962525364174\n",
      "Current iteration=100, loss=0.5976493550665709\n",
      "Current iteration=200, loss=0.5976493550665708\n",
      "Current iteration=300, loss=0.5976493550665708\n",
      "Current iteration=400, loss=0.5976493550665708\n",
      "Current iteration=500, loss=0.5976493550665708\n",
      "Current iteration=600, loss=0.5976493550665708\n",
      "Current iteration=700, loss=0.5976493550665708\n",
      "Current iteration=800, loss=0.5976493550665708\n",
      "Current iteration=900, loss=0.5976493550665708\n",
      "Current iteration=0, loss=0.5968566503854437\n",
      "Current iteration=100, loss=0.5968355867370132\n",
      "Current iteration=200, loss=0.5968355867370133\n",
      "Current iteration=300, loss=0.5968355867370133\n",
      "Current iteration=400, loss=0.5968355867370133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=500, loss=0.5968355867370133\n",
      "Current iteration=600, loss=0.5968355867370133\n",
      "Current iteration=700, loss=0.5968355867370133\n",
      "Current iteration=800, loss=0.5968355867370133\n",
      "Current iteration=900, loss=0.5968355867370133\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.6070914434073195\n",
      "Current iteration=100, loss=0.6066300388610836\n",
      "Current iteration=200, loss=0.6066300388610838\n",
      "Current iteration=300, loss=0.6066300388610838\n",
      "Current iteration=400, loss=0.6066300388610838\n",
      "Current iteration=500, loss=0.6066300388610838\n",
      "Current iteration=600, loss=0.6066300388610838\n",
      "Current iteration=700, loss=0.6066300388610838\n",
      "Current iteration=800, loss=0.6066300388610838\n",
      "Current iteration=900, loss=0.6066300388610838\n",
      "Current iteration=0, loss=0.6047717967870869\n",
      "Current iteration=100, loss=0.6047379491853345\n",
      "Current iteration=200, loss=0.6047379491853346\n",
      "Current iteration=300, loss=0.6047379491853346\n",
      "Current iteration=400, loss=0.6047379491853346\n",
      "Current iteration=500, loss=0.6047379491853346\n",
      "Current iteration=600, loss=0.6047379491853346\n",
      "Current iteration=700, loss=0.6047379491853346\n",
      "Current iteration=800, loss=0.6047379491853346\n",
      "Current iteration=900, loss=0.6047379491853346\n",
      "Current iteration=0, loss=0.6071092246855243\n",
      "Current iteration=100, loss=0.6070763880522693\n",
      "Current iteration=200, loss=0.6070763880522694\n",
      "Current iteration=300, loss=0.6070763880522694\n",
      "Current iteration=400, loss=0.6070763880522694\n",
      "Current iteration=500, loss=0.6070763880522694\n",
      "Current iteration=600, loss=0.6070763880522694\n",
      "Current iteration=700, loss=0.6070763880522694\n",
      "Current iteration=800, loss=0.6070763880522694\n",
      "Current iteration=900, loss=0.6070763880522694\n",
      "Current iteration=0, loss=0.606324021362378\n",
      "Current iteration=100, loss=0.6063088158228976\n",
      "Current iteration=200, loss=0.6063088158228976\n",
      "Current iteration=300, loss=0.6063088158228976\n",
      "Current iteration=400, loss=0.6063088158228976\n",
      "Current iteration=500, loss=0.6063088158228976\n",
      "Current iteration=600, loss=0.6063088158228976\n",
      "Current iteration=700, loss=0.6063088158228976\n",
      "Current iteration=800, loss=0.6063088158228976\n",
      "Current iteration=900, loss=0.6063088158228976\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.6168083292281974\n",
      "Current iteration=100, loss=0.6164742179377629\n",
      "Current iteration=200, loss=0.6164742179377629\n",
      "Current iteration=300, loss=0.6164742179377629\n",
      "Current iteration=400, loss=0.6164742179377629\n",
      "Current iteration=500, loss=0.6164742179377629\n",
      "Current iteration=600, loss=0.6164742179377629\n",
      "Current iteration=700, loss=0.6164742179377629\n",
      "Current iteration=800, loss=0.6164742179377629\n",
      "Current iteration=900, loss=0.6164742179377629\n",
      "Current iteration=0, loss=0.6148709018752005\n",
      "Current iteration=100, loss=0.6148499867477706\n",
      "Current iteration=200, loss=0.6148499867477706\n",
      "Current iteration=300, loss=0.6148499867477706\n",
      "Current iteration=400, loss=0.6148499867477706\n",
      "Current iteration=500, loss=0.6148499867477706\n",
      "Current iteration=600, loss=0.6148499867477706\n",
      "Current iteration=700, loss=0.6148499867477706\n",
      "Current iteration=800, loss=0.6148499867477706\n",
      "Current iteration=900, loss=0.6148499867477706\n",
      "Current iteration=0, loss=0.6169508074311247\n",
      "Current iteration=100, loss=0.616929809104816\n",
      "Current iteration=200, loss=0.616929809104816\n",
      "Current iteration=300, loss=0.616929809104816\n",
      "Current iteration=400, loss=0.616929809104816\n",
      "Current iteration=500, loss=0.616929809104816\n",
      "Current iteration=600, loss=0.616929809104816\n",
      "Current iteration=700, loss=0.616929809104816\n",
      "Current iteration=800, loss=0.616929809104816\n",
      "Current iteration=900, loss=0.616929809104816\n",
      "Current iteration=0, loss=0.6162330405463008\n",
      "Current iteration=100, loss=0.6162228971587959\n",
      "Current iteration=200, loss=0.6162228971587957\n",
      "Current iteration=300, loss=0.6162228971587957\n",
      "Current iteration=400, loss=0.6162228971587957\n",
      "Current iteration=500, loss=0.6162228971587957\n",
      "Current iteration=600, loss=0.6162228971587957\n",
      "Current iteration=700, loss=0.6162228971587957\n",
      "Current iteration=800, loss=0.6162228971587957\n",
      "Current iteration=900, loss=0.6162228971587957\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6266836169283617\n",
      "Current iteration=100, loss=0.6265005304351533\n",
      "Current iteration=200, loss=0.6265005304351533\n",
      "Current iteration=300, loss=0.6265005304351533\n",
      "Current iteration=400, loss=0.6265005304351533\n",
      "Current iteration=500, loss=0.6265005304351533\n",
      "Current iteration=600, loss=0.6265005304351533\n",
      "Current iteration=700, loss=0.6265005304351533\n",
      "Current iteration=800, loss=0.6265005304351533\n",
      "Current iteration=900, loss=0.6265005304351533\n",
      "Current iteration=0, loss=0.6251484979889332\n",
      "Current iteration=100, loss=0.6251377777927453\n",
      "Current iteration=200, loss=0.6251377777927453\n",
      "Current iteration=300, loss=0.6251377777927453\n",
      "Current iteration=400, loss=0.6251377777927453\n",
      "Current iteration=500, loss=0.6251377777927453\n",
      "Current iteration=600, loss=0.6251377777927453\n",
      "Current iteration=700, loss=0.6251377777927453\n",
      "Current iteration=800, loss=0.6251377777927453\n",
      "Current iteration=900, loss=0.6251377777927453\n",
      "Current iteration=0, loss=0.6269657889483772\n",
      "Current iteration=100, loss=0.6269538431403177\n",
      "Current iteration=200, loss=0.6269538431403177\n",
      "Current iteration=300, loss=0.6269538431403177\n",
      "Current iteration=400, loss=0.6269538431403177\n",
      "Current iteration=500, loss=0.6269538431403177\n",
      "Current iteration=600, loss=0.6269538431403177\n",
      "Current iteration=700, loss=0.6269538431403177\n",
      "Current iteration=800, loss=0.6269538431403177\n",
      "Current iteration=900, loss=0.6269538431403177\n",
      "Current iteration=0, loss=0.6263250919589776\n",
      "Current iteration=100, loss=0.6263188417573824\n",
      "Current iteration=200, loss=0.6263188417573824\n",
      "Current iteration=300, loss=0.6263188417573824\n",
      "Current iteration=400, loss=0.6263188417573824\n",
      "Current iteration=500, loss=0.6263188417573824\n",
      "Current iteration=600, loss=0.6263188417573824\n",
      "Current iteration=700, loss=0.6263188417573824\n",
      "Current iteration=800, loss=0.6263188417573824\n",
      "Current iteration=900, loss=0.6263188417573824\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6364657724967887\n",
      "Current iteration=100, loss=0.6364012136778248\n",
      "Current iteration=200, loss=0.6364012136778248\n",
      "Current iteration=300, loss=0.6364012136778248\n",
      "Current iteration=400, loss=0.6364012136778248\n",
      "Current iteration=500, loss=0.6364012136778248\n",
      "Current iteration=600, loss=0.6364012136778248\n",
      "Current iteration=700, loss=0.6364012136778248\n",
      "Current iteration=800, loss=0.6364012136778248\n",
      "Current iteration=900, loss=0.6364012136778248\n",
      "Current iteration=0, loss=0.6352874556562043\n",
      "Current iteration=100, loss=0.6352836401869171\n",
      "Current iteration=200, loss=0.6352836401869171\n",
      "Current iteration=300, loss=0.6352836401869171\n",
      "Current iteration=400, loss=0.6352836401869171\n",
      "Current iteration=500, loss=0.6352836401869171\n",
      "Current iteration=600, loss=0.6352836401869171\n",
      "Current iteration=700, loss=0.6352836401869171\n",
      "Current iteration=800, loss=0.6352836401869171\n",
      "Current iteration=900, loss=0.6352836401869171\n",
      "Current iteration=0, loss=0.6368450593252418\n",
      "Current iteration=100, loss=0.6368386957808206\n",
      "Current iteration=200, loss=0.6368386957808206\n",
      "Current iteration=300, loss=0.6368386957808206\n",
      "Current iteration=400, loss=0.6368386957808206\n",
      "Current iteration=500, loss=0.6368386957808206\n",
      "Current iteration=600, loss=0.6368386957808206\n",
      "Current iteration=700, loss=0.6368386957808206\n",
      "Current iteration=800, loss=0.6368386957808206\n",
      "Current iteration=900, loss=0.6368386957808206\n",
      "Current iteration=0, loss=0.6362867514307147\n",
      "Current iteration=100, loss=0.6362827184810562\n",
      "Current iteration=200, loss=0.6362827184810562\n",
      "Current iteration=300, loss=0.6362827184810562\n",
      "Current iteration=400, loss=0.6362827184810562\n",
      "Current iteration=500, loss=0.6362827184810562\n",
      "Current iteration=600, loss=0.6362827184810562\n",
      "Current iteration=700, loss=0.6362827184810562\n",
      "Current iteration=800, loss=0.6362827184810562\n",
      "Current iteration=900, loss=0.6362827184810562\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.6459493350840989\n",
      "Current iteration=100, loss=0.6458504504381604\n",
      "Current iteration=200, loss=0.6458504504381604\n",
      "Current iteration=300, loss=0.6458504504381604\n",
      "Current iteration=400, loss=0.6458504504381604\n",
      "Current iteration=500, loss=0.6458504504381604\n",
      "Current iteration=600, loss=0.6458504504381604\n",
      "Current iteration=700, loss=0.6458504504381604\n",
      "Current iteration=800, loss=0.6458504504381604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=900, loss=0.6458504504381604\n",
      "Current iteration=0, loss=0.6449548205233084\n",
      "Current iteration=100, loss=0.6449538657300605\n",
      "Current iteration=200, loss=0.6449538657300604\n",
      "Current iteration=300, loss=0.6449538657300604\n",
      "Current iteration=400, loss=0.6449538657300604\n",
      "Current iteration=500, loss=0.6449538657300604\n",
      "Current iteration=600, loss=0.6449538657300604\n",
      "Current iteration=700, loss=0.6449538657300604\n",
      "Current iteration=800, loss=0.6449538657300604\n",
      "Current iteration=900, loss=0.6449538657300604\n",
      "Current iteration=0, loss=0.6462638098512644\n",
      "Current iteration=100, loss=0.6462586331741144\n",
      "Current iteration=200, loss=0.6462586331741142\n",
      "Current iteration=300, loss=0.6462586331741142\n",
      "Current iteration=400, loss=0.6462586331741142\n",
      "Current iteration=500, loss=0.6462586331741142\n",
      "Current iteration=600, loss=0.6462586331741142\n",
      "Current iteration=700, loss=0.6462586331741142\n",
      "Current iteration=800, loss=0.6462586331741142\n",
      "Current iteration=900, loss=0.6462586331741142\n",
      "Current iteration=0, loss=0.6457883749957356\n",
      "Current iteration=100, loss=0.6457842086355554\n",
      "Current iteration=200, loss=0.6457842086355554\n",
      "Current iteration=300, loss=0.6457842086355554\n",
      "Current iteration=400, loss=0.6457842086355554\n",
      "Current iteration=500, loss=0.6457842086355554\n",
      "Current iteration=600, loss=0.6457842086355554\n",
      "Current iteration=700, loss=0.6457842086355554\n",
      "Current iteration=800, loss=0.6457842086355554\n",
      "Current iteration=900, loss=0.6457842086355554\n",
      "Iteration 28\n",
      "Current iteration=0, loss=0.655046062203628\n",
      "Current iteration=100, loss=0.6731965854615671\n",
      "Current iteration=200, loss=0.684306787808186\n",
      "Current iteration=300, loss=0.6843071263500854\n",
      "Current iteration=400, loss=0.684307126356827\n",
      "Current iteration=500, loss=0.684307126356827\n",
      "Current iteration=600, loss=0.684307126356827\n",
      "Current iteration=700, loss=0.684307126356827\n",
      "Current iteration=800, loss=0.684307126356827\n",
      "Current iteration=900, loss=0.684307126356827\n",
      "Current iteration=0, loss=0.6838076672512111\n",
      "Current iteration=100, loss=0.682300639963849\n",
      "Current iteration=200, loss=0.6823005961663221\n",
      "Current iteration=300, loss=0.6823005961649768\n",
      "Current iteration=400, loss=0.6823005961649768\n",
      "Current iteration=500, loss=0.6823005961649768\n",
      "Current iteration=600, loss=0.6823005961649768\n",
      "Current iteration=700, loss=0.6823005961649768\n",
      "Current iteration=800, loss=0.6823005961649768\n",
      "Current iteration=900, loss=0.6823005961649768\n",
      "Current iteration=0, loss=0.6849485994718729\n",
      "Current iteration=100, loss=0.6889924676047269\n",
      "Current iteration=200, loss=0.6889924865114807\n",
      "Current iteration=300, loss=0.6889924865115595\n",
      "Current iteration=400, loss=0.6889924865115595\n",
      "Current iteration=500, loss=0.6889924865115595\n",
      "Current iteration=600, loss=0.6889924865115595\n",
      "Current iteration=700, loss=0.6889924865115595\n",
      "Current iteration=800, loss=0.6889924865115595\n",
      "Current iteration=900, loss=0.6889924865115595\n",
      "Current iteration=0, loss=0.685878007231932\n",
      "Current iteration=100, loss=0.6755687861385792\n",
      "Current iteration=200, loss=0.6755666249638627\n",
      "Current iteration=300, loss=0.6755666243079209\n",
      "Current iteration=400, loss=0.6755666243077222\n",
      "Current iteration=500, loss=0.6755666243077222\n",
      "Current iteration=600, loss=0.6755666243077222\n",
      "Current iteration=700, loss=0.6755666243077222\n",
      "Current iteration=800, loss=0.6755666243077222\n",
      "Current iteration=900, loss=0.6755666243077222\n",
      "Iteration 29\n",
      "Current iteration=0, loss=0.7131852243312184\n",
      "Current iteration=100, loss=1.5457952276692364\n",
      "Current iteration=200, loss=1.545795227669259\n",
      "Current iteration=300, loss=1.545795227669259\n",
      "Current iteration=400, loss=1.545795227669259\n",
      "Current iteration=500, loss=1.545795227669259\n",
      "Current iteration=600, loss=1.545795227669259\n",
      "Current iteration=700, loss=1.545795227669259\n",
      "Current iteration=800, loss=1.545795227669259\n",
      "Current iteration=900, loss=1.545795227669259\n",
      "Current iteration=0, loss=1.5472201738276707\n",
      "Current iteration=100, loss=1.5450860852557133\n",
      "Current iteration=200, loss=1.545086085255714\n",
      "Current iteration=300, loss=1.545086085255714\n",
      "Current iteration=400, loss=1.545086085255714\n",
      "Current iteration=500, loss=1.545086085255714\n",
      "Current iteration=600, loss=1.545086085255714\n",
      "Current iteration=700, loss=1.545086085255714\n",
      "Current iteration=800, loss=1.545086085255714\n",
      "Current iteration=900, loss=1.545086085255714\n",
      "Current iteration=0, loss=1.553852507957676\n",
      "Current iteration=100, loss=1.555327378744847\n",
      "Current iteration=200, loss=1.5553273787448463\n",
      "Current iteration=300, loss=1.5553273787448463\n",
      "Current iteration=400, loss=1.5553273787448463\n",
      "Current iteration=500, loss=1.5553273787448463\n",
      "Current iteration=600, loss=1.5553273787448463\n",
      "Current iteration=700, loss=1.5553273787448463\n",
      "Current iteration=800, loss=1.5553273787448463\n",
      "Current iteration=900, loss=1.5553273787448463\n",
      "Current iteration=0, loss=1.5350494209376904\n",
      "Current iteration=100, loss=1.5165577250162383\n",
      "Current iteration=200, loss=1.516557725016241\n",
      "Current iteration=300, loss=1.516557725016241\n",
      "Current iteration=400, loss=1.516557725016241\n",
      "Current iteration=500, loss=1.516557725016241\n",
      "Current iteration=600, loss=1.516557725016241\n",
      "Current iteration=700, loss=1.516557725016241\n",
      "Current iteration=800, loss=1.516557725016241\n",
      "Current iteration=900, loss=1.516557725016241\n"
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 1000\n",
    "    gamma = 0.7 # 0.01\n",
    "    optimal_lambda = log_optimal_lambda(ybs[jet_num], standardized_dset, initial_w, max_iters, gamma)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.0001, 0.0001]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdas when replacing -999 by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.0001, 0.0001]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5981457873646676\n",
      "Current iteration=100, loss=0.40570366954781983\n",
      "Current iteration=200, loss=0.39811158731651086\n",
      "Current iteration=300, loss=0.3951233762054761\n",
      "Current iteration=400, loss=0.3937249484158812\n",
      "Current iteration=500, loss=0.39302899842308897\n",
      "Current iteration=600, loss=0.3926703056127306\n",
      "Current iteration=700, loss=0.39248120630136046\n",
      "Current iteration=800, loss=0.3923800033816537\n",
      "Current iteration=900, loss=0.39232526283559516\n",
      "Current iteration=0, loss=0.6370622906477821\n",
      "Current iteration=100, loss=0.5440962786181257\n",
      "Current iteration=200, loss=0.5421053931684284\n",
      "Current iteration=300, loss=0.5416118282423613\n",
      "Current iteration=400, loss=0.54146090795682\n",
      "Current iteration=500, loss=0.5414110536697603\n",
      "Current iteration=600, loss=0.5413940004007834\n",
      "Current iteration=700, loss=0.5413880623987355\n",
      "Current iteration=800, loss=0.541385974816579\n",
      "Current iteration=900, loss=0.5413852369652208\n",
      "Current iteration=0, loss=0.6052448901473417\n",
      "Current iteration=100, loss=0.5276225960234489\n",
      "Current iteration=200, loss=0.5252384837692791\n",
      "Current iteration=300, loss=0.524705958519787\n",
      "Current iteration=400, loss=0.5245525339591433\n",
      "Current iteration=500, loss=0.5245019601860572\n",
      "Current iteration=600, loss=0.5244836873138192\n",
      "Current iteration=700, loss=0.5244766277620212\n",
      "Current iteration=800, loss=0.5244737523434064\n",
      "Current iteration=900, loss=0.5244725257314055\n"
     ]
    }
   ],
   "source": [
    "ws_RLR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 1000\n",
    "    gamma = 0.7 # 0.01\n",
    "    loss, w_RLR = reg_logistic_regression(ybs[jet_num], standardized_dset, lambdas[jet_num], initial_w, max_iters, gamma)\n",
    "    ws_RLR.append(w_RLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_RLR = model_output(x_te, ws_RLR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logistic_predictions(output_RLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard score (no impute of -999) was 0.76402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76004\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7593799999999999\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
