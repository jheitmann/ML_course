{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dsets(y, tx, pri_jet_num_idx):\n",
    "    cond_null = tx[:, pri_jet_num_idx] == 0\n",
    "    cond_one = tx[:, pri_jet_num_idx] == 1\n",
    "    cond_plural = tx[:, pri_jet_num_idx] >= 2\n",
    "    conditions = [cond_null, cond_one, cond_plural]\n",
    "\n",
    "    dsets = [tx[cond] for cond in conditions]\n",
    "    ybs = [y[cond] for cond in conditions]\n",
    "    \n",
    "    return dsets, ybs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_undefined(dsets):\n",
    "    clean_dsets = []\n",
    "    clean_features = []\n",
    "\n",
    "    for dset in dsets:\n",
    "        # Remove constant features and features with undefined samples\n",
    "        no_undefined = np.all(dset != -999, axis = 0)\n",
    "        no_constant = np.any(dset != dset[0], axis = 0)\n",
    "        cleaned = no_undefined * no_constant\n",
    "        clean_dset = dset[:,cleaned]\n",
    "        clean_dsets.append(clean_dset)\n",
    "        clean_features.append(cleaned)\n",
    "    \n",
    "    return clean_dsets, clean_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_and_standardize(clean_dsets, clean_features, degree):\n",
    "    standardized_dsets = []\n",
    "    parameters = []\n",
    "\n",
    "    for clean_dset in clean_dsets:\n",
    "        extended_dset = build_poly(clean_dset, degree)\n",
    "        standardized_dset, mean_x, std_x = extend_and_standardize(extended_dset[:,1:])\n",
    "        standardized_dsets.append(standardized_dset)\n",
    "        parameters.append((mean_x,std_x))\n",
    "    \n",
    "    return standardized_dsets, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, predictions):\n",
    "    N = y.size\n",
    "    accuracy = 1 - (np.count_nonzero(predictions-y)/N)\n",
    "    print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(weights, clean_features, parameters):\n",
    "    np.save('all/weights.npy', weights)\n",
    "    np.save('all/clean_features.npy', clean_features)\n",
    "    np.save('all/parameters.npy', parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'all/train.csv'\n",
    "labels, input_data, ids, features = load_csv_data(train_data)\n",
    "i, = np.where(features == 'PRI_jet_num')\n",
    "pri_jet_num_idx = np.squeeze(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets, ybs = split_dsets(labels, input_data, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dsets, clean_features = remove_undefined(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_dsets, parameters = expand_and_standardize(clean_dsets, clean_features, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    optimal_lambda = ridge_optimal_lambda(ybs[jet_num], standardized_dset)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_RR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    w_RR = ridge_regression(ybs[jet_num],standardized_dset,lambdas[jet_num])\n",
    "    ws_RR.append(w_RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_RR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Without feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n",
       "       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
       "       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n",
       "       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n",
       "       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num',\n",
       "       'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
       "       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n",
       "       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], dtype='<U27')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_tr, mean_tr, std_tr = extend_and_standardize(x_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:44: RuntimeWarning: overflow encountered in square\n",
      "  return 1/2*np.mean(e**2)\n"
     ]
    }
   ],
   "source": [
    "losses_GD, ws_GD = least_squares_GD(y_tr, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in less_equal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "predictions_GD = predict_labels(w_GD,x_te)\n",
    "compute_accuracy(y_te,predictions_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_LS = least_squares(y_tr,x_tr)\n",
    "predictions = predict_labels(w_LS,x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74402\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_te, _, _ = extend_and_standardize(x_te, mean_tr, std_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_LS = least_squares(y_tr,tx_tr)\n",
    "predictions = predict_labels(w_LS,tx_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74468\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross-validation to find good hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "lambda_ = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "optimal_lambda = ridge_optimal_lambda(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rr = ridge_regression(y_tr,x_tr,optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006210169418915616"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006210169418915616"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_labels(w_rr,x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.744\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.744\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.7\n",
    "y_tr_log = np.ones(y_tr.size)\n",
    "y_tr_log[y_tr == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:55: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1. - y) * np.log(1. - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:55: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1. - y) * np.log(1. - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_logistic = logistic_regression(y_tr_log, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67828\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_labels(w_logistic, x_te)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.7 # 0.01\n",
    "y_logistic = np.ones(y_tr.size)\n",
    "y_logistic[y_tr == -1] = 0\n",
    "optimal_lambda = logistic_optimal_lambda(y_logistic, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_reg_logistic = reg_logistic_regression(y_tr_log, x_tr, optimal_lambda, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7079599999999999\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_labels(w_reg_logistic, x_te)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: EDA and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8\n",
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets, ybs = split_dsets(y_tr, x_tr, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dsets, clean_features = remove_undefined(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_dsets, parameters = expand_and_standardize(clean_dsets, clean_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws_GD = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    losses_GD, w_GD = least_squares_GD(ybs[jet_num], standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_GD.append(w_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_GD, pri_jet_num_idx, clean_features, parameters, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78418\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78418\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72386\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: bit worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72848\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_SGD = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    loss_SGD, w_SGD = least_squares_SGD(ybs[jet_num], standardized_dset, initial_w, batch_size, max_iters, gamma)\n",
    "    ws_SGD.append(w_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_SGD, pri_jet_num_idx, clean_features, parameters, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70154\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7794\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_LS = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    loss, w = least_squares(ybs[jet_num],standardized_dset)\n",
    "    ws_LS.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_LS, pri_jet_num_idx, clean_features, parameters, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78556\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75986\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79222\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_LS = []\n",
    "for jet_num, extended_dset in enumerate(extended_dsets):\n",
    "    loss, w = least_squares(ybs[jet_num],extended_dset)\n",
    "    ws_LS.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76336\n"
     ]
    }
   ],
   "source": [
    "predictions = model_predictions(x_te, ws_LS, pri_jet_num_idx, clean_features, parameters, 8)\n",
    "compute_accuracy(y_te, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    optimal_lambda = ridge_optimal_lambda(ybs[jet_num], standardized_dset)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.05736152510448681]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree 3 polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14873521072935117, 1.0, 0.002395026619987486]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_RR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    w_RR = ridge_regression(ybs[jet_num],standardized_dset,lambdas[jet_num])\n",
    "    ws_RR.append(w_RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_RR, pri_jet_num_idx, clean_features, parameters, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7854\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_RR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree 3 polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79234\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5853413172803463\n",
      "Current iteration=100, loss=0.38242539449182134\n",
      "Current iteration=200, loss=0.3758365528197574\n",
      "Current iteration=300, loss=0.37406757141223684\n",
      "Current iteration=400, loss=0.3733865214630594\n",
      "Current iteration=500, loss=0.37304664080949995\n",
      "Current iteration=600, loss=0.3728418967625082\n",
      "Current iteration=700, loss=0.37270160860474555\n",
      "Current iteration=800, loss=0.3725955789555245\n",
      "Current iteration=900, loss=0.3725094992688114\n",
      "Current iteration=1000, loss=0.37243618360400654\n",
      "Current iteration=1100, loss=0.3723717370451153\n",
      "Current iteration=1200, loss=0.37231385658826005\n",
      "Current iteration=1300, loss=0.37226106593147135\n",
      "Current iteration=1400, loss=0.37221235451715207\n",
      "Current iteration=1500, loss=0.3721669954163542\n",
      "Current iteration=1600, loss=0.37212444615370477\n",
      "Current iteration=1700, loss=0.3720842905543233\n",
      "Current iteration=1800, loss=0.37204620238916103\n",
      "Current iteration=1900, loss=0.3720099214328091\n",
      "Current iteration=0, loss=0.6230529744542551\n",
      "Current iteration=100, loss=0.5022348483410025\n",
      "Current iteration=200, loss=0.49520759910833584\n",
      "Current iteration=300, loss=0.49123607607380804\n",
      "Current iteration=400, loss=0.48839296204658644\n",
      "Current iteration=500, loss=0.4861958911863805\n",
      "Current iteration=600, loss=0.484434890587137\n",
      "Current iteration=700, loss=0.4829920915950962\n",
      "Current iteration=800, loss=0.48179199415774526\n",
      "Current iteration=900, loss=0.48078240963162777\n",
      "Current iteration=1000, loss=0.47992546151672294\n",
      "Current iteration=1100, loss=0.4791927110007569\n",
      "Current iteration=1200, loss=0.4785622611376916\n",
      "Current iteration=1300, loss=0.47801692056019557\n",
      "Current iteration=1400, loss=0.47754298093839603\n",
      "Current iteration=1500, loss=0.47712937144091727\n",
      "Current iteration=1600, loss=0.4767670557101027\n",
      "Current iteration=1700, loss=0.4764485908396586\n",
      "Current iteration=1800, loss=0.47616779804255743\n",
      "Current iteration=1900, loss=0.4759195124021219\n",
      "Current iteration=0, loss=0.5693684627903125\n",
      "Current iteration=100, loss=0.4987613298728339\n",
      "Current iteration=200, loss=0.4878901534324069\n",
      "Current iteration=300, loss=0.4810701760436699\n",
      "Current iteration=400, loss=0.4762135453283628\n",
      "Current iteration=500, loss=0.47255174894752466\n",
      "Current iteration=600, loss=0.4696942487368997\n",
      "Current iteration=700, loss=0.46741073522629284\n",
      "Current iteration=800, loss=0.4655532645372127\n",
      "Current iteration=900, loss=0.4640212095128885\n",
      "Current iteration=1000, loss=0.4627432244739355\n",
      "Current iteration=1100, loss=0.46166709539588074\n",
      "Current iteration=1200, loss=0.46075363978037104\n",
      "Current iteration=1300, loss=0.45997284956455853\n",
      "Current iteration=1400, loss=0.45930135154120577\n",
      "Current iteration=1500, loss=0.4587206789924871\n",
      "Current iteration=1600, loss=0.45821606251664776\n",
      "Current iteration=1700, loss=0.4577755640965051\n",
      "Current iteration=1800, loss=0.4573894444296114\n",
      "Current iteration=1900, loss=0.45704969258675315\n"
     ]
    }
   ],
   "source": [
    "ws_LR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    loss, w_LR = logistic_regression(y_logistic, standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_LR.append(w_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_LR, pri_jet_num_idx, clean_features, parameters, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8017\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_LR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8017\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_LR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76258\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76196\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logitic regression, degree 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80266\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Current iteration=0, loss=0.5840898688325303\n",
      "Current iteration=100, loss=0.38302967217440864\n",
      "Current iteration=200, loss=0.3778226394034337\n",
      "Current iteration=300, loss=0.3761220817626732\n",
      "Current iteration=400, loss=0.3753605022566267\n",
      "Current iteration=500, loss=0.3749101570804421\n",
      "Current iteration=600, loss=0.3745743367064042\n",
      "Current iteration=700, loss=0.3742894528664899\n",
      "Current iteration=800, loss=0.3740320084918895\n",
      "Current iteration=900, loss=0.3737923776663226\n",
      "Current iteration=1000, loss=0.37356622529283084\n",
      "Current iteration=1100, loss=0.3733514161762931\n",
      "Current iteration=1200, loss=0.3731467994444135\n",
      "Current iteration=1300, loss=0.37295168461626355\n",
      "Current iteration=1400, loss=0.3727655926181169\n",
      "Current iteration=1500, loss=0.3725954781543667\n",
      "Current iteration=1600, loss=0.37248753313593114\n",
      "Current iteration=1700, loss=0.37240281837422784\n",
      "Current iteration=1800, loss=0.372333537129307\n",
      "Current iteration=1900, loss=0.372275597533538\n",
      "Current iteration=0, loss=0.3728193660710849\n",
      "Current iteration=100, loss=0.3726393190412583\n",
      "Current iteration=200, loss=0.372591140847398\n",
      "Current iteration=300, loss=0.3725551713078993\n",
      "Current iteration=400, loss=0.3725254610756477\n",
      "Current iteration=500, loss=0.3724997709366872\n",
      "Current iteration=600, loss=0.37247700538799694\n",
      "Current iteration=700, loss=0.37245651263345153\n",
      "Current iteration=800, loss=0.3724378523595378\n",
      "Current iteration=900, loss=0.3724207042888741\n",
      "Current iteration=1000, loss=0.37240482552551335\n",
      "Current iteration=1100, loss=0.37239002730995263\n",
      "Current iteration=1200, loss=0.3723761606474198\n",
      "Current iteration=1300, loss=0.37236310658621924\n",
      "Current iteration=1400, loss=0.3723507692505175\n",
      "Current iteration=1500, loss=0.37233907067065763\n",
      "Current iteration=1600, loss=0.37232794686881604\n",
      "Current iteration=1700, loss=0.3723173448600429\n",
      "Current iteration=1800, loss=0.3723072203382839\n",
      "Current iteration=1900, loss=0.37229753588272485\n",
      "Current iteration=0, loss=0.37216133248427324\n",
      "Current iteration=100, loss=0.3716993380812493\n",
      "Current iteration=200, loss=0.37142173965137626\n",
      "Current iteration=300, loss=0.3711996033895834\n",
      "Current iteration=400, loss=0.37100925852689387\n",
      "Current iteration=500, loss=0.370859484387019\n",
      "Current iteration=600, loss=0.37076257701963233\n",
      "Current iteration=700, loss=0.3706826000064247\n",
      "Current iteration=800, loss=0.37061388859315253\n",
      "Current iteration=900, loss=0.3705535537617429\n",
      "Current iteration=1000, loss=0.37049986390059936\n",
      "Current iteration=1100, loss=0.3704516820108561\n",
      "Current iteration=1200, loss=0.37040819646482465\n",
      "Current iteration=1300, loss=0.37036878632346976\n",
      "Current iteration=1400, loss=0.3703329509004949\n",
      "Current iteration=1500, loss=0.3703002712011167\n",
      "Current iteration=1600, loss=0.370270387782692\n",
      "Current iteration=1700, loss=0.3702429873671427\n",
      "Current iteration=1800, loss=0.3702177942461036\n",
      "Current iteration=1900, loss=0.37019456439411774\n",
      "Current iteration=0, loss=0.370998818969288\n",
      "Current iteration=100, loss=0.37169409627989913\n",
      "Current iteration=200, loss=0.3713625410864196\n",
      "Current iteration=300, loss=0.3712001096617901\n",
      "Current iteration=400, loss=0.3711043514991027\n",
      "Current iteration=500, loss=0.3710450457685293\n",
      "Current iteration=600, loss=0.3710064597886043\n",
      "Current iteration=700, loss=0.3709799166821838\n",
      "Current iteration=800, loss=0.37096061185118806\n",
      "Current iteration=900, loss=0.3709458519551482\n",
      "Current iteration=1000, loss=0.37093409001605715\n",
      "Current iteration=1100, loss=0.37092440642699753\n",
      "Current iteration=1200, loss=0.37091623097537496\n",
      "Current iteration=1300, loss=0.3709091932285852\n",
      "Current iteration=1400, loss=0.3709030410277738\n",
      "Current iteration=1500, loss=0.3708975951414614\n",
      "Current iteration=1600, loss=0.37089272347126145\n",
      "Current iteration=1700, loss=0.3708883257289943\n",
      "Current iteration=1800, loss=0.37088432405635563\n",
      "Current iteration=1900, loss=0.370880656972556\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.37310671047866745\n",
      "Current iteration=100, loss=0.3729165355529056\n",
      "Current iteration=200, loss=0.3728542796906179\n",
      "Current iteration=300, loss=0.3728054722207461\n",
      "Current iteration=400, loss=0.3727660553758717\n",
      "Current iteration=500, loss=0.3727336621652119\n",
      "Current iteration=600, loss=0.3727067092905519\n",
      "Current iteration=700, loss=0.3726840612473853\n",
      "Current iteration=800, loss=0.37266486895772455\n",
      "Current iteration=900, loss=0.3726484808342695\n",
      "Current iteration=1000, loss=0.3726343882844064\n",
      "Current iteration=1100, loss=0.372622189577248\n",
      "Current iteration=1200, loss=0.37261156449010996\n",
      "Current iteration=1300, loss=0.37260225583787665\n",
      "Current iteration=1400, loss=0.3725940556697606\n",
      "Current iteration=1500, loss=0.372586794782423\n",
      "Current iteration=1600, loss=0.3725803346600894\n",
      "Current iteration=1700, loss=0.37257456122838634\n",
      "Current iteration=1800, loss=0.37256937998547274\n",
      "Current iteration=1900, loss=0.372564712184582\n",
      "Current iteration=0, loss=0.373296705717304\n",
      "Current iteration=100, loss=0.37313571268294166\n",
      "Current iteration=200, loss=0.3731066564785455\n",
      "Current iteration=300, loss=0.3730888868282381\n",
      "Current iteration=400, loss=0.37307609327489594\n",
      "Current iteration=500, loss=0.3730660147970422\n",
      "Current iteration=600, loss=0.3730576678846765\n",
      "Current iteration=700, loss=0.37305055076085564\n",
      "Current iteration=800, loss=0.3730443706828502\n",
      "Current iteration=900, loss=0.3730389373739167\n",
      "Current iteration=1000, loss=0.373034116570036\n",
      "Current iteration=1100, loss=0.37302980778143735\n",
      "Current iteration=1200, loss=0.3730259326951278\n",
      "Current iteration=1300, loss=0.3730224286058562\n",
      "Current iteration=1400, loss=0.3730192443851654\n",
      "Current iteration=1500, loss=0.37301633781876786\n",
      "Current iteration=1600, loss=0.37301367373435207\n",
      "Current iteration=1700, loss=0.3730112226194772\n",
      "Current iteration=1800, loss=0.37300895956450664\n",
      "Current iteration=1900, loss=0.3730068634340621\n",
      "Current iteration=0, loss=0.3727786509795424\n",
      "Current iteration=100, loss=0.3723642751848404\n",
      "Current iteration=200, loss=0.3721302689621423\n",
      "Current iteration=300, loss=0.3719500100458486\n",
      "Current iteration=400, loss=0.37180053704516863\n",
      "Current iteration=500, loss=0.37169955394548093\n",
      "Current iteration=600, loss=0.37163257244902426\n",
      "Current iteration=700, loss=0.37157782381167664\n",
      "Current iteration=800, loss=0.3715313894838879\n",
      "Current iteration=900, loss=0.3714911335104256\n",
      "Current iteration=1000, loss=0.37145575562792665\n",
      "Current iteration=1100, loss=0.37142438969949554\n",
      "Current iteration=1200, loss=0.3713964122525426\n",
      "Current iteration=1300, loss=0.37137134628178997\n",
      "Current iteration=1400, loss=0.37134881026726513\n",
      "Current iteration=1500, loss=0.3713284895311394\n",
      "Current iteration=1600, loss=0.37131011907876976\n",
      "Current iteration=1700, loss=0.3712934726085347\n",
      "Current iteration=1800, loss=0.3712783549994641\n",
      "Current iteration=1900, loss=0.3712645968765037\n",
      "Current iteration=0, loss=0.3720546422278937\n",
      "Current iteration=100, loss=0.3726344877736168\n",
      "Current iteration=200, loss=0.37214077375619187\n",
      "Current iteration=300, loss=0.3720089079868588\n",
      "Current iteration=400, loss=0.3719360931765385\n",
      "Current iteration=500, loss=0.37189333488396026\n",
      "Current iteration=600, loss=0.37186660797036236\n",
      "Current iteration=700, loss=0.3718488252341\n",
      "Current iteration=800, loss=0.37183628962845783\n",
      "Current iteration=900, loss=0.3718270047303723\n",
      "Current iteration=1000, loss=0.3718198482564084\n",
      "Current iteration=1100, loss=0.3718141595294375\n",
      "Current iteration=1200, loss=0.3718095295151988\n",
      "Current iteration=1300, loss=0.3718056917129932\n",
      "Current iteration=1400, loss=0.371802463965931\n",
      "Current iteration=1500, loss=0.3717997164735193\n",
      "Current iteration=1600, loss=0.3717973535845885\n",
      "Current iteration=1700, loss=0.3717953028977606\n",
      "Current iteration=1800, loss=0.37179350848555764\n",
      "Current iteration=1900, loss=0.3717919265055249\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.37427288042940776\n",
      "Current iteration=100, loss=0.37407161688468\n",
      "Current iteration=200, loss=0.3740055437526313\n",
      "Current iteration=300, loss=0.37395451943401553\n",
      "Current iteration=400, loss=0.3739138174634609\n",
      "Current iteration=500, loss=0.37388076956444977\n",
      "Current iteration=600, loss=0.3738536009061167\n",
      "Current iteration=700, loss=0.3738310459048057\n",
      "Current iteration=800, loss=0.37381216396388756\n",
      "Current iteration=900, loss=0.37379623785214156\n",
      "Current iteration=1000, loss=0.37378271139125463\n",
      "Current iteration=1100, loss=0.3737711481527599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1200, loss=0.3737612025388063\n",
      "Current iteration=1300, loss=0.3737525987889186\n",
      "Current iteration=1400, loss=0.373745115368474\n",
      "Current iteration=1500, loss=0.37373857317043224\n",
      "Current iteration=1600, loss=0.3737328265017454\n",
      "Current iteration=1700, loss=0.37372775613755144\n",
      "Current iteration=1800, loss=0.3737232639365049\n",
      "Current iteration=1900, loss=0.3737192686414367\n",
      "Current iteration=0, loss=0.3744035082446261\n",
      "Current iteration=100, loss=0.3742425211474675\n",
      "Current iteration=200, loss=0.37421282751410107\n",
      "Current iteration=300, loss=0.3741943686026007\n",
      "Current iteration=400, loss=0.3741809124827378\n",
      "Current iteration=500, loss=0.3741702374381993\n",
      "Current iteration=600, loss=0.3741613693472125\n",
      "Current iteration=700, loss=0.3741538028137963\n",
      "Current iteration=800, loss=0.37414723721688853\n",
      "Current iteration=900, loss=0.3741414738002689\n",
      "Current iteration=1000, loss=0.37413637054914356\n",
      "Current iteration=1100, loss=0.37413182032058\n",
      "Current iteration=1200, loss=0.37412773924543175\n",
      "Current iteration=1300, loss=0.37412406003201104\n",
      "Current iteration=1400, loss=0.37412072777772876\n",
      "Current iteration=1500, loss=0.37411769715565557\n",
      "Current iteration=1600, loss=0.3741149304105571\n",
      "Current iteration=1700, loss=0.3741123958667462\n",
      "Current iteration=1800, loss=0.3741100667815711\n",
      "Current iteration=1900, loss=0.37410792044553703\n",
      "Current iteration=0, loss=0.37389061494870846\n",
      "Current iteration=100, loss=0.3735296035900136\n",
      "Current iteration=200, loss=0.37334135916835376\n",
      "Current iteration=300, loss=0.37320068029628634\n",
      "Current iteration=400, loss=0.37308614549384406\n",
      "Current iteration=500, loss=0.37299051271464334\n",
      "Current iteration=600, loss=0.37292820740412647\n",
      "Current iteration=700, loss=0.37288199805310135\n",
      "Current iteration=800, loss=0.3728440392695714\n",
      "Current iteration=900, loss=0.3728119517040011\n",
      "Current iteration=1000, loss=0.37278434323929754\n",
      "Current iteration=1100, loss=0.37276031780162505\n",
      "Current iteration=1200, loss=0.37273924983639667\n",
      "Current iteration=1300, loss=0.3727206731387759\n",
      "Current iteration=1400, loss=0.37270422309528156\n",
      "Current iteration=1500, loss=0.3726896048500438\n",
      "Current iteration=1600, loss=0.37267657454736003\n",
      "Current iteration=1700, loss=0.3726649274744867\n",
      "Current iteration=1800, loss=0.37265449002805767\n",
      "Current iteration=1900, loss=0.37264511393713495\n",
      "Current iteration=0, loss=0.37341169366304805\n",
      "Current iteration=100, loss=0.3734484850208725\n",
      "Current iteration=200, loss=0.3732178524937105\n",
      "Current iteration=300, loss=0.3731108687996763\n",
      "Current iteration=400, loss=0.37305337617021744\n",
      "Current iteration=500, loss=0.3730201090279923\n",
      "Current iteration=600, loss=0.3729994179217701\n",
      "Current iteration=700, loss=0.3729856310134366\n",
      "Current iteration=800, loss=0.3729758636526261\n",
      "Current iteration=900, loss=0.3729685817588528\n",
      "Current iteration=1000, loss=0.3729629293424551\n",
      "Current iteration=1100, loss=0.3729584035459674\n",
      "Current iteration=1200, loss=0.3729546929077595\n",
      "Current iteration=1300, loss=0.37295159432215524\n",
      "Current iteration=1400, loss=0.3729489690452685\n",
      "Current iteration=1500, loss=0.37294671835939036\n",
      "Current iteration=1600, loss=0.3729447697242033\n",
      "Current iteration=1700, loss=0.37294306833812746\n",
      "Current iteration=1800, loss=0.37294157196860683\n",
      "Current iteration=1900, loss=0.37294024743175114\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.3756549212861087\n",
      "Current iteration=100, loss=0.3754415915832176\n",
      "Current iteration=200, loss=0.37537159587819197\n",
      "Current iteration=300, loss=0.37531903633245184\n",
      "Current iteration=400, loss=0.3752779436878808\n",
      "Current iteration=500, loss=0.37524522307992314\n",
      "Current iteration=600, loss=0.3752188386547811\n",
      "Current iteration=700, loss=0.3751973520307259\n",
      "Current iteration=800, loss=0.3751797056249896\n",
      "Current iteration=900, loss=0.37516510262585995\n",
      "Current iteration=1000, loss=0.3751529330142938\n",
      "Current iteration=1100, loss=0.375142724386586\n",
      "Current iteration=1200, loss=0.37513410758727483\n",
      "Current iteration=1300, loss=0.37512679189754794\n",
      "Current iteration=1400, loss=0.3751205467396049\n",
      "Current iteration=1500, loss=0.37511518799621096\n",
      "Current iteration=1600, loss=0.37511056768903556\n",
      "Current iteration=1700, loss=0.37510656612265614\n",
      "Current iteration=1800, loss=0.3751030858736349\n",
      "Current iteration=1900, loss=0.37510004716884526\n",
      "Current iteration=0, loss=0.3757034108091858\n",
      "Current iteration=100, loss=0.37554521519433093\n",
      "Current iteration=200, loss=0.37551747156772347\n",
      "Current iteration=300, loss=0.3755007222834819\n",
      "Current iteration=400, loss=0.37548883480899176\n",
      "Current iteration=500, loss=0.3754796462338811\n",
      "Current iteration=600, loss=0.37547220221181227\n",
      "Current iteration=700, loss=0.37546600078532294\n",
      "Current iteration=800, loss=0.37546074009243563\n",
      "Current iteration=900, loss=0.37545621997463885\n",
      "Current iteration=1000, loss=0.37545229820143683\n",
      "Current iteration=1100, loss=0.37544886872725247\n",
      "Current iteration=1200, loss=0.37544584982040274\n",
      "Current iteration=1300, loss=0.37544317701701896\n",
      "Current iteration=1400, loss=0.3754407986216453\n",
      "Current iteration=1500, loss=0.3754386726535558\n",
      "Current iteration=1600, loss=0.37543676467314774\n",
      "Current iteration=1700, loss=0.3754350461794776\n",
      "Current iteration=1800, loss=0.3754334933991171\n",
      "Current iteration=1900, loss=0.37543208635476\n",
      "Current iteration=0, loss=0.37522843224555047\n",
      "Current iteration=100, loss=0.37492297537317587\n",
      "Current iteration=200, loss=0.374781437559655\n",
      "Current iteration=300, loss=0.3746802969378658\n",
      "Current iteration=400, loss=0.37460054662536235\n",
      "Current iteration=500, loss=0.3745340469046433\n",
      "Current iteration=600, loss=0.37447725661304215\n",
      "Current iteration=700, loss=0.374434208472013\n",
      "Current iteration=800, loss=0.3744034596281102\n",
      "Current iteration=900, loss=0.37437877455814667\n",
      "Current iteration=1000, loss=0.37435834420980674\n",
      "Current iteration=1100, loss=0.37434114360203896\n",
      "Current iteration=1200, loss=0.3743264980746073\n",
      "Current iteration=1300, loss=0.37431393046719685\n",
      "Current iteration=1400, loss=0.37430308380919053\n",
      "Current iteration=1500, loss=0.3742936799048955\n",
      "Current iteration=1600, loss=0.3742854957888989\n",
      "Current iteration=1700, loss=0.37427834934872384\n",
      "Current iteration=1800, loss=0.37427208993364947\n",
      "Current iteration=1900, loss=0.374266591812068\n",
      "Current iteration=0, loss=0.3750397971017956\n",
      "Current iteration=100, loss=0.3747190673108974\n",
      "Current iteration=200, loss=0.3745416648732626\n",
      "Current iteration=300, loss=0.37445773057518567\n",
      "Current iteration=400, loss=0.3744131644742109\n",
      "Current iteration=500, loss=0.3743875773978932\n",
      "Current iteration=600, loss=0.3743717481187927\n",
      "Current iteration=700, loss=0.37436124556547656\n",
      "Current iteration=800, loss=0.37435382913406157\n",
      "Current iteration=900, loss=0.37434831071413804\n",
      "Current iteration=1000, loss=0.3743440296976026\n",
      "Current iteration=1100, loss=0.3743406003255178\n",
      "Current iteration=1200, loss=0.3743377859057971\n",
      "Current iteration=1300, loss=0.3743354337037468\n",
      "Current iteration=1400, loss=0.37433344045522\n",
      "Current iteration=1500, loss=0.37433173314782325\n",
      "Current iteration=1600, loss=0.3743302583957652\n",
      "Current iteration=1700, loss=0.37432897591543246\n",
      "Current iteration=1800, loss=0.37432785442215916\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.37731490764914283\n",
      "Current iteration=100, loss=0.37708834453842527\n",
      "Current iteration=200, loss=0.37701411386421385\n",
      "Current iteration=300, loss=0.37696084072031805\n",
      "Current iteration=400, loss=0.3769206206101859\n",
      "Current iteration=500, loss=0.37688965655111895\n",
      "Current iteration=600, loss=0.3768655211031235\n",
      "Current iteration=700, loss=0.37684653405585483\n",
      "Current iteration=800, loss=0.3768314867242798\n",
      "Current iteration=900, loss=0.3768194885691577\n",
      "Current iteration=1000, loss=0.3768098716647989\n",
      "Current iteration=1100, loss=0.37680212725454704\n",
      "Current iteration=1200, loss=0.3767958624368285\n",
      "Current iteration=1300, loss=0.37679077041269343\n",
      "Current iteration=1400, loss=0.376786609929973\n",
      "Current iteration=1500, loss=0.37678319077699346\n",
      "Current iteration=1600, loss=0.3767803630923072\n",
      "Current iteration=1700, loss=0.37677800906843323\n",
      "Current iteration=1800, loss=0.3767760362896151\n",
      "Current iteration=1900, loss=0.3767743723084647\n",
      "Current iteration=0, loss=0.3773001090871114\n",
      "Current iteration=100, loss=0.3771472143138945\n",
      "Current iteration=200, loss=0.3771230389990451\n",
      "Current iteration=300, loss=0.37710928525393195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=400, loss=0.37709997602409634\n",
      "Current iteration=500, loss=0.3770930579093503\n",
      "Current iteration=600, loss=0.37708764266208633\n",
      "Current iteration=700, loss=0.3770832704055291\n",
      "Current iteration=800, loss=0.377079668589509\n",
      "Current iteration=900, loss=0.37707665923404166\n",
      "Current iteration=1000, loss=0.3770741179629736\n",
      "Current iteration=1100, loss=0.3770719536824448\n",
      "Current iteration=1200, loss=0.37707009745311476\n",
      "Current iteration=1300, loss=0.37706849586322516\n",
      "Current iteration=1400, loss=0.37706710679869815\n",
      "Current iteration=1500, loss=0.37706589659109285\n",
      "Current iteration=0, loss=0.3768460897038585\n",
      "Current iteration=100, loss=0.37659334391345856\n",
      "Current iteration=200, loss=0.37649548845717246\n",
      "Current iteration=300, loss=0.37643051013715867\n",
      "Current iteration=400, loss=0.3763819293255297\n",
      "Current iteration=500, loss=0.37634314152550646\n",
      "Current iteration=600, loss=0.37631094032118345\n",
      "Current iteration=700, loss=0.3762835629998467\n",
      "Current iteration=800, loss=0.3762600259798307\n",
      "Current iteration=900, loss=0.3762401896505237\n",
      "Current iteration=1000, loss=0.3762246360577443\n",
      "Current iteration=1100, loss=0.37621259658054523\n",
      "Current iteration=1200, loss=0.37620291833708314\n",
      "Current iteration=1300, loss=0.3761949981949494\n",
      "Current iteration=1400, loss=0.37618844958472736\n",
      "Current iteration=1500, loss=0.3761829946432136\n",
      "Current iteration=1600, loss=0.3761784248071524\n",
      "Current iteration=1700, loss=0.37617457870095106\n",
      "Current iteration=1800, loss=0.37617132885682997\n",
      "Current iteration=1900, loss=0.37616857304472795\n",
      "Current iteration=0, loss=0.3769648460648943\n",
      "Current iteration=100, loss=0.3763106427897209\n",
      "Current iteration=200, loss=0.3761741616005176\n",
      "Current iteration=300, loss=0.3761096362648456\n",
      "Current iteration=400, loss=0.37607624154557306\n",
      "Current iteration=500, loss=0.3760575363404042\n",
      "Current iteration=600, loss=0.3760461902604873\n",
      "Current iteration=700, loss=0.37603875304930334\n",
      "Current iteration=800, loss=0.37603352607111895\n",
      "Current iteration=900, loss=0.3760296355953361\n",
      "Current iteration=1000, loss=0.37602660959793754\n",
      "Current iteration=1100, loss=0.37602417892613316\n",
      "Current iteration=1200, loss=0.3760221808023747\n",
      "Current iteration=1300, loss=0.3760205108602379\n",
      "Current iteration=1400, loss=0.3760190982384679\n",
      "Current iteration=1500, loss=0.3760178929848825\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.37934700089049606\n",
      "Current iteration=100, loss=0.379095775076191\n",
      "Current iteration=200, loss=0.37901733723964104\n",
      "Current iteration=300, loss=0.37896425300094416\n",
      "Current iteration=400, loss=0.378926618336173\n",
      "Current iteration=500, loss=0.37889973083082346\n",
      "Current iteration=600, loss=0.378880502368742\n",
      "Current iteration=700, loss=0.3788666862071281\n",
      "Current iteration=800, loss=0.3788566467422336\n",
      "Current iteration=900, loss=0.3788492324300769\n",
      "Current iteration=1000, loss=0.3788436541749982\n",
      "Current iteration=1100, loss=0.37883937790984523\n",
      "Current iteration=1200, loss=0.3788360421399437\n",
      "Current iteration=1300, loss=0.37883339992490256\n",
      "Current iteration=1400, loss=0.3788312799382351\n",
      "Current iteration=1500, loss=0.3788295609571486\n",
      "Current iteration=1600, loss=0.37882815531661834\n",
      "Current iteration=1700, loss=0.3788269982046226\n",
      "Current iteration=0, loss=0.37927589970374026\n",
      "Current iteration=100, loss=0.3791314668110029\n",
      "Current iteration=200, loss=0.37911197082242026\n",
      "Current iteration=300, loss=0.3791016452994531\n",
      "Current iteration=400, loss=0.37909496770688916\n",
      "Current iteration=500, loss=0.37909016383958455\n",
      "Current iteration=600, loss=0.37908650744781636\n",
      "Current iteration=700, loss=0.37908363429187175\n",
      "Current iteration=800, loss=0.37908133135497885\n",
      "Current iteration=900, loss=0.3790794602485202\n",
      "Current iteration=1000, loss=0.3790779246727781\n",
      "Current iteration=1100, loss=0.3790766545316142\n",
      "Current iteration=0, loss=0.3788153451565219\n",
      "Current iteration=100, loss=0.3786038933624705\n",
      "Current iteration=200, loss=0.37854251463984956\n",
      "Current iteration=300, loss=0.3785069064500212\n",
      "Current iteration=400, loss=0.3784827955196928\n",
      "Current iteration=500, loss=0.3784650233672974\n",
      "Current iteration=600, loss=0.37845123328957714\n",
      "Current iteration=700, loss=0.3784401783925466\n",
      "Current iteration=800, loss=0.37843112302759613\n",
      "Current iteration=900, loss=0.37842359635626044\n",
      "Current iteration=1000, loss=0.37841727749822607\n",
      "Current iteration=1100, loss=0.3784119359354025\n",
      "Current iteration=1200, loss=0.37840739925774486\n",
      "Current iteration=1300, loss=0.3784035339561041\n",
      "Current iteration=1400, loss=0.378400234124891\n",
      "Current iteration=1500, loss=0.378397414382116\n",
      "Current iteration=1600, loss=0.37839500465802783\n",
      "Current iteration=1700, loss=0.3783929476290633\n",
      "Current iteration=1800, loss=0.378391195491086\n",
      "Current iteration=1900, loss=0.37838970819716694\n",
      "Current iteration=0, loss=0.3791518092432549\n",
      "Current iteration=100, loss=0.3782698978304019\n",
      "Current iteration=200, loss=0.37817591594875144\n",
      "Current iteration=300, loss=0.3781306207750272\n",
      "Current iteration=400, loss=0.3781037694534071\n",
      "Current iteration=500, loss=0.37808577949043937\n",
      "Current iteration=600, loss=0.378072829505867\n",
      "Current iteration=700, loss=0.3780630530400195\n",
      "Current iteration=800, loss=0.3780554185571741\n",
      "Current iteration=900, loss=0.3780493081470722\n",
      "Current iteration=1000, loss=0.37804432939950683\n",
      "Current iteration=1100, loss=0.37804021960766465\n",
      "Current iteration=1200, loss=0.3780367962149909\n",
      "Current iteration=1300, loss=0.37803392370702615\n",
      "Current iteration=1400, loss=0.37803150333617513\n",
      "Current iteration=1500, loss=0.37802945538884286\n",
      "Current iteration=1600, loss=0.3780277185064963\n",
      "Current iteration=1700, loss=0.37802624254530826\n",
      "Current iteration=1800, loss=0.37802498694157605\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.3818935858812789\n",
      "Current iteration=100, loss=0.3815691997569967\n",
      "Current iteration=200, loss=0.38146861672982774\n",
      "Current iteration=300, loss=0.38141837809750806\n",
      "Current iteration=400, loss=0.3813902317752529\n",
      "Current iteration=500, loss=0.3813728100036933\n",
      "Current iteration=600, loss=0.3813612460792616\n",
      "Current iteration=700, loss=0.3813531778729441\n",
      "Current iteration=800, loss=0.38134734117954183\n",
      "Current iteration=900, loss=0.3813430069916571\n",
      "Current iteration=1000, loss=0.381339727986404\n",
      "Current iteration=1100, loss=0.3813372144268153\n",
      "Current iteration=1200, loss=0.38133526971411097\n",
      "Current iteration=1300, loss=0.3813337552055254\n",
      "Current iteration=1400, loss=0.3813325701460066\n",
      "Current iteration=0, loss=0.38171355464423495\n",
      "Current iteration=100, loss=0.3815774590414949\n",
      "Current iteration=200, loss=0.3815623794896966\n",
      "Current iteration=300, loss=0.3815548104347511\n",
      "Current iteration=400, loss=0.38154997426391823\n",
      "Current iteration=500, loss=0.3815465239281336\n",
      "Current iteration=600, loss=0.3815439390640463\n",
      "Current iteration=700, loss=0.38154195416241843\n",
      "Current iteration=800, loss=0.3815404071369944\n",
      "Current iteration=900, loss=0.3815391890131451\n",
      "Current iteration=0, loss=0.38124204267113215\n",
      "Current iteration=100, loss=0.38104876594008985\n",
      "Current iteration=200, loss=0.38100733219060495\n",
      "Current iteration=300, loss=0.38098727886098316\n",
      "Current iteration=400, loss=0.38097550015077936\n",
      "Current iteration=500, loss=0.38096780227430893\n",
      "Current iteration=600, loss=0.3809624240032957\n",
      "Current iteration=700, loss=0.38095849677290583\n",
      "Current iteration=800, loss=0.3809555395564189\n",
      "Current iteration=900, loss=0.38095326465864626\n",
      "Current iteration=1000, loss=0.3809514868270962\n",
      "Current iteration=1100, loss=0.38095008262941904\n",
      "Current iteration=0, loss=0.38144366738109825\n",
      "Current iteration=100, loss=0.3806673651986569\n",
      "Current iteration=200, loss=0.3805716815052874\n",
      "Current iteration=300, loss=0.3805204421872366\n",
      "Current iteration=400, loss=0.3804895235947159\n",
      "Current iteration=500, loss=0.38046930017921315\n",
      "Current iteration=600, loss=0.38045526066692553\n",
      "Current iteration=700, loss=0.38044507078966366\n",
      "Current iteration=800, loss=0.3804374287350125\n",
      "Current iteration=900, loss=0.3804315607574359\n",
      "Current iteration=1000, loss=0.38042697857159763\n",
      "Current iteration=1100, loss=0.3804233580247018\n",
      "Current iteration=1200, loss=0.38042047257924455\n",
      "Current iteration=1300, loss=0.38041816217012625\n",
      "Current iteration=1400, loss=0.38041630099398716\n",
      "Current iteration=1500, loss=0.3804148013889094\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.38487457202395886\n",
      "Current iteration=100, loss=0.3845105985792132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=200, loss=0.384411037396742\n",
      "Current iteration=300, loss=0.3843672710134138\n",
      "Current iteration=400, loss=0.3843448012126863\n",
      "Current iteration=500, loss=0.3843318709200725\n",
      "Current iteration=600, loss=0.3843238487344807\n",
      "Current iteration=700, loss=0.38431860919421956\n",
      "Current iteration=800, loss=0.38431506155883605\n",
      "Current iteration=900, loss=0.38431259792544803\n",
      "Current iteration=1000, loss=0.3843108565479117\n",
      "Current iteration=1100, loss=0.3843096104994086\n",
      "Current iteration=0, loss=0.3846322630824754\n",
      "Current iteration=100, loss=0.3845001775624101\n",
      "Current iteration=200, loss=0.3844870473640092\n",
      "Current iteration=300, loss=0.38448090102064086\n",
      "Current iteration=400, loss=0.3844772220071955\n",
      "Current iteration=500, loss=0.38447476574782774\n",
      "Current iteration=600, loss=0.3844730465623656\n",
      "Current iteration=700, loss=0.3844718145216981\n",
      "Current iteration=0, loss=0.38417465913602916\n",
      "Current iteration=100, loss=0.3839795039284595\n",
      "Current iteration=200, loss=0.3839412769717242\n",
      "Current iteration=300, loss=0.38392432751120104\n",
      "Current iteration=400, loss=0.3839151078162044\n",
      "Current iteration=500, loss=0.38390949761845417\n",
      "Current iteration=600, loss=0.3839058397470707\n",
      "Current iteration=700, loss=0.3839033453899584\n",
      "Current iteration=800, loss=0.38390159019459574\n",
      "Current iteration=900, loss=0.38390032926126705\n",
      "Current iteration=0, loss=0.3839413249714595\n",
      "Current iteration=100, loss=0.38354950700619\n",
      "Current iteration=200, loss=0.38343080083425723\n",
      "Current iteration=300, loss=0.3833781596589924\n",
      "Current iteration=400, loss=0.3833495436857076\n",
      "Current iteration=500, loss=0.38333224918469105\n",
      "Current iteration=600, loss=0.383321054006189\n",
      "Current iteration=700, loss=0.3833134515228683\n",
      "Current iteration=800, loss=0.3833081114676531\n",
      "Current iteration=900, loss=0.38330427111279514\n",
      "Current iteration=1000, loss=0.38330146355722405\n",
      "Current iteration=1100, loss=0.3832993888232582\n",
      "Current iteration=1200, loss=0.38329784504420866\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.3884279877332811\n",
      "Current iteration=100, loss=0.3880109986645886\n",
      "Current iteration=200, loss=0.3879169823521543\n",
      "Current iteration=300, loss=0.3878818666797181\n",
      "Current iteration=400, loss=0.3878657686426122\n",
      "Current iteration=500, loss=0.3878573550837649\n",
      "Current iteration=600, loss=0.3878525898449827\n",
      "Current iteration=700, loss=0.3878497466927361\n",
      "Current iteration=800, loss=0.38784798968185574\n",
      "Current iteration=0, loss=0.38812093443617274\n",
      "Current iteration=100, loss=0.387994034929863\n",
      "Current iteration=200, loss=0.38798307698358336\n",
      "Current iteration=300, loss=0.38797839314369076\n",
      "Current iteration=400, loss=0.3879758249645565\n",
      "Current iteration=500, loss=0.3879742588919301\n",
      "Current iteration=0, loss=0.38763826769168497\n",
      "Current iteration=100, loss=0.38743808313883316\n",
      "Current iteration=200, loss=0.3874029784281389\n",
      "Current iteration=300, loss=0.3873890841097965\n",
      "Current iteration=400, loss=0.3873822555850718\n",
      "Current iteration=500, loss=0.38737847823830707\n",
      "Current iteration=600, loss=0.387376234907203\n",
      "Current iteration=700, loss=0.3873748396240134\n",
      "Current iteration=0, loss=0.3873555876438237\n",
      "Current iteration=100, loss=0.38698210354498536\n",
      "Current iteration=200, loss=0.38687803628490125\n",
      "Current iteration=300, loss=0.38683682564692157\n",
      "Current iteration=400, loss=0.38681680059242385\n",
      "Current iteration=500, loss=0.38680589374013824\n",
      "Current iteration=600, loss=0.3867995019067056\n",
      "Current iteration=700, loss=0.38679555945844707\n",
      "Current iteration=800, loss=0.3867930429691664\n",
      "Current iteration=900, loss=0.38679139484600017\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.3926903344112875\n",
      "Current iteration=100, loss=0.3922021514245465\n",
      "Current iteration=200, loss=0.3921164844082729\n",
      "Current iteration=300, loss=0.3920904038374524\n",
      "Current iteration=400, loss=0.39208014752451087\n",
      "Current iteration=500, loss=0.39207546972602547\n",
      "Current iteration=600, loss=0.39207314869015764\n",
      "Current iteration=0, loss=0.39230633037744345\n",
      "Current iteration=100, loss=0.39218549408564785\n",
      "Current iteration=200, loss=0.3921768307919825\n",
      "Current iteration=300, loss=0.3921735611231239\n",
      "Current iteration=400, loss=0.3921719736386496\n",
      "Current iteration=0, loss=0.3917614801305649\n",
      "Current iteration=100, loss=0.3915557998179111\n",
      "Current iteration=200, loss=0.39152475055377733\n",
      "Current iteration=300, loss=0.3915141653448147\n",
      "Current iteration=400, loss=0.3915096139178028\n",
      "Current iteration=500, loss=0.3915073961919601\n",
      "Current iteration=0, loss=0.391504656585814\n",
      "Current iteration=100, loss=0.3911538469884442\n",
      "Current iteration=200, loss=0.3910664553281443\n",
      "Current iteration=300, loss=0.3910358019795601\n",
      "Current iteration=400, loss=0.3910230426552589\n",
      "Current iteration=500, loss=0.3910170314921093\n",
      "Current iteration=600, loss=0.39101396482391565\n",
      "Current iteration=700, loss=0.39101231245574847\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.3977859303486033\n",
      "Current iteration=100, loss=0.39720565740666813\n",
      "Current iteration=200, loss=0.39713136857523973\n",
      "Current iteration=300, loss=0.39711354320091014\n",
      "Current iteration=400, loss=0.39710774356180406\n",
      "Current iteration=500, loss=0.3971055375232207\n",
      "Current iteration=0, loss=0.39731100106525996\n",
      "Current iteration=100, loss=0.3971966449559519\n",
      "Current iteration=200, loss=0.39719021127080323\n",
      "Current iteration=300, loss=0.39718816544536495\n",
      "Current iteration=0, loss=0.3966664999771611\n",
      "Current iteration=100, loss=0.39646174118725946\n",
      "Current iteration=200, loss=0.39643697181272025\n",
      "Current iteration=300, loss=0.3964300766062139\n",
      "Current iteration=400, loss=0.3964276004758721\n",
      "Current iteration=0, loss=0.39649404096689755\n",
      "Current iteration=100, loss=0.3961715825444217\n",
      "Current iteration=200, loss=0.39610545746742504\n",
      "Current iteration=300, loss=0.3960849338250149\n",
      "Current iteration=400, loss=0.3960777733996055\n",
      "Current iteration=500, loss=0.3960749836295844\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.4038245101434289\n",
      "Current iteration=100, loss=0.40313398157867575\n",
      "Current iteration=200, loss=0.4030744346833317\n",
      "Current iteration=300, loss=0.40306350926123846\n",
      "Current iteration=400, loss=0.4030606939157858\n",
      "Current iteration=0, loss=0.4032506361894501\n",
      "Current iteration=100, loss=0.40314276086514583\n",
      "Current iteration=200, loss=0.4031383534838851\n",
      "Current iteration=0, loss=0.40247689081787824\n",
      "Current iteration=100, loss=0.4022845999697537\n",
      "Current iteration=200, loss=0.4022678947225878\n",
      "Current iteration=300, loss=0.40226437594305997\n",
      "Current iteration=0, loss=0.4024306954871524\n",
      "Current iteration=100, loss=0.40214209477562063\n",
      "Current iteration=200, loss=0.4020983437381668\n",
      "Current iteration=300, loss=0.40208729572851787\n",
      "Current iteration=400, loss=0.4020841218410271\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.4109076583052245\n",
      "Current iteration=100, loss=0.41009586326598524\n",
      "Current iteration=200, loss=0.4100550909520489\n",
      "Current iteration=300, loss=0.41004987818499244\n",
      "Current iteration=0, loss=0.410237924687291\n",
      "Current iteration=100, loss=0.4101362672780397\n",
      "Current iteration=0, loss=0.40932406948299815\n",
      "Current iteration=100, loss=0.40915143013876176\n",
      "Current iteration=200, loss=0.409142094877568\n",
      "Current iteration=0, loss=0.4094210860346539\n",
      "Current iteration=100, loss=0.4091714458164218\n",
      "Current iteration=200, loss=0.4091466617785166\n",
      "Current iteration=300, loss=0.40914220404394797\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.41914446265668087\n",
      "Current iteration=100, loss=0.4182052621417914\n",
      "Current iteration=200, loss=0.41818358074679957\n",
      "Current iteration=0, loss=0.4183847253657936\n",
      "Current iteration=100, loss=0.4182888563898097\n",
      "Current iteration=0, loss=0.4173331054860666\n",
      "Current iteration=100, loss=0.41718333339024394\n",
      "Current iteration=0, loss=0.4175728499040883\n",
      "Current iteration=100, loss=0.4173647842825617\n",
      "Current iteration=200, loss=0.41735318630832874\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.42864704552140054\n",
      "Current iteration=100, loss=0.42757571520534676\n",
      "Current iteration=200, loss=0.427567122744584\n",
      "Current iteration=0, loss=0.4277988817103205\n",
      "Current iteration=100, loss=0.4277085093523311\n",
      "Current iteration=0, loss=0.42662097203766863\n",
      "Current iteration=100, loss=0.42649458400947504\n",
      "Current iteration=0, loss=0.42699216428681863\n",
      "Current iteration=100, loss=0.4268240227394937\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.439513515461718\n",
      "Current iteration=100, loss=0.438307929277043\n",
      "Current iteration=0, loss=0.4385764877005003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.43729221371055027\n",
      "Current iteration=100, loss=0.43718622116887235\n",
      "Current iteration=0, loss=0.4377789241066053\n",
      "Current iteration=100, loss=0.4376425794781645\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.45182851626211523\n",
      "Current iteration=100, loss=0.45047551113571044\n",
      "Current iteration=0, loss=0.4507889873984481\n",
      "Current iteration=0, loss=0.44942321428902116\n",
      "Current iteration=0, loss=0.45000485846571175\n",
      "Current iteration=100, loss=0.4498912483869394\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.46562193457537915\n",
      "Current iteration=0, loss=0.4644643518310449\n",
      "Current iteration=0, loss=0.4630423403995487\n",
      "Current iteration=0, loss=0.46369290368888705\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.4808717385214998\n",
      "Current iteration=0, loss=0.47956451503427044\n",
      "Current iteration=0, loss=0.47811620202531985\n",
      "Current iteration=0, loss=0.4788072251794409\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.49740092116064577\n",
      "Current iteration=0, loss=0.49596240596993596\n",
      "Current iteration=0, loss=0.49452131874415095\n",
      "Current iteration=0, loss=0.49522661540525703\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.5149638250791126\n",
      "Current iteration=0, loss=0.5134202925737968\n",
      "Current iteration=0, loss=0.5120228222418628\n",
      "Current iteration=0, loss=0.5127258134869923\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.5331838537035778\n",
      "Current iteration=0, loss=0.5315939369404103\n",
      "Current iteration=0, loss=0.5302775502030502\n",
      "Current iteration=0, loss=0.5309578415561265\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.5515831515634915\n",
      "Current iteration=0, loss=0.5500891093176352\n",
      "Current iteration=0, loss=0.5488562263125318\n",
      "Current iteration=0, loss=0.5495185250447441\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.5697467321674781\n",
      "Current iteration=0, loss=0.5684405398039584\n",
      "Current iteration=0, loss=0.5672749719230528\n",
      "Current iteration=0, loss=0.5679277252021289\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.5871359729487223\n",
      "Current iteration=0, loss=0.5861530767055353\n",
      "Current iteration=0, loss=0.5850718331333398\n",
      "Current iteration=0, loss=0.5856907585314629\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6034033286066375\n",
      "Current iteration=0, loss=0.6028157789251348\n",
      "Current iteration=0, loss=0.6018380619200588\n",
      "Current iteration=0, loss=0.6024120365471198\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6183441654510337\n",
      "Current iteration=0, loss=0.6181036928238626\n",
      "Current iteration=0, loss=0.6172449281963467\n",
      "Current iteration=0, loss=0.6177582852165338\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.6319307975435694\n",
      "Current iteration=0, loss=0.6317975986795449\n",
      "Current iteration=0, loss=0.6310682248274423\n",
      "Current iteration=0, loss=0.6315122977827644\n",
      "Iteration 28\n",
      "Current iteration=0, loss=0.6443405033900625\n",
      "Current iteration=100, loss=0.6437803407415841\n",
      "Current iteration=200, loss=0.6438074844188004\n",
      "Current iteration=300, loss=0.644630527974384\n",
      "Current iteration=400, loss=0.6446313633882341\n",
      "Current iteration=500, loss=0.6446313634312824\n",
      "Current iteration=600, loss=0.6446313634312846\n",
      "Current iteration=700, loss=0.6446313634312846\n",
      "Current iteration=800, loss=0.6446313634312846\n",
      "Current iteration=900, loss=0.6446313634312845\n",
      "Current iteration=1000, loss=0.6446313634312846\n",
      "Current iteration=1100, loss=0.6446313634312846\n",
      "Current iteration=1200, loss=0.6446313634312846\n",
      "Current iteration=1300, loss=0.6446313634312846\n",
      "Current iteration=1400, loss=0.6446313634312846\n",
      "Current iteration=1500, loss=0.6446313634312845\n",
      "Current iteration=1600, loss=0.6446313634312845\n",
      "Current iteration=1700, loss=0.6446313634312846\n",
      "Current iteration=1800, loss=0.6446313634312846\n",
      "Current iteration=1900, loss=0.6446313634312846\n",
      "Current iteration=0, loss=0.6445327470632807\n",
      "Current iteration=100, loss=0.6443628672771163\n",
      "Current iteration=200, loss=0.6443628464226713\n",
      "Current iteration=300, loss=0.6443628464195554\n",
      "Current iteration=400, loss=0.6443628464195551\n",
      "Current iteration=500, loss=0.6443628464195551\n",
      "Current iteration=600, loss=0.6443628464195551\n",
      "Current iteration=700, loss=0.6443628464195551\n",
      "Current iteration=800, loss=0.6443628464195551\n",
      "Current iteration=900, loss=0.6443628464195551\n",
      "Current iteration=1000, loss=0.6443628464195551\n",
      "Current iteration=1100, loss=0.6443628464195551\n",
      "Current iteration=1200, loss=0.6443628464195551\n",
      "Current iteration=1300, loss=0.6443628464195551\n",
      "Current iteration=1400, loss=0.6443628464195551\n",
      "Current iteration=1500, loss=0.6443628464195551\n",
      "Current iteration=1600, loss=0.6443628464195551\n",
      "Current iteration=1700, loss=0.6443628464195551\n",
      "Current iteration=1800, loss=0.6443628464195551\n",
      "Current iteration=1900, loss=0.6443628464195551\n",
      "Current iteration=0, loss=0.6437126042296395\n",
      "Current iteration=0, loss=0.6435620467018478\n",
      "Iteration 29\n",
      "Current iteration=0, loss=0.6560602347800946\n",
      "Current iteration=100, loss=1.0946825216471667\n",
      "Current iteration=200, loss=1.0949252679919517\n",
      "Current iteration=300, loss=1.0949258295183057\n",
      "Current iteration=400, loss=1.094925830896727\n",
      "Current iteration=500, loss=1.0949258309001113\n",
      "Current iteration=600, loss=1.0949258309001197\n",
      "Current iteration=700, loss=1.0949258309001197\n",
      "Current iteration=800, loss=1.0949258309001197\n",
      "Current iteration=900, loss=1.0949258309001197\n",
      "Current iteration=1000, loss=1.0949258309001197\n",
      "Current iteration=1100, loss=1.0949258309001197\n",
      "Current iteration=1200, loss=1.0949258309001197\n",
      "Current iteration=1300, loss=1.0949258309001197\n",
      "Current iteration=1400, loss=1.0949258309001197\n",
      "Current iteration=1500, loss=1.0949258309001197\n",
      "Current iteration=1600, loss=1.0949258309001197\n",
      "Current iteration=1700, loss=1.0949258309001197\n",
      "Current iteration=1800, loss=1.0949258309001197\n",
      "Current iteration=1900, loss=1.0949258309001197\n",
      "Current iteration=0, loss=1.0930304420916337\n",
      "Current iteration=100, loss=1.093058383502128\n",
      "Current iteration=200, loss=1.0930595688213292\n",
      "Current iteration=300, loss=1.0930595721743002\n",
      "Current iteration=400, loss=1.0930595721837872\n",
      "Current iteration=500, loss=1.0930595721838146\n",
      "Current iteration=600, loss=1.0930595721838143\n",
      "Current iteration=700, loss=1.0930595721838143\n",
      "Current iteration=800, loss=1.0930595721838143\n",
      "Current iteration=900, loss=1.0930595721838143\n",
      "Current iteration=1000, loss=1.0930595721838143\n",
      "Current iteration=1100, loss=1.0930595721838143\n",
      "Current iteration=1200, loss=1.0930595721838143\n",
      "Current iteration=1300, loss=1.0930595721838143\n",
      "Current iteration=1400, loss=1.0930595721838143\n",
      "Current iteration=1500, loss=1.0930595721838143\n",
      "Current iteration=1600, loss=1.0930595721838143\n",
      "Current iteration=1700, loss=1.0930595721838143\n",
      "Current iteration=1800, loss=1.0930595721838143\n",
      "Current iteration=1900, loss=1.0930595721838143\n",
      "Current iteration=0, loss=1.0881198380951997\n",
      "Current iteration=100, loss=1.0734485143484882\n",
      "Current iteration=200, loss=1.0734477161779512\n",
      "Current iteration=300, loss=1.0734477137048861\n",
      "Current iteration=400, loss=1.073447713697223\n",
      "Current iteration=500, loss=1.0734477136971994\n",
      "Current iteration=600, loss=1.0734477136971992\n",
      "Current iteration=700, loss=1.0734477136971992\n",
      "Current iteration=800, loss=1.0734477136971992\n",
      "Current iteration=900, loss=1.0734477136971992\n",
      "Current iteration=1000, loss=1.0734477136971992\n",
      "Current iteration=1100, loss=1.0734477136971992\n",
      "Current iteration=1200, loss=1.0734477136971992\n",
      "Current iteration=1300, loss=1.0734477136971992\n",
      "Current iteration=1400, loss=1.0734477136971992\n",
      "Current iteration=1500, loss=1.0734477136971992\n",
      "Current iteration=1600, loss=1.0734477136971992\n",
      "Current iteration=1700, loss=1.0734477136971992\n",
      "Current iteration=1800, loss=1.0734477136971992\n",
      "Current iteration=1900, loss=1.0734477136971992\n",
      "Current iteration=0, loss=1.0832826167636576\n",
      "Current iteration=100, loss=1.0976876503677009\n",
      "Current iteration=200, loss=1.0976895739591719\n",
      "Current iteration=300, loss=1.0976895776438873\n",
      "Current iteration=400, loss=1.0976895776509492\n",
      "Current iteration=500, loss=1.0976895776509643\n",
      "Current iteration=600, loss=1.0976895776509643\n",
      "Current iteration=700, loss=1.0976895776509643\n",
      "Current iteration=800, loss=1.0976895776509643\n",
      "Current iteration=900, loss=1.0976895776509643\n",
      "Current iteration=1000, loss=1.0976895776509643\n",
      "Current iteration=1100, loss=1.0976895776509643\n",
      "Current iteration=1200, loss=1.0976895776509643\n",
      "Current iteration=1300, loss=1.0976895776509643\n",
      "Current iteration=1400, loss=1.0976895776509643\n",
      "Current iteration=1500, loss=1.0976895776509643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1600, loss=1.0976895776509643\n",
      "Current iteration=1700, loss=1.0976895776509643\n",
      "Current iteration=1800, loss=1.0976895776509643\n",
      "Current iteration=1900, loss=1.0976895776509643\n",
      "Iteration 0\n",
      "Current iteration=0, loss=0.6211662975801961\n",
      "Current iteration=100, loss=0.4968894234883006\n",
      "Current iteration=200, loss=0.4878786455243362\n",
      "Current iteration=300, loss=0.4833087682333199\n",
      "Current iteration=400, loss=0.48066089460611133\n",
      "Current iteration=500, loss=0.4789912552354673\n",
      "Current iteration=600, loss=0.4778714956342543\n",
      "Current iteration=700, loss=0.47708354897312255\n",
      "Current iteration=800, loss=0.4765065997202151\n",
      "Current iteration=900, loss=0.4760694766976356\n",
      "Current iteration=1000, loss=0.4757282146631611\n",
      "Current iteration=1100, loss=0.47545463241831376\n",
      "Current iteration=1200, loss=0.47523012255538033\n",
      "Current iteration=1300, loss=0.4750420759726502\n",
      "Current iteration=1400, loss=0.474881734528562\n",
      "Current iteration=1500, loss=0.4747428707682647\n",
      "Current iteration=1600, loss=0.4746209637787919\n",
      "Current iteration=1700, loss=0.47451267297864513\n",
      "Current iteration=1800, loss=0.47441549131412186\n",
      "Current iteration=1900, loss=0.4743275098884705\n",
      "Current iteration=0, loss=0.47733963738512\n",
      "Current iteration=100, loss=0.4765140655903716\n",
      "Current iteration=200, loss=0.4762204822341581\n",
      "Current iteration=300, loss=0.4759870704434432\n",
      "Current iteration=400, loss=0.47577964368203063\n",
      "Current iteration=500, loss=0.4755894277891512\n",
      "Current iteration=600, loss=0.47541284071145545\n",
      "Current iteration=700, loss=0.47524784251715313\n",
      "Current iteration=800, loss=0.475093009418688\n",
      "Current iteration=900, loss=0.4749472376461252\n",
      "Current iteration=1000, loss=0.47480962576162805\n",
      "Current iteration=1100, loss=0.4746794167207872\n",
      "Current iteration=1200, loss=0.474555963823502\n",
      "Current iteration=1300, loss=0.47443870812407124\n",
      "Current iteration=1400, loss=0.4743271622740957\n",
      "Current iteration=1500, loss=0.4742208984183024\n",
      "Current iteration=1600, loss=0.47411953884658903\n",
      "Current iteration=1700, loss=0.47402274861170735\n",
      "Current iteration=1800, loss=0.47393022958711256\n",
      "Current iteration=1900, loss=0.4738417155917745\n",
      "Current iteration=0, loss=0.4772489747768824\n",
      "Current iteration=100, loss=0.47667855856423935\n",
      "Current iteration=200, loss=0.4765219461813533\n",
      "Current iteration=300, loss=0.4764171423006692\n",
      "Current iteration=400, loss=0.4763361621425848\n",
      "Current iteration=500, loss=0.47626846287953467\n",
      "Current iteration=600, loss=0.47620919508899956\n",
      "Current iteration=700, loss=0.4761558675528044\n",
      "Current iteration=800, loss=0.4761070824640824\n",
      "Current iteration=900, loss=0.47606199380023695\n",
      "Current iteration=1000, loss=0.47602012935343646\n",
      "Current iteration=1100, loss=0.47598181182365\n",
      "Current iteration=1200, loss=0.4759485617597819\n",
      "Current iteration=1300, loss=0.47591953111218327\n",
      "Current iteration=1400, loss=0.4758932457362821\n",
      "Current iteration=1500, loss=0.4758692011043468\n",
      "Current iteration=1600, loss=0.4758471165302153\n",
      "Current iteration=1700, loss=0.4758267766767588\n",
      "Current iteration=1800, loss=0.4758080017335087\n",
      "Current iteration=1900, loss=0.475790637052202\n",
      "Current iteration=0, loss=0.47488933907381603\n",
      "Current iteration=100, loss=0.4740014843061373\n",
      "Current iteration=200, loss=0.47388041592662555\n",
      "Current iteration=300, loss=0.47378976669754275\n",
      "Current iteration=400, loss=0.47371062633810046\n",
      "Current iteration=500, loss=0.4736386360869788\n",
      "Current iteration=600, loss=0.47357220364571595\n",
      "Current iteration=700, loss=0.4735107167486715\n",
      "Current iteration=800, loss=0.47345435804186203\n",
      "Current iteration=900, loss=0.47340363595469903\n",
      "Current iteration=1000, loss=0.47335916916061804\n",
      "Current iteration=1100, loss=0.4733221519357692\n",
      "Current iteration=1200, loss=0.4732916299034689\n",
      "Current iteration=1300, loss=0.47326527610762636\n",
      "Current iteration=1400, loss=0.47324187548069635\n",
      "Current iteration=1500, loss=0.47322083109724233\n",
      "Current iteration=1600, loss=0.47320176345080567\n",
      "Current iteration=1700, loss=0.4731843943953409\n",
      "Current iteration=1800, loss=0.47316850574699404\n",
      "Current iteration=1900, loss=0.4731539203059806\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.47584443057218273\n",
      "Current iteration=100, loss=0.4752065959266623\n",
      "Current iteration=200, loss=0.474832932339286\n",
      "Current iteration=300, loss=0.4747677650395349\n",
      "Current iteration=400, loss=0.4747260183807114\n",
      "Current iteration=500, loss=0.47469547699319337\n",
      "Current iteration=600, loss=0.4746714187871416\n",
      "Current iteration=700, loss=0.4746516108755903\n",
      "Current iteration=800, loss=0.47463485076014017\n",
      "Current iteration=900, loss=0.4746204143419187\n",
      "Current iteration=1000, loss=0.4746078250565143\n",
      "Current iteration=1100, loss=0.47459674635768884\n",
      "Current iteration=1200, loss=0.4745869273797143\n",
      "Current iteration=1300, loss=0.4745781735542365\n",
      "Current iteration=1400, loss=0.4745703296330279\n",
      "Current iteration=1500, loss=0.4745632692086788\n",
      "Current iteration=1600, loss=0.4745568878328599\n",
      "Current iteration=1700, loss=0.47455109824677655\n",
      "Current iteration=1800, loss=0.47454582692639563\n",
      "Current iteration=1900, loss=0.4745410114917809\n",
      "Current iteration=0, loss=0.47560797472448724\n",
      "Current iteration=100, loss=0.4749706870229136\n",
      "Current iteration=200, loss=0.47481021248984284\n",
      "Current iteration=300, loss=0.4747212942824944\n",
      "Current iteration=400, loss=0.4747005585742063\n",
      "Current iteration=500, loss=0.47468901076232367\n",
      "Current iteration=600, loss=0.47468121614302805\n",
      "Current iteration=700, loss=0.4746754982764206\n",
      "Current iteration=800, loss=0.47467106042976687\n",
      "Current iteration=900, loss=0.4746674712306572\n",
      "Current iteration=1000, loss=0.47466447931073025\n",
      "Current iteration=1100, loss=0.4746619295110992\n",
      "Current iteration=1200, loss=0.4746597208454016\n",
      "Current iteration=1300, loss=0.4746577842456089\n",
      "Current iteration=1400, loss=0.47465607030980517\n",
      "Current iteration=1500, loss=0.4746545423030283\n",
      "Current iteration=1600, loss=0.474653172004789\n",
      "Current iteration=1700, loss=0.4746519371479968\n",
      "Current iteration=1800, loss=0.4746508197770368\n",
      "Current iteration=0, loss=0.4781138244406106\n",
      "Current iteration=100, loss=0.4776119576395756\n",
      "Current iteration=200, loss=0.47750824500004546\n",
      "Current iteration=300, loss=0.4774528392430724\n",
      "Current iteration=400, loss=0.4774185401805429\n",
      "Current iteration=500, loss=0.4773951565142725\n",
      "Current iteration=600, loss=0.4773780655577926\n",
      "Current iteration=700, loss=0.4773649448176457\n",
      "Current iteration=800, loss=0.4773545297981295\n",
      "Current iteration=900, loss=0.47734607767968457\n",
      "Current iteration=1000, loss=0.4773391179607174\n",
      "Current iteration=1100, loss=0.47733333080027535\n",
      "Current iteration=1200, loss=0.47732848530667993\n",
      "Current iteration=1300, loss=0.47732440692098554\n",
      "Current iteration=1400, loss=0.4773209592919312\n",
      "Current iteration=1500, loss=0.4773180335687852\n",
      "Current iteration=1600, loss=0.4773155416273536\n",
      "Current iteration=1700, loss=0.47731341148236456\n",
      "Current iteration=1800, loss=0.4773115839903093\n",
      "Current iteration=1900, loss=0.47731001036785214\n",
      "Current iteration=0, loss=0.476397956318791\n",
      "Current iteration=100, loss=0.47557895099916103\n",
      "Current iteration=200, loss=0.47548319269307365\n",
      "Current iteration=300, loss=0.4754150727394685\n",
      "Current iteration=400, loss=0.475358383249172\n",
      "Current iteration=500, loss=0.4753090675460992\n",
      "Current iteration=600, loss=0.47526545018509825\n",
      "Current iteration=700, loss=0.4752269259721283\n",
      "Current iteration=800, loss=0.47519355913916167\n",
      "Current iteration=900, loss=0.4751651360937136\n",
      "Current iteration=1000, loss=0.4751409638465893\n",
      "Current iteration=1100, loss=0.4751206108184967\n",
      "Current iteration=1200, loss=0.4751042094380681\n",
      "Current iteration=1300, loss=0.4750916229851979\n",
      "Current iteration=1400, loss=0.47508179092358443\n",
      "Current iteration=1500, loss=0.4750737436086731\n",
      "Current iteration=1600, loss=0.475066969458391\n",
      "Current iteration=1700, loss=0.4750611830147153\n",
      "Current iteration=1800, loss=0.4750561950545946\n",
      "Current iteration=1900, loss=0.4750518666160923\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.4781895237611773\n",
      "Current iteration=100, loss=0.47745134302261605\n",
      "Current iteration=200, loss=0.4771163176725301\n",
      "Current iteration=300, loss=0.4770358930425721\n",
      "Current iteration=400, loss=0.4769775114924053\n",
      "Current iteration=500, loss=0.47693018584864244\n",
      "Current iteration=600, loss=0.47688985461431876\n",
      "Current iteration=700, loss=0.47685450336449575\n",
      "Current iteration=800, loss=0.4768229744497322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=900, loss=0.4767945341298707\n",
      "Current iteration=1000, loss=0.4767686777544366\n",
      "Current iteration=1100, loss=0.4767450345102534\n",
      "Current iteration=1200, loss=0.47672331801002515\n",
      "Current iteration=1300, loss=0.47670329897118724\n",
      "Current iteration=1400, loss=0.4766847890359649\n",
      "Current iteration=1500, loss=0.47666763052142763\n",
      "Current iteration=1600, loss=0.47665168952241765\n",
      "Current iteration=1700, loss=0.47663685103211273\n",
      "Current iteration=1800, loss=0.4766230153506818\n",
      "Current iteration=1900, loss=0.4766100953603244\n",
      "Current iteration=0, loss=0.4777725584021189\n",
      "Current iteration=100, loss=0.47715513407038473\n",
      "Current iteration=200, loss=0.47700989849456416\n",
      "Current iteration=300, loss=0.47691611701712244\n",
      "Current iteration=400, loss=0.4768451695126322\n",
      "Current iteration=500, loss=0.47678882717544435\n",
      "Current iteration=600, loss=0.4767482609992922\n",
      "Current iteration=700, loss=0.47673601207616206\n",
      "Current iteration=800, loss=0.47672983061355145\n",
      "Current iteration=900, loss=0.47672538338707554\n",
      "Current iteration=1000, loss=0.47672186026727015\n",
      "Current iteration=1100, loss=0.47671892932396964\n",
      "Current iteration=1200, loss=0.4767164201019215\n",
      "Current iteration=1300, loss=0.47671423274438723\n",
      "Current iteration=1400, loss=0.47671230299398326\n",
      "Current iteration=1500, loss=0.47671058633347535\n",
      "Current iteration=1600, loss=0.47670905006817427\n",
      "Current iteration=1700, loss=0.4767076690744604\n",
      "Current iteration=1800, loss=0.4767064233655952\n",
      "Current iteration=1900, loss=0.47670529661384226\n",
      "Current iteration=0, loss=0.48015269434579744\n",
      "Current iteration=100, loss=0.47964612578380095\n",
      "Current iteration=200, loss=0.4795428202538931\n",
      "Current iteration=300, loss=0.4794881827700066\n",
      "Current iteration=400, loss=0.47945457424016014\n",
      "Current iteration=500, loss=0.4794317932833605\n",
      "Current iteration=600, loss=0.479415255095707\n",
      "Current iteration=700, loss=0.47940266123647\n",
      "Current iteration=800, loss=0.4793927562858433\n",
      "Current iteration=900, loss=0.47938479744201323\n",
      "Current iteration=1000, loss=0.47937831024842326\n",
      "Current iteration=1100, loss=0.47937297015277286\n",
      "Current iteration=1200, loss=0.4793685424335002\n",
      "Current iteration=1300, loss=0.47936485017864855\n",
      "Current iteration=1400, loss=0.4793617561772804\n",
      "Current iteration=1500, loss=0.47935915196542767\n",
      "Current iteration=1600, loss=0.47935695072613865\n",
      "Current iteration=1700, loss=0.47935508238999647\n",
      "Current iteration=1800, loss=0.47935349007851197\n",
      "Current iteration=1900, loss=0.47935212742445876\n",
      "Current iteration=0, loss=0.47852465358421553\n",
      "Current iteration=100, loss=0.47775029136175223\n",
      "Current iteration=200, loss=0.47767438296040465\n",
      "Current iteration=300, loss=0.4776237970645722\n",
      "Current iteration=400, loss=0.47758358675591894\n",
      "Current iteration=500, loss=0.4775498547499589\n",
      "Current iteration=600, loss=0.4775208921137318\n",
      "Current iteration=700, loss=0.47749586503101205\n",
      "Current iteration=800, loss=0.4774745002790854\n",
      "Current iteration=900, loss=0.47745669512760974\n",
      "Current iteration=1000, loss=0.4774420510868582\n",
      "Current iteration=1100, loss=0.4774299626183084\n",
      "Current iteration=1200, loss=0.4774198794357\n",
      "Current iteration=1300, loss=0.47741137898044794\n",
      "Current iteration=1400, loss=0.47740414739664355\n",
      "Current iteration=1500, loss=0.4773979490252234\n",
      "Current iteration=1600, loss=0.47739260301184977\n",
      "Current iteration=1700, loss=0.4773879675622922\n",
      "Current iteration=1800, loss=0.47738392951555736\n",
      "Current iteration=1900, loss=0.4773803972872814\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.4806679635137634\n",
      "Current iteration=100, loss=0.4796463897867225\n",
      "Current iteration=200, loss=0.4795147011924213\n",
      "Current iteration=300, loss=0.47941469896113753\n",
      "Current iteration=400, loss=0.4793318349909665\n",
      "Current iteration=500, loss=0.47926086726506617\n",
      "Current iteration=600, loss=0.4791989040071689\n",
      "Current iteration=700, loss=0.47914413889379304\n",
      "Current iteration=800, loss=0.47909533872142873\n",
      "Current iteration=900, loss=0.47905160033586486\n",
      "Current iteration=1000, loss=0.4790122265211472\n",
      "Current iteration=1100, loss=0.47897665836999037\n",
      "Current iteration=1200, loss=0.4789444358412126\n",
      "Current iteration=1300, loss=0.47891517312578114\n",
      "Current iteration=1400, loss=0.4788885422465134\n",
      "Current iteration=1500, loss=0.47886426151971384\n",
      "Current iteration=1600, loss=0.4788420870652883\n",
      "Current iteration=1700, loss=0.47882180633815913\n",
      "Current iteration=1800, loss=0.4788032330670899\n",
      "Current iteration=1900, loss=0.47878620321413384\n",
      "Current iteration=0, loss=0.48015894239877155\n",
      "Current iteration=100, loss=0.47955753791323574\n",
      "Current iteration=200, loss=0.479427147195652\n",
      "Current iteration=300, loss=0.47934654779835395\n",
      "Current iteration=400, loss=0.47928775041534555\n",
      "Current iteration=500, loss=0.4792425557607112\n",
      "Current iteration=600, loss=0.47920703525302044\n",
      "Current iteration=700, loss=0.47917876435949724\n",
      "Current iteration=800, loss=0.4791560650526492\n",
      "Current iteration=900, loss=0.47913771239469927\n",
      "Current iteration=1000, loss=0.4791227864092776\n",
      "Current iteration=1100, loss=0.4791105837253852\n",
      "Current iteration=1200, loss=0.4791005597243081\n",
      "Current iteration=1300, loss=0.47909228868809584\n",
      "Current iteration=1400, loss=0.47908543612500987\n",
      "Current iteration=1500, loss=0.47907974320204\n",
      "Current iteration=1600, loss=0.4790750371559518\n",
      "Current iteration=1700, loss=0.47907130990398356\n",
      "Current iteration=1800, loss=0.47906880013056236\n",
      "Current iteration=0, loss=0.48247675801870166\n",
      "Current iteration=100, loss=0.48195896938614635\n",
      "Current iteration=200, loss=0.4818538666729568\n",
      "Current iteration=300, loss=0.48179781557498996\n",
      "Current iteration=400, loss=0.4817629077836907\n",
      "Current iteration=500, loss=0.481738965141012\n",
      "Current iteration=600, loss=0.48172144625226887\n",
      "Current iteration=700, loss=0.4817080698146118\n",
      "Current iteration=800, loss=0.4816975720813632\n",
      "Current iteration=900, loss=0.4816891867246991\n",
      "Current iteration=1000, loss=0.48168240986527955\n",
      "Current iteration=1100, loss=0.4816768876438041\n",
      "Current iteration=1200, loss=0.48167235923425383\n",
      "Current iteration=1300, loss=0.4816686259644527\n",
      "Current iteration=1400, loss=0.4816655332617939\n",
      "Current iteration=1500, loss=0.4816629592408564\n",
      "Current iteration=1600, loss=0.4816608069653813\n",
      "Current iteration=1700, loss=0.4816589989022316\n",
      "Current iteration=1800, loss=0.48165747278592824\n",
      "Current iteration=1900, loss=0.48165617845308845\n",
      "Current iteration=0, loss=0.48094504947160865\n",
      "Current iteration=100, loss=0.48020001275196245\n",
      "Current iteration=200, loss=0.4801324021148571\n",
      "Current iteration=300, loss=0.48008920441917985\n",
      "Current iteration=400, loss=0.4800563124549059\n",
      "Current iteration=500, loss=0.4800297238405633\n",
      "Current iteration=600, loss=0.480007596895708\n",
      "Current iteration=700, loss=0.47998892286842\n",
      "Current iteration=800, loss=0.479973153774922\n",
      "Current iteration=900, loss=0.479960026190635\n",
      "Current iteration=1000, loss=0.4799493375301454\n",
      "Current iteration=1100, loss=0.4799407608174194\n",
      "Current iteration=1200, loss=0.47993388950488325\n",
      "Current iteration=1300, loss=0.47992835215565444\n",
      "Current iteration=1400, loss=0.4799238542530229\n",
      "Current iteration=1500, loss=0.47992017252923047\n",
      "Current iteration=1600, loss=0.47991713844742595\n",
      "Current iteration=1700, loss=0.47991462349589986\n",
      "Current iteration=1800, loss=0.4799125283482097\n",
      "Current iteration=1900, loss=0.47991077523407016\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.48256108583864593\n",
      "Current iteration=100, loss=0.4820995521072275\n",
      "Current iteration=200, loss=0.4819507417653708\n",
      "Current iteration=300, loss=0.4818360315551343\n",
      "Current iteration=400, loss=0.48174109923533315\n",
      "Current iteration=500, loss=0.4816606106155783\n",
      "Current iteration=600, loss=0.48159147656269063\n",
      "Current iteration=700, loss=0.48153159416308927\n",
      "Current iteration=800, loss=0.4814794117560086\n",
      "Current iteration=900, loss=0.4814337285346526\n",
      "Current iteration=1000, loss=0.48139358598644805\n",
      "Current iteration=1100, loss=0.48135820260806805\n",
      "Current iteration=1200, loss=0.4813269315126772\n",
      "Current iteration=1300, loss=0.4812992311986287\n",
      "Current iteration=1400, loss=0.4812746444187474\n",
      "Current iteration=1500, loss=0.4812527823387588\n",
      "Current iteration=1600, loss=0.48123331233005007\n",
      "Current iteration=1700, loss=0.4812159483686049\n",
      "Current iteration=1800, loss=0.48120044336799445\n",
      "Current iteration=1900, loss=0.4811865829861537\n",
      "Current iteration=0, loss=0.4827951277521422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=0.4821913380094363\n",
      "Current iteration=200, loss=0.48206803762706346\n",
      "Current iteration=300, loss=0.48199476131320695\n",
      "Current iteration=400, loss=0.4819430029192768\n",
      "Current iteration=500, loss=0.48190435888501126\n",
      "Current iteration=600, loss=0.48187479514426096\n",
      "Current iteration=700, loss=0.481851850125501\n",
      "Current iteration=800, loss=0.481833854902153\n",
      "Current iteration=900, loss=0.4818196211411387\n",
      "Current iteration=1000, loss=0.48180827959722383\n",
      "Current iteration=1100, loss=0.4817991830591831\n",
      "Current iteration=1200, loss=0.4817918431987976\n",
      "Current iteration=1300, loss=0.4817858876013113\n",
      "Current iteration=1400, loss=0.48178102968180164\n",
      "Current iteration=1500, loss=0.48177704718411074\n",
      "Current iteration=1600, loss=0.48177376656151266\n",
      "Current iteration=1700, loss=0.4817710514755945\n",
      "Current iteration=1800, loss=0.48176879422915925\n",
      "Current iteration=1900, loss=0.481766909320507\n",
      "Current iteration=0, loss=0.48498577327596043\n",
      "Current iteration=100, loss=0.4844548070576829\n",
      "Current iteration=200, loss=0.4843498716522123\n",
      "Current iteration=300, loss=0.48429460064263613\n",
      "Current iteration=400, loss=0.48426083070022896\n",
      "Current iteration=500, loss=0.4842381829609004\n",
      "Current iteration=600, loss=0.4842220138732111\n",
      "Current iteration=700, loss=0.4842099856576151\n",
      "Current iteration=800, loss=0.48420079777695135\n",
      "Current iteration=900, loss=0.4841936585573609\n",
      "Current iteration=1000, loss=0.4841880476115394\n",
      "Current iteration=1100, loss=0.4841836018953152\n",
      "Current iteration=1200, loss=0.48418005721955565\n",
      "Current iteration=1300, loss=0.484177215860962\n",
      "Current iteration=1400, loss=0.48417492714276905\n",
      "Current iteration=1500, loss=0.48417307489988004\n",
      "Current iteration=1600, loss=0.484171568883929\n",
      "Current iteration=1700, loss=0.48417033860231967\n",
      "Current iteration=0, loss=0.48355633154908173\n",
      "Current iteration=100, loss=0.4828537978988681\n",
      "Current iteration=200, loss=0.4827916136416547\n",
      "Current iteration=300, loss=0.48275311100581064\n",
      "Current iteration=400, loss=0.4827251153603336\n",
      "Current iteration=500, loss=0.482703402651442\n",
      "Current iteration=600, loss=0.4826859711135354\n",
      "Current iteration=700, loss=0.48267170994892694\n",
      "Current iteration=800, loss=0.48265996081263446\n",
      "Current iteration=900, loss=0.4826503253320332\n",
      "Current iteration=1000, loss=0.48264253474402036\n",
      "Current iteration=1100, loss=0.4826363374786753\n",
      "Current iteration=1200, loss=0.4826314557806656\n",
      "Current iteration=1300, loss=0.48262761610152694\n",
      "Current iteration=1400, loss=0.48262458470442327\n",
      "Current iteration=1500, loss=0.48262217749740166\n",
      "Current iteration=1600, loss=0.48262025417501375\n",
      "Current iteration=1700, loss=0.4826187085582038\n",
      "Current iteration=1800, loss=0.48261745995662525\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.48510501072931583\n",
      "Current iteration=100, loss=0.48469867226044355\n",
      "Current iteration=200, loss=0.4845524276950944\n",
      "Current iteration=300, loss=0.4844434396642067\n",
      "Current iteration=400, loss=0.4843565219132983\n",
      "Current iteration=500, loss=0.4842853661146956\n",
      "Current iteration=600, loss=0.48422627531029644\n",
      "Current iteration=700, loss=0.4841767483637492\n",
      "Current iteration=800, loss=0.48413496614282664\n",
      "Current iteration=900, loss=0.48409954802350263\n",
      "Current iteration=1000, loss=0.4840694154021536\n",
      "Current iteration=1100, loss=0.48404370737410024\n",
      "Current iteration=1200, loss=0.4840217254784706\n",
      "Current iteration=1300, loss=0.48400289591610046\n",
      "Current iteration=1400, loss=0.4839867427677422\n",
      "Current iteration=1500, loss=0.4839728683882112\n",
      "Current iteration=1600, loss=0.48396093863957834\n",
      "Current iteration=1700, loss=0.48395067149567594\n",
      "Current iteration=1800, loss=0.48394182806986247\n",
      "Current iteration=1900, loss=0.48393420543508736\n",
      "Current iteration=0, loss=0.4856992628250894\n",
      "Current iteration=100, loss=0.4850849180271744\n",
      "Current iteration=200, loss=0.48496411689070024\n",
      "Current iteration=300, loss=0.48489549118320996\n",
      "Current iteration=400, loss=0.48484851052554095\n",
      "Current iteration=500, loss=0.48481437896734203\n",
      "Current iteration=600, loss=0.48478890028049104\n",
      "Current iteration=700, loss=0.484769557383145\n",
      "Current iteration=800, loss=0.484754687951912\n",
      "Current iteration=900, loss=0.4847431409612779\n",
      "Current iteration=1000, loss=0.4847340963494837\n",
      "Current iteration=1100, loss=0.48472695802022814\n",
      "Current iteration=1200, loss=0.4847212859124332\n",
      "Current iteration=1300, loss=0.48471675102331413\n",
      "Current iteration=1400, loss=0.4847131047433201\n",
      "Current iteration=1500, loss=0.4847101574754487\n",
      "Current iteration=1600, loss=0.4847077634549263\n",
      "Current iteration=1700, loss=0.484705809805863\n",
      "Current iteration=1800, loss=0.48470420854908036\n",
      "Current iteration=1900, loss=0.4847028906994062\n",
      "Current iteration=0, loss=0.48773846224343786\n",
      "Current iteration=100, loss=0.48720163903513386\n",
      "Current iteration=200, loss=0.48710132505628007\n",
      "Current iteration=300, loss=0.4870493592761463\n",
      "Current iteration=400, loss=0.4870188388310631\n",
      "Current iteration=500, loss=0.4869993481697139\n",
      "Current iteration=600, loss=0.48698608935945853\n",
      "Current iteration=700, loss=0.48697665984227845\n",
      "Current iteration=800, loss=0.486969751688143\n",
      "Current iteration=900, loss=0.48696459153689636\n",
      "Current iteration=1000, loss=0.4869606871751746\n",
      "Current iteration=1100, loss=0.4869577064557225\n",
      "Current iteration=1200, loss=0.4869554155890807\n",
      "Current iteration=1300, loss=0.4869536452676799\n",
      "Current iteration=1400, loss=0.48695227058203\n",
      "Current iteration=0, loss=0.486397527236734\n",
      "Current iteration=100, loss=0.48574295159488085\n",
      "Current iteration=200, loss=0.4856850947174567\n",
      "Current iteration=300, loss=0.48565101705377134\n",
      "Current iteration=400, loss=0.4856276341772274\n",
      "Current iteration=500, loss=0.4856104309046781\n",
      "Current iteration=600, loss=0.4855972627714255\n",
      "Current iteration=700, loss=0.48558694874622566\n",
      "Current iteration=800, loss=0.4855787773680409\n",
      "Current iteration=900, loss=0.48557229008284836\n",
      "Current iteration=1000, loss=0.4855671673714959\n",
      "Current iteration=1100, loss=0.48556316021570156\n",
      "Current iteration=1200, loss=0.4855600539454389\n",
      "Current iteration=1300, loss=0.48555765923708794\n",
      "Current iteration=1400, loss=0.48555581564857025\n",
      "Current iteration=1500, loss=0.48555439402069334\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.48811351243364787\n",
      "Current iteration=100, loss=0.48771675113155466\n",
      "Current iteration=200, loss=0.4875685271199259\n",
      "Current iteration=300, loss=0.48746445521947435\n",
      "Current iteration=400, loss=0.48738593523543833\n",
      "Current iteration=500, loss=0.48732498525629353\n",
      "Current iteration=600, loss=0.4872769490100232\n",
      "Current iteration=700, loss=0.48723872896609904\n",
      "Current iteration=800, loss=0.4872081214885314\n",
      "Current iteration=900, loss=0.4871834958572772\n",
      "Current iteration=1000, loss=0.4871636139579856\n",
      "Current iteration=1100, loss=0.48714751893776154\n",
      "Current iteration=1200, loss=0.4871344618698529\n",
      "Current iteration=1300, loss=0.4871238511047146\n",
      "Current iteration=1400, loss=0.4871152159957293\n",
      "Current iteration=1500, loss=0.48710818017983454\n",
      "Current iteration=1600, loss=0.4871024414643088\n",
      "Current iteration=1700, loss=0.487097756431038\n",
      "Current iteration=1800, loss=0.4870939284991482\n",
      "Current iteration=1900, loss=0.48709079857684434\n",
      "Current iteration=0, loss=0.48885305254731565\n",
      "Current iteration=100, loss=0.48824693005957515\n",
      "Current iteration=200, loss=0.48813172372957386\n",
      "Current iteration=300, loss=0.4880695412343592\n",
      "Current iteration=400, loss=0.48802893556731636\n",
      "Current iteration=500, loss=0.48800068581078065\n",
      "Current iteration=600, loss=0.48798042133210007\n",
      "Current iteration=700, loss=0.48796559364200565\n",
      "Current iteration=800, loss=0.48795458242910245\n",
      "Current iteration=900, loss=0.4879463085437948\n",
      "Current iteration=1000, loss=0.48794003066022623\n",
      "Current iteration=1100, loss=0.48793522767143377\n",
      "Current iteration=1200, loss=0.48793152660404665\n",
      "Current iteration=1300, loss=0.48792865657325535\n",
      "Current iteration=1400, loss=0.4879264184246937\n",
      "Current iteration=1500, loss=0.4879246642082853\n",
      "Current iteration=1600, loss=0.4879232830130429\n",
      "Current iteration=0, loss=0.49077937733770904\n",
      "Current iteration=100, loss=0.4902410999765683\n",
      "Current iteration=200, loss=0.49015030687222444\n",
      "Current iteration=300, loss=0.490105529163946\n",
      "Current iteration=400, loss=0.4900806508803381\n",
      "Current iteration=500, loss=0.49006575344156805\n",
      "Current iteration=600, loss=0.4900562667759303\n",
      "Current iteration=700, loss=0.4900499295043404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=800, loss=0.49004554802924183\n",
      "Current iteration=900, loss=0.4900424469460838\n",
      "Current iteration=1000, loss=0.49004021738539844\n",
      "Current iteration=1100, loss=0.4900385972279392\n",
      "Current iteration=1200, loss=0.49003741094252146\n",
      "Current iteration=0, loss=0.4895228602547395\n",
      "Current iteration=100, loss=0.48892099190970023\n",
      "Current iteration=200, loss=0.4888687552318333\n",
      "Current iteration=300, loss=0.48883943667340934\n",
      "Current iteration=400, loss=0.4888203535441973\n",
      "Current iteration=500, loss=0.4888070426102546\n",
      "Current iteration=600, loss=0.4887973800704748\n",
      "Current iteration=700, loss=0.4887901970196095\n",
      "Current iteration=800, loss=0.4887847854245309\n",
      "Current iteration=900, loss=0.4887806836276359\n",
      "Current iteration=1000, loss=0.4887775717303409\n",
      "Current iteration=1100, loss=0.48877521640947563\n",
      "Current iteration=1200, loss=0.4887734406758414\n",
      "Current iteration=1300, loss=0.48877210721607806\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.4915821053363505\n",
      "Current iteration=100, loss=0.4911539625461324\n",
      "Current iteration=200, loss=0.4910026065710882\n",
      "Current iteration=300, loss=0.4909056794669324\n",
      "Current iteration=400, loss=0.49083882552591973\n",
      "Current iteration=500, loss=0.4907911668346852\n",
      "Current iteration=600, loss=0.4907565339668396\n",
      "Current iteration=700, loss=0.49073105100681474\n",
      "Current iteration=800, loss=0.4907121393898477\n",
      "Current iteration=900, loss=0.4906980189955826\n",
      "Current iteration=1000, loss=0.4906874291227666\n",
      "Current iteration=1100, loss=0.4906794606159955\n",
      "Current iteration=1200, loss=0.49067344926165835\n",
      "Current iteration=1300, loss=0.49066890520361134\n",
      "Current iteration=1400, loss=0.4906654646687482\n",
      "Current iteration=1500, loss=0.49066285612068444\n",
      "Current iteration=1600, loss=0.490660876079501\n",
      "Current iteration=1700, loss=0.4906593716022263\n",
      "Current iteration=0, loss=0.49227042327112563\n",
      "Current iteration=100, loss=0.4916937086888403\n",
      "Current iteration=200, loss=0.4915927570038329\n",
      "Current iteration=300, loss=0.4915421191174816\n",
      "Current iteration=400, loss=0.49151135214789404\n",
      "Current iteration=500, loss=0.49149139718014484\n",
      "Current iteration=600, loss=0.4914780178742495\n",
      "Current iteration=700, loss=0.49146884566198207\n",
      "Current iteration=800, loss=0.4914624523678627\n",
      "Current iteration=900, loss=0.49145793788796177\n",
      "Current iteration=1000, loss=0.4914547166348546\n",
      "Current iteration=1100, loss=0.49145239824452913\n",
      "Current iteration=1200, loss=0.49145071746833946\n",
      "Current iteration=1300, loss=0.49144949129739424\n",
      "Current iteration=0, loss=0.4941319334196756\n",
      "Current iteration=100, loss=0.4936015658888982\n",
      "Current iteration=200, loss=0.49352335011164666\n",
      "Current iteration=300, loss=0.4934885029513794\n",
      "Current iteration=400, loss=0.49347085462233664\n",
      "Current iteration=500, loss=0.49346108547146184\n",
      "Current iteration=600, loss=0.49345528965825247\n",
      "Current iteration=700, loss=0.49345167495530284\n",
      "Current iteration=800, loss=0.4934493431977827\n",
      "Current iteration=900, loss=0.49344780549688244\n",
      "Current iteration=0, loss=0.49296898755507024\n",
      "Current iteration=100, loss=0.4924197808662738\n",
      "Current iteration=200, loss=0.4923745377583046\n",
      "Current iteration=300, loss=0.4923506112555873\n",
      "Current iteration=400, loss=0.4923359725671167\n",
      "Current iteration=500, loss=0.4923264024249722\n",
      "Current iteration=600, loss=0.49231990604192105\n",
      "Current iteration=700, loss=0.49231539642904987\n",
      "Current iteration=800, loss=0.49231222463468793\n",
      "Current iteration=900, loss=0.4923099774142054\n",
      "Current iteration=1000, loss=0.4923083794067072\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.49547561136701934\n",
      "Current iteration=100, loss=0.4950069235418128\n",
      "Current iteration=200, loss=0.4948562311467105\n",
      "Current iteration=300, loss=0.49477164141736774\n",
      "Current iteration=400, loss=0.49472019301459536\n",
      "Current iteration=500, loss=0.4946875705916191\n",
      "Current iteration=600, loss=0.4946663421096568\n",
      "Current iteration=700, loss=0.49465229071321476\n",
      "Current iteration=800, loss=0.49464288249848665\n",
      "Current iteration=900, loss=0.4946365331785881\n",
      "Current iteration=1000, loss=0.49463222430897574\n",
      "Current iteration=1100, loss=0.49462928837932374\n",
      "Current iteration=1200, loss=0.49462728193158617\n",
      "Current iteration=1300, loss=0.49462590754467084\n",
      "Current iteration=0, loss=0.49599406399325535\n",
      "Current iteration=100, loss=0.49546441035886524\n",
      "Current iteration=200, loss=0.4953846193392818\n",
      "Current iteration=300, loss=0.49534894028715265\n",
      "Current iteration=400, loss=0.49532951344953285\n",
      "Current iteration=500, loss=0.4953181811520252\n",
      "Current iteration=600, loss=0.4953113238442644\n",
      "Current iteration=700, loss=0.49530706893118853\n",
      "Current iteration=800, loss=0.495304378782824\n",
      "Current iteration=900, loss=0.49530265306473253\n",
      "Current iteration=0, loss=0.49781467193618906\n",
      "Current iteration=100, loss=0.49730678896190306\n",
      "Current iteration=200, loss=0.49724598284938826\n",
      "Current iteration=300, loss=0.49722204429627664\n",
      "Current iteration=400, loss=0.4972111203207675\n",
      "Current iteration=500, loss=0.49720563564237935\n",
      "Current iteration=600, loss=0.4972026814791859\n",
      "Current iteration=700, loss=0.49720101002191447\n",
      "Current iteration=0, loss=0.4967629505209334\n",
      "Current iteration=100, loss=0.4962607100760496\n",
      "Current iteration=200, loss=0.49622307982507713\n",
      "Current iteration=300, loss=0.4962048546669619\n",
      "Current iteration=400, loss=0.49619465736755025\n",
      "Current iteration=500, loss=0.49618857948988104\n",
      "Current iteration=600, loss=0.4961848272234022\n",
      "Current iteration=700, loss=0.49618246195156085\n",
      "Current iteration=800, loss=0.4961809521417008\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.49978318850577236\n",
      "Current iteration=100, loss=0.49926309012014064\n",
      "Current iteration=200, loss=0.4991189091576171\n",
      "Current iteration=300, loss=0.4990514894442009\n",
      "Current iteration=400, loss=0.4990168984156382\n",
      "Current iteration=500, loss=0.49899814338520626\n",
      "Current iteration=600, loss=0.4989876082319592\n",
      "Current iteration=700, loss=0.49898155417953877\n",
      "Current iteration=800, loss=0.4989780236882249\n",
      "Current iteration=900, loss=0.4989759449002143\n",
      "Current iteration=0, loss=0.500069044408172\n",
      "Current iteration=100, loss=0.4995915193569081\n",
      "Current iteration=200, loss=0.4995322517150708\n",
      "Current iteration=300, loss=0.4995093632579796\n",
      "Current iteration=400, loss=0.49949857207485104\n",
      "Current iteration=500, loss=0.4994931095484104\n",
      "Current iteration=600, loss=0.4994902329522478\n",
      "Current iteration=700, loss=0.4994886756501545\n",
      "Current iteration=0, loss=0.5018440338901234\n",
      "Current iteration=100, loss=0.5013814884213397\n",
      "Current iteration=0, loss=0.5007881304013259\n",
      "Current iteration=100, loss=0.5004309142760779\n",
      "Current iteration=200, loss=0.500412061673573\n",
      "Current iteration=300, loss=0.500404699528399\n",
      "Current iteration=400, loss=0.500401232433619\n",
      "Current iteration=500, loss=0.5003994889269218\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.5044856364250228\n",
      "Current iteration=100, loss=0.5039022441335446\n",
      "Current iteration=200, loss=0.5037724938469592\n",
      "Current iteration=300, loss=0.5037249656211754\n",
      "Current iteration=400, loss=0.5037054838770261\n",
      "Current iteration=500, loss=0.5036968891713682\n",
      "Current iteration=600, loss=0.503692914994461\n",
      "Current iteration=700, loss=0.5036910236309184\n",
      "Current iteration=0, loss=0.5045001388228422\n",
      "Current iteration=100, loss=0.5040731526918172\n",
      "Current iteration=200, loss=0.5040320400510451\n",
      "Current iteration=300, loss=0.5040189515277526\n",
      "Current iteration=400, loss=0.5040138648442251\n",
      "Current iteration=500, loss=0.5040117411850008\n",
      "Current iteration=0, loss=0.5062354055950494\n",
      "Current iteration=100, loss=0.5058149130021783\n",
      "Current iteration=200, loss=0.5057823437806594\n",
      "Current iteration=300, loss=0.5057739174869668\n",
      "Current iteration=400, loss=0.5057711429169762\n",
      "Current iteration=0, loss=0.5054265171008112\n",
      "Current iteration=100, loss=0.5050003192761103\n",
      "Current iteration=200, loss=0.5049784015971229\n",
      "Current iteration=300, loss=0.5049706159783448\n",
      "Current iteration=400, loss=0.5049674199241451\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.5095615202525481\n",
      "Current iteration=100, loss=0.5089046252326661\n",
      "Current iteration=200, loss=0.5087984130963604\n",
      "Current iteration=300, loss=0.5087704454349041\n",
      "Current iteration=400, loss=0.5087619870153395\n",
      "Current iteration=500, loss=0.5087591672559545\n",
      "Current iteration=0, loss=0.5092920281868618\n",
      "Current iteration=100, loss=0.50891020483774\n",
      "Current iteration=200, loss=0.5088840837464211\n",
      "Current iteration=300, loss=0.508877696015139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=400, loss=0.5088757899596386\n",
      "Current iteration=0, loss=0.5110049167515422\n",
      "Current iteration=100, loss=0.5106205273245481\n",
      "Current iteration=200, loss=0.5106016258520699\n",
      "Current iteration=300, loss=0.5105975191514703\n",
      "Current iteration=0, loss=0.5103012237799047\n",
      "Current iteration=100, loss=0.50990532847375\n",
      "Current iteration=200, loss=0.5098904485743809\n",
      "Current iteration=300, loss=0.509886388153293\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.5150039550400695\n",
      "Current iteration=100, loss=0.5142710991874618\n",
      "Current iteration=200, loss=0.5141945741733845\n",
      "Current iteration=300, loss=0.5141813737553296\n",
      "Current iteration=400, loss=0.5141786777482749\n",
      "Current iteration=0, loss=0.5144558852923538\n",
      "Current iteration=100, loss=0.5141176885654262\n",
      "Current iteration=200, loss=0.5141031311150258\n",
      "Current iteration=300, loss=0.5141006540243864\n",
      "Current iteration=0, loss=0.5161710131747788\n",
      "Current iteration=100, loss=0.5158152113237916\n",
      "Current iteration=200, loss=0.5158043175652818\n",
      "Current iteration=0, loss=0.5155474227579718\n",
      "Current iteration=100, loss=0.5151799943064004\n",
      "Current iteration=200, loss=0.5151710128089648\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.5208237912335012\n",
      "Current iteration=100, loss=0.520027197483441\n",
      "Current iteration=200, loss=0.5199819548855206\n",
      "Current iteration=300, loss=0.5199774303340636\n",
      "Current iteration=0, loss=0.5200257176539205\n",
      "Current iteration=100, loss=0.519731880105333\n",
      "Current iteration=200, loss=0.5197251204358865\n",
      "Current iteration=0, loss=0.5217620231007862\n",
      "Current iteration=100, loss=0.5214329253522682\n",
      "Current iteration=200, loss=0.5214275595538654\n",
      "Current iteration=0, loss=0.5211910525961752\n",
      "Current iteration=100, loss=0.520852968083039\n",
      "Current iteration=200, loss=0.5208484789275892\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.5270699628112302\n",
      "Current iteration=100, loss=0.5262300679497779\n",
      "Current iteration=200, loss=0.5262094563983529\n",
      "Current iteration=0, loss=0.5260617857863414\n",
      "Current iteration=100, loss=0.5258118418090808\n",
      "Current iteration=0, loss=0.5278280275903666\n",
      "Current iteration=100, loss=0.5275330321178188\n",
      "Current iteration=0, loss=0.527284879336446\n",
      "Current iteration=100, loss=0.5269781750116405\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.5338238835567003\n",
      "Current iteration=100, loss=0.5329560053515278\n",
      "Current iteration=0, loss=0.5326460983924236\n",
      "Current iteration=100, loss=0.5324363648070705\n",
      "Current iteration=0, loss=0.5344360158211028\n",
      "Current iteration=100, loss=0.5341895881714391\n",
      "Current iteration=0, loss=0.5339007351910842\n",
      "Current iteration=100, loss=0.5336320083187234\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.5411805082880997\n",
      "Current iteration=100, loss=0.5402912510155139\n",
      "Current iteration=0, loss=0.5398696780951706\n",
      "Current iteration=100, loss=0.5396938108817144\n",
      "Current iteration=0, loss=0.5416713613473498\n",
      "Current iteration=0, loss=0.5411187478699356\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.5492290993292847\n",
      "Current iteration=100, loss=0.5483158691101563\n",
      "Current iteration=0, loss=0.5478106329696705\n",
      "Current iteration=100, loss=0.5476752881554166\n",
      "Current iteration=200, loss=0.5476817402227153\n",
      "Current iteration=300, loss=0.5476857306985201\n",
      "Current iteration=400, loss=0.5476875132597915\n",
      "Current iteration=500, loss=0.5476881958410321\n",
      "Current iteration=600, loss=0.5476884415063379\n",
      "Current iteration=700, loss=0.5476885279296974\n",
      "Current iteration=800, loss=0.5476885580879238\n",
      "Current iteration=900, loss=0.5476885685821629\n",
      "Current iteration=1000, loss=0.5476885722302721\n",
      "Current iteration=1100, loss=0.5476885734980284\n",
      "Current iteration=1200, loss=0.5476885739385345\n",
      "Current iteration=1300, loss=0.5476885740915904\n",
      "Current iteration=1400, loss=0.5476885741447696\n",
      "Current iteration=1500, loss=0.5476885741632467\n",
      "Current iteration=1600, loss=0.5476885741696663\n",
      "Current iteration=1700, loss=0.547688574171897\n",
      "Current iteration=1800, loss=0.5476885741726719\n",
      "Current iteration=1900, loss=0.5476885741729413\n",
      "Current iteration=0, loss=0.5495956633636425\n",
      "Current iteration=0, loss=0.549019053273419\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.5580229561553913\n",
      "Current iteration=0, loss=0.5565133411468723\n",
      "Current iteration=100, loss=0.5563962369429075\n",
      "Current iteration=200, loss=0.5563960772460143\n",
      "Current iteration=300, loss=0.5563959774867452\n",
      "Current iteration=400, loss=0.5563959117814868\n",
      "Current iteration=500, loss=0.5563958682451374\n",
      "Current iteration=600, loss=0.5563958392876521\n",
      "Current iteration=700, loss=0.5563958199781712\n",
      "Current iteration=800, loss=0.5563958070804161\n",
      "Current iteration=900, loss=0.5563957984556436\n",
      "Current iteration=1000, loss=0.5563957926838772\n",
      "Current iteration=1100, loss=0.5563957888194152\n",
      "Current iteration=1200, loss=0.5563957862311063\n",
      "Current iteration=1300, loss=0.556395784497137\n",
      "Current iteration=1400, loss=0.5563957833353337\n",
      "Current iteration=1500, loss=0.556395782556817\n",
      "Current iteration=1600, loss=0.5563957820351028\n",
      "Current iteration=1700, loss=0.5563957816854659\n",
      "Current iteration=1800, loss=0.5563957814511427\n",
      "Current iteration=1900, loss=0.5563957812940983\n",
      "Current iteration=0, loss=0.558263700194786\n",
      "Current iteration=0, loss=0.5576682995161107\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.5675478720342596\n",
      "Current iteration=0, loss=0.5659665144211464\n",
      "Current iteration=0, loss=0.5676753821639199\n",
      "Current iteration=0, loss=0.5670707619239272\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.5777101220258074\n",
      "Current iteration=0, loss=0.5760950421384046\n",
      "Current iteration=0, loss=0.5777373999917431\n",
      "Current iteration=0, loss=0.5771241703843629\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.5883662959777302\n",
      "Current iteration=0, loss=0.5867719793896042\n",
      "Current iteration=0, loss=0.5883380587604667\n",
      "Current iteration=100, loss=0.5883956241070282\n",
      "Current iteration=200, loss=0.5884126133235479\n",
      "Current iteration=300, loss=0.5884127624629798\n",
      "Current iteration=400, loss=0.5884127635899511\n",
      "Current iteration=500, loss=0.5884127635984566\n",
      "Current iteration=600, loss=0.5884127635985207\n",
      "Current iteration=700, loss=0.5884127635985212\n",
      "Current iteration=800, loss=0.5884127635985212\n",
      "Current iteration=900, loss=0.5884127635985212\n",
      "Current iteration=1000, loss=0.5884127635985212\n",
      "Current iteration=1100, loss=0.5884127635985212\n",
      "Current iteration=1200, loss=0.5884127635985212\n",
      "Current iteration=1300, loss=0.5884127635985212\n",
      "Current iteration=1400, loss=0.5884127635985212\n",
      "Current iteration=1500, loss=0.5884127635985212\n",
      "Current iteration=1600, loss=0.5884127635985212\n",
      "Current iteration=1700, loss=0.5884127635985212\n",
      "Current iteration=1800, loss=0.5884127635985212\n",
      "Current iteration=1900, loss=0.5884127635985212\n",
      "Current iteration=0, loss=0.5877480699966245\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.5993194095065306\n",
      "Current iteration=0, loss=0.5977903675164263\n",
      "Current iteration=0, loss=0.5992802264921622\n",
      "Current iteration=100, loss=0.5993124626152528\n",
      "Current iteration=200, loss=0.5993191090642529\n",
      "Current iteration=300, loss=0.5993191728030425\n",
      "Current iteration=400, loss=0.5993191733680804\n",
      "Current iteration=500, loss=0.5993191733730856\n",
      "Current iteration=600, loss=0.5993191733731299\n",
      "Current iteration=700, loss=0.5993191733731302\n",
      "Current iteration=800, loss=0.5993191733731302\n",
      "Current iteration=900, loss=0.5993191733731302\n",
      "Current iteration=1000, loss=0.5993191733731302\n",
      "Current iteration=1100, loss=0.5993191733731302\n",
      "Current iteration=1200, loss=0.5993191733731303\n",
      "Current iteration=1300, loss=0.5993191733731302\n",
      "Current iteration=1400, loss=0.5993191733731303\n",
      "Current iteration=1500, loss=0.5993191733731303\n",
      "Current iteration=1600, loss=0.5993191733731303\n",
      "Current iteration=1700, loss=0.5993191733731302\n",
      "Current iteration=1800, loss=0.5993191733731302\n",
      "Current iteration=1900, loss=0.5993191733731302\n",
      "Current iteration=0, loss=0.5986206591876558\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.6103098250415186\n",
      "Current iteration=0, loss=0.6089032377005394\n",
      "Current iteration=0, loss=0.6103121077789886\n",
      "Current iteration=0, loss=0.6095863752129504\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.6210499261350222\n",
      "Current iteration=0, loss=0.6198382712533703\n",
      "Current iteration=0, loss=0.6211572860828269\n",
      "Current iteration=100, loss=0.6211378559451243\n",
      "Current iteration=200, loss=0.6211381897541325\n",
      "Current iteration=300, loss=0.6211384948685382\n",
      "Current iteration=400, loss=0.6211387719406131\n",
      "Current iteration=500, loss=0.6211390220598982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.6211392466420508\n",
      "Current iteration=700, loss=0.621139447326348\n",
      "Current iteration=800, loss=0.6211396258859231\n",
      "Current iteration=900, loss=0.6211397841527043\n",
      "Current iteration=1000, loss=0.621139923957384\n",
      "Current iteration=1100, loss=0.6211400470836006\n",
      "Current iteration=1200, loss=0.6211401552348017\n",
      "Current iteration=1300, loss=0.6211402500119186\n",
      "Current iteration=1400, loss=0.6211403328998861\n",
      "Current iteration=1500, loss=0.6211404052611392\n",
      "Current iteration=1600, loss=0.6211404683344103\n",
      "Current iteration=1700, loss=0.6211405232373877\n",
      "Current iteration=1800, loss=0.6211405709720546\n",
      "Current iteration=1900, loss=0.6211406124317598\n",
      "Current iteration=0, loss=0.6204065232870212\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6313129862858955\n",
      "Current iteration=100, loss=0.6328153180958073\n",
      "Current iteration=200, loss=0.6328158999663068\n",
      "Current iteration=300, loss=0.6328158999688378\n",
      "Current iteration=400, loss=0.6328158999688379\n",
      "Current iteration=500, loss=0.6328158999688379\n",
      "Current iteration=600, loss=0.6328158999688379\n",
      "Current iteration=700, loss=0.6328158999688379\n",
      "Current iteration=800, loss=0.6328158999688379\n",
      "Current iteration=900, loss=0.6328158999688379\n",
      "Current iteration=1000, loss=0.6328158999688379\n",
      "Current iteration=1100, loss=0.6328158999688379\n",
      "Current iteration=1200, loss=0.6328158999688379\n",
      "Current iteration=1300, loss=0.6328158999688379\n",
      "Current iteration=1400, loss=0.6328158999688379\n",
      "Current iteration=1500, loss=0.6328158999688379\n",
      "Current iteration=1600, loss=0.6328158999688379\n",
      "Current iteration=1700, loss=0.6328158999688379\n",
      "Current iteration=1800, loss=0.6328158999688379\n",
      "Current iteration=1900, loss=0.6328158999688379\n",
      "Current iteration=0, loss=0.6318633748462783\n",
      "Current iteration=100, loss=0.6308664909982052\n",
      "Current iteration=200, loss=0.630849403120389\n",
      "Current iteration=300, loss=0.6308485009966623\n",
      "Current iteration=400, loss=0.6308484516844814\n",
      "Current iteration=500, loss=0.6308484489839228\n",
      "Current iteration=600, loss=0.6308484488360129\n",
      "Current iteration=700, loss=0.6308484488279116\n",
      "Current iteration=800, loss=0.6308484488274678\n",
      "Current iteration=900, loss=0.6308484488274437\n",
      "Current iteration=1000, loss=0.6308484488274423\n",
      "Current iteration=1100, loss=0.6308484488274422\n",
      "Current iteration=1200, loss=0.6308484488274422\n",
      "Current iteration=1300, loss=0.6308484488274422\n",
      "Current iteration=1400, loss=0.6308484488274422\n",
      "Current iteration=1500, loss=0.6308484488274422\n",
      "Current iteration=1600, loss=0.6308484488274422\n",
      "Current iteration=1700, loss=0.6308484488274422\n",
      "Current iteration=1800, loss=0.6308484488274422\n",
      "Current iteration=1900, loss=0.6308484488274422\n",
      "Current iteration=0, loss=0.6322799762576555\n",
      "Current iteration=100, loss=0.6341850526045693\n",
      "Current iteration=200, loss=0.6341850526117945\n",
      "Current iteration=300, loss=0.6341850526117945\n",
      "Current iteration=400, loss=0.6341850526117945\n",
      "Current iteration=500, loss=0.6341850526117945\n",
      "Current iteration=600, loss=0.6341850526117945\n",
      "Current iteration=700, loss=0.6341850526117945\n",
      "Current iteration=800, loss=0.6341850526117945\n",
      "Current iteration=900, loss=0.6341850526117945\n",
      "Current iteration=1000, loss=0.6341850526117945\n",
      "Current iteration=1100, loss=0.6341850526117945\n",
      "Current iteration=1200, loss=0.6341850526117945\n",
      "Current iteration=1300, loss=0.6341850526117945\n",
      "Current iteration=1400, loss=0.6341850526117945\n",
      "Current iteration=1500, loss=0.6341850526117945\n",
      "Current iteration=1600, loss=0.6341850526117945\n",
      "Current iteration=1700, loss=0.6341850526117945\n",
      "Current iteration=1800, loss=0.6341850526117945\n",
      "Current iteration=1900, loss=0.6341850526117945\n",
      "Current iteration=0, loss=0.6329371731930071\n",
      "Current iteration=100, loss=0.630831427198646\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6410737252534311\n",
      "Current iteration=100, loss=0.6539832419683254\n",
      "Current iteration=200, loss=0.6539832419683254\n",
      "Current iteration=300, loss=0.6539832419683254\n",
      "Current iteration=400, loss=0.6539832419683254\n",
      "Current iteration=500, loss=0.6539832419683254\n",
      "Current iteration=600, loss=0.6539832419683254\n",
      "Current iteration=700, loss=0.6539832419683254\n",
      "Current iteration=800, loss=0.6539832419683254\n",
      "Current iteration=900, loss=0.6539832419683254\n",
      "Current iteration=1000, loss=0.6539832419683254\n",
      "Current iteration=1100, loss=0.6539832419683254\n",
      "Current iteration=1200, loss=0.6539832419683254\n",
      "Current iteration=1300, loss=0.6539832419683254\n",
      "Current iteration=1400, loss=0.6539832419683254\n",
      "Current iteration=1500, loss=0.6539832419683254\n",
      "Current iteration=1600, loss=0.6539832419683254\n",
      "Current iteration=1700, loss=0.6539832419683254\n",
      "Current iteration=1800, loss=0.6539832419683254\n",
      "Current iteration=1900, loss=0.6539832419683254\n",
      "Current iteration=0, loss=0.6520496591900428\n",
      "Current iteration=100, loss=0.6512713048516117\n",
      "Current iteration=200, loss=0.6512713048516117\n",
      "Current iteration=300, loss=0.6512713048516117\n",
      "Current iteration=400, loss=0.6512713048516117\n",
      "Current iteration=500, loss=0.6512713048516117\n",
      "Current iteration=600, loss=0.6512713048516117\n",
      "Current iteration=700, loss=0.6512713048516117\n",
      "Current iteration=800, loss=0.6512713048516117\n",
      "Current iteration=900, loss=0.6512713048516117\n",
      "Current iteration=1000, loss=0.6512713048516117\n",
      "Current iteration=1100, loss=0.6512713048516117\n",
      "Current iteration=1200, loss=0.6512713048516117\n",
      "Current iteration=1300, loss=0.6512713048516117\n",
      "Current iteration=1400, loss=0.6512713048516117\n",
      "Current iteration=1500, loss=0.6512713048516117\n",
      "Current iteration=1600, loss=0.6512713048516117\n",
      "Current iteration=1700, loss=0.6512713048516117\n",
      "Current iteration=1800, loss=0.6512713048516117\n",
      "Current iteration=1900, loss=0.6512713048516117\n",
      "Current iteration=0, loss=0.653407185799661\n",
      "Current iteration=100, loss=0.6547291979780694\n",
      "Current iteration=200, loss=0.6547291979780694\n",
      "Current iteration=300, loss=0.6547291979780694\n",
      "Current iteration=400, loss=0.6547291979780694\n",
      "Current iteration=500, loss=0.6547291979780694\n",
      "Current iteration=600, loss=0.6547291979780694\n",
      "Current iteration=700, loss=0.6547291979780694\n",
      "Current iteration=800, loss=0.6547291979780694\n",
      "Current iteration=900, loss=0.6547291979780694\n",
      "Current iteration=1000, loss=0.6547291979780694\n",
      "Current iteration=1100, loss=0.6547291979780694\n",
      "Current iteration=1200, loss=0.6547291979780694\n",
      "Current iteration=1300, loss=0.6547291979780694\n",
      "Current iteration=1400, loss=0.6547291979780694\n",
      "Current iteration=1500, loss=0.6547291979780694\n",
      "Current iteration=1600, loss=0.6547291979780694\n",
      "Current iteration=1700, loss=0.6547291979780694\n",
      "Current iteration=1800, loss=0.6547291979780694\n",
      "Current iteration=1900, loss=0.6547291979780694\n",
      "Current iteration=0, loss=0.6528930864638112\n",
      "Current iteration=100, loss=0.6509578769624256\n",
      "Current iteration=200, loss=0.6509578769624255\n",
      "Current iteration=300, loss=0.6509578769624255\n",
      "Current iteration=400, loss=0.6509578769624255\n",
      "Current iteration=500, loss=0.6509578769624255\n",
      "Current iteration=600, loss=0.6509578769624255\n",
      "Current iteration=700, loss=0.6509578769624255\n",
      "Current iteration=800, loss=0.6509578769624256\n",
      "Current iteration=900, loss=0.6509578769624255\n",
      "Current iteration=1000, loss=0.6509578769624255\n",
      "Current iteration=1100, loss=0.6509578769624255\n",
      "Current iteration=1200, loss=0.6509578769624255\n",
      "Current iteration=1300, loss=0.6509578769624255\n",
      "Current iteration=1400, loss=0.6509578769624256\n",
      "Current iteration=1500, loss=0.6509578769624255\n",
      "Current iteration=1600, loss=0.6509578769624256\n",
      "Current iteration=1700, loss=0.6509578769624255\n",
      "Current iteration=1800, loss=0.6509578769624255\n",
      "Current iteration=1900, loss=0.6509578769624255\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.6743441131901303\n",
      "Current iteration=100, loss=0.7048288521119578\n",
      "Current iteration=200, loss=0.7048288521119578\n",
      "Current iteration=300, loss=0.7048288521119578\n",
      "Current iteration=400, loss=0.7048288521119578\n",
      "Current iteration=500, loss=0.7048288521119578\n",
      "Current iteration=600, loss=0.7048288521119578\n",
      "Current iteration=700, loss=0.7048288521119578\n",
      "Current iteration=800, loss=0.7048288521119578\n",
      "Current iteration=900, loss=0.7048288521119578\n",
      "Current iteration=1000, loss=0.7048288521119578\n",
      "Current iteration=1100, loss=0.7048288521119578\n",
      "Current iteration=1200, loss=0.7048288521119578\n",
      "Current iteration=1300, loss=0.7048288521119578\n",
      "Current iteration=1400, loss=0.7048288521119578\n",
      "Current iteration=1500, loss=0.7048288521119578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1600, loss=0.7048288521119578\n",
      "Current iteration=1700, loss=0.7048288521119578\n",
      "Current iteration=1800, loss=0.7048288521119578\n",
      "Current iteration=1900, loss=0.7048288521119578\n",
      "Current iteration=0, loss=0.7018451248348244\n",
      "Current iteration=100, loss=0.7021102259896016\n",
      "Current iteration=200, loss=0.7021102259896016\n",
      "Current iteration=300, loss=0.7021102259896016\n",
      "Current iteration=400, loss=0.7021102259896016\n",
      "Current iteration=500, loss=0.7021102259896016\n",
      "Current iteration=600, loss=0.7021102259896016\n",
      "Current iteration=700, loss=0.7021102259896016\n",
      "Current iteration=800, loss=0.7021102259896016\n",
      "Current iteration=900, loss=0.7021102259896016\n",
      "Current iteration=1000, loss=0.7021102259896016\n",
      "Current iteration=1100, loss=0.7021102259896016\n",
      "Current iteration=1200, loss=0.7021102259896016\n",
      "Current iteration=1300, loss=0.7021102259896016\n",
      "Current iteration=1400, loss=0.7021102259896016\n",
      "Current iteration=1500, loss=0.7021102259896016\n",
      "Current iteration=1600, loss=0.7021102259896016\n",
      "Current iteration=1700, loss=0.7021102259896016\n",
      "Current iteration=1800, loss=0.7021102259896016\n",
      "Current iteration=1900, loss=0.7021102259896016\n",
      "Current iteration=0, loss=0.7047544511492233\n",
      "Current iteration=100, loss=0.7056959065341076\n",
      "Current iteration=200, loss=0.7056959065341076\n",
      "Current iteration=300, loss=0.7056959065341076\n",
      "Current iteration=400, loss=0.7056959065341076\n",
      "Current iteration=500, loss=0.7056959065341076\n",
      "Current iteration=600, loss=0.7056959065341076\n",
      "Current iteration=700, loss=0.7056959065341076\n",
      "Current iteration=800, loss=0.7056959065341076\n",
      "Current iteration=900, loss=0.7056959065341076\n",
      "Current iteration=1000, loss=0.7056959065341076\n",
      "Current iteration=1100, loss=0.7056959065341076\n",
      "Current iteration=1200, loss=0.7056959065341076\n",
      "Current iteration=1300, loss=0.7056959065341076\n",
      "Current iteration=1400, loss=0.7056959065341076\n",
      "Current iteration=1500, loss=0.7056959065341076\n",
      "Current iteration=1600, loss=0.7056959065341076\n",
      "Current iteration=1700, loss=0.7056959065341076\n",
      "Current iteration=1800, loss=0.7056959065341076\n",
      "Current iteration=1900, loss=0.7056959065341076\n",
      "Current iteration=0, loss=0.7028140577169639\n",
      "Current iteration=100, loss=0.7011826033579213\n",
      "Current iteration=200, loss=0.7011826033579213\n",
      "Current iteration=300, loss=0.7011826033579213\n",
      "Current iteration=400, loss=0.7011826033579213\n",
      "Current iteration=500, loss=0.7011826033579213\n",
      "Current iteration=600, loss=0.7011826033579213\n",
      "Current iteration=700, loss=0.7011826033579213\n",
      "Current iteration=800, loss=0.7011826033579213\n",
      "Current iteration=900, loss=0.7011826033579213\n",
      "Current iteration=1000, loss=0.7011826033579213\n",
      "Current iteration=1100, loss=0.7011826033579213\n",
      "Current iteration=1200, loss=0.7011826033579213\n",
      "Current iteration=1300, loss=0.7011826033579213\n",
      "Current iteration=1400, loss=0.7011826033579213\n",
      "Current iteration=1500, loss=0.7011826033579213\n",
      "Current iteration=1600, loss=0.7011826033579213\n",
      "Current iteration=1700, loss=0.7011826033579213\n",
      "Current iteration=1800, loss=0.7011826033579213\n",
      "Current iteration=1900, loss=0.7011826033579213\n",
      "Iteration 28\n",
      "Current iteration=0, loss=0.7806976323818947\n",
      "Current iteration=100, loss=0.8889064232481311\n",
      "Current iteration=200, loss=0.8889064232481311\n",
      "Current iteration=300, loss=0.8889064232481311\n",
      "Current iteration=400, loss=0.8889064232481311\n",
      "Current iteration=500, loss=0.8889064232481311\n",
      "Current iteration=600, loss=0.8889064232481311\n",
      "Current iteration=700, loss=0.8889064232481311\n",
      "Current iteration=800, loss=0.8889064232481311\n",
      "Current iteration=900, loss=0.8889064232481311\n",
      "Current iteration=1000, loss=0.8889064232481311\n",
      "Current iteration=1100, loss=0.8889064232481311\n",
      "Current iteration=1200, loss=0.8889064232481311\n",
      "Current iteration=1300, loss=0.8889064232481311\n",
      "Current iteration=1400, loss=0.8889064232481311\n",
      "Current iteration=1500, loss=0.8889064232481311\n",
      "Current iteration=1600, loss=0.8889064232481311\n",
      "Current iteration=1700, loss=0.8889064232481311\n",
      "Current iteration=1800, loss=0.8889064232481311\n",
      "Current iteration=1900, loss=0.8889064232481311\n",
      "Current iteration=0, loss=0.8851041248680741\n",
      "Current iteration=100, loss=0.887303350302934\n",
      "Current iteration=200, loss=0.8873033503029338\n",
      "Current iteration=300, loss=0.8873033503029338\n",
      "Current iteration=400, loss=0.8873033503029338\n",
      "Current iteration=500, loss=0.8873033503029338\n",
      "Current iteration=600, loss=0.8873033503029338\n",
      "Current iteration=700, loss=0.8873033503029338\n",
      "Current iteration=800, loss=0.8873033503029338\n",
      "Current iteration=900, loss=0.8873033503029338\n",
      "Current iteration=1000, loss=0.8873033503029338\n",
      "Current iteration=1100, loss=0.8873033503029338\n",
      "Current iteration=1200, loss=0.8873033503029338\n",
      "Current iteration=1300, loss=0.8873033503029338\n",
      "Current iteration=1400, loss=0.8873033503029338\n",
      "Current iteration=1500, loss=0.8873033503029338\n",
      "Current iteration=1600, loss=0.8873033503029338\n",
      "Current iteration=1700, loss=0.8873033503029338\n",
      "Current iteration=1800, loss=0.8873033503029338\n",
      "Current iteration=1900, loss=0.8873033503029338\n",
      "Current iteration=0, loss=0.890206509554169\n",
      "Current iteration=100, loss=0.8911951974482478\n",
      "Current iteration=200, loss=0.8911951974482478\n",
      "Current iteration=300, loss=0.8911951974482478\n",
      "Current iteration=400, loss=0.8911951974482478\n",
      "Current iteration=500, loss=0.8911951974482478\n",
      "Current iteration=600, loss=0.8911951974482478\n",
      "Current iteration=700, loss=0.8911951974482478\n",
      "Current iteration=800, loss=0.8911951974482478\n",
      "Current iteration=900, loss=0.8911951974482478\n",
      "Current iteration=1000, loss=0.8911951974482478\n",
      "Current iteration=1100, loss=0.8911951974482478\n",
      "Current iteration=1200, loss=0.8911951974482478\n",
      "Current iteration=1300, loss=0.8911951974482478\n",
      "Current iteration=1400, loss=0.8911951974482478\n",
      "Current iteration=1500, loss=0.8911951974482478\n",
      "Current iteration=1600, loss=0.8911951974482478\n",
      "Current iteration=1700, loss=0.8911951974482478\n",
      "Current iteration=1800, loss=0.8911951974482478\n",
      "Current iteration=1900, loss=0.8911951974482478\n",
      "Current iteration=0, loss=0.8870371747173575\n",
      "Current iteration=100, loss=0.8855728240846271\n",
      "Current iteration=200, loss=0.8855728240846271\n",
      "Current iteration=300, loss=0.8855728240846272\n",
      "Current iteration=400, loss=0.8855728240846271\n",
      "Current iteration=500, loss=0.8855728240846271\n",
      "Current iteration=600, loss=0.8855728240846271\n",
      "Current iteration=700, loss=0.8855728240846271\n",
      "Current iteration=800, loss=0.8855728240846271\n",
      "Current iteration=900, loss=0.8855728240846271\n",
      "Current iteration=1000, loss=0.8855728240846271\n",
      "Current iteration=1100, loss=0.8855728240846271\n",
      "Current iteration=1200, loss=0.8855728240846271\n",
      "Current iteration=1300, loss=0.8855728240846271\n",
      "Current iteration=1400, loss=0.8855728240846271\n",
      "Current iteration=1500, loss=0.8855728240846271\n",
      "Current iteration=1600, loss=0.8855728240846271\n",
      "Current iteration=1700, loss=0.8855728240846271\n",
      "Current iteration=1800, loss=0.8855728240846271\n",
      "Current iteration=1900, loss=0.8855728240846271\n",
      "Iteration 29\n",
      "Current iteration=0, loss=1.2306692213833759\n",
      "Current iteration=100, loss=2.120688429816632\n",
      "Current iteration=200, loss=2.1206884298166804\n",
      "Current iteration=300, loss=2.1206884298166804\n",
      "Current iteration=400, loss=2.1206884298166804\n",
      "Current iteration=500, loss=2.1206884298166804\n",
      "Current iteration=600, loss=2.1206884298166804\n",
      "Current iteration=700, loss=2.1206884298166804\n",
      "Current iteration=800, loss=2.1206884298166804\n",
      "Current iteration=900, loss=2.1206884298166804\n",
      "Current iteration=1000, loss=2.1206884298166804\n",
      "Current iteration=1100, loss=2.1206884298166804\n",
      "Current iteration=1200, loss=2.1206884298166804\n",
      "Current iteration=1300, loss=2.1206884298166804\n",
      "Current iteration=1400, loss=2.1206884298166804\n",
      "Current iteration=1500, loss=2.1206884298166804\n",
      "Current iteration=1600, loss=2.1206884298166804\n",
      "Current iteration=1700, loss=2.1206884298166804\n",
      "Current iteration=1800, loss=2.1206884298166804\n",
      "Current iteration=1900, loss=2.1206884298166804\n",
      "Current iteration=0, loss=2.11509115862913\n",
      "Current iteration=100, loss=2.1248205089489884\n",
      "Current iteration=200, loss=2.1248205089489938\n",
      "Current iteration=300, loss=2.1248205089489938\n",
      "Current iteration=400, loss=2.1248205089489938\n",
      "Current iteration=500, loss=2.1248205089489938\n",
      "Current iteration=600, loss=2.1248205089489938\n",
      "Current iteration=700, loss=2.1248205089489938\n",
      "Current iteration=800, loss=2.1248205089489938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=900, loss=2.1248205089489938\n",
      "Current iteration=1000, loss=2.1248205089489938\n",
      "Current iteration=1100, loss=2.1248205089489938\n",
      "Current iteration=1200, loss=2.1248205089489938\n",
      "Current iteration=1300, loss=2.1248205089489938\n",
      "Current iteration=1400, loss=2.1248205089489938\n",
      "Current iteration=1500, loss=2.1248205089489938\n",
      "Current iteration=1600, loss=2.1248205089489938\n",
      "Current iteration=1700, loss=2.1248205089489938\n",
      "Current iteration=1800, loss=2.1248205089489938\n",
      "Current iteration=1900, loss=2.1248205089489938\n",
      "Current iteration=0, loss=2.1290362371044136\n",
      "Current iteration=100, loss=2.1297318054444196\n",
      "Current iteration=200, loss=2.1297318054444094\n",
      "Current iteration=300, loss=2.1297318054444094\n",
      "Current iteration=400, loss=2.1297318054444094\n",
      "Current iteration=500, loss=2.1297318054444094\n",
      "Current iteration=600, loss=2.1297318054444094\n",
      "Current iteration=700, loss=2.1297318054444094\n",
      "Current iteration=800, loss=2.1297318054444094\n",
      "Current iteration=900, loss=2.1297318054444094\n",
      "Current iteration=1000, loss=2.1297318054444094\n",
      "Current iteration=1100, loss=2.1297318054444094\n",
      "Current iteration=1200, loss=2.1297318054444094\n",
      "Current iteration=1300, loss=2.1297318054444094\n",
      "Current iteration=1400, loss=2.1297318054444094\n",
      "Current iteration=1500, loss=2.1297318054444094\n",
      "Current iteration=1600, loss=2.1297318054444094\n",
      "Current iteration=1700, loss=2.1297318054444094\n",
      "Current iteration=1800, loss=2.1297318054444094\n",
      "Current iteration=1900, loss=2.1297318054444094\n",
      "Current iteration=0, loss=2.12074132372019\n",
      "Current iteration=100, loss=2.1151027721902116\n",
      "Current iteration=200, loss=2.11510277219021\n",
      "Current iteration=300, loss=2.11510277219021\n",
      "Current iteration=400, loss=2.11510277219021\n",
      "Current iteration=500, loss=2.11510277219021\n",
      "Current iteration=600, loss=2.11510277219021\n",
      "Current iteration=700, loss=2.11510277219021\n",
      "Current iteration=800, loss=2.11510277219021\n",
      "Current iteration=900, loss=2.11510277219021\n",
      "Current iteration=1000, loss=2.11510277219021\n",
      "Current iteration=1100, loss=2.11510277219021\n",
      "Current iteration=1200, loss=2.11510277219021\n",
      "Current iteration=1300, loss=2.11510277219021\n",
      "Current iteration=1400, loss=2.11510277219021\n",
      "Current iteration=1500, loss=2.11510277219021\n",
      "Current iteration=1600, loss=2.11510277219021\n",
      "Current iteration=1700, loss=2.11510277219021\n",
      "Current iteration=1800, loss=2.11510277219021\n",
      "Current iteration=1900, loss=2.11510277219021\n",
      "Iteration 0\n",
      "Current iteration=0, loss=0.5641308856070585\n",
      "Current iteration=100, loss=0.4933612727051427\n",
      "Current iteration=200, loss=0.48154621598843156\n",
      "Current iteration=300, loss=0.47530950839377656\n",
      "Current iteration=400, loss=0.47152743099316463\n",
      "Current iteration=500, loss=0.4690520145272559\n",
      "Current iteration=600, loss=0.46736348156425134\n",
      "Current iteration=700, loss=0.46617132073517986\n",
      "Current iteration=800, loss=0.4652980231608709\n",
      "Current iteration=900, loss=0.46463712916760436\n",
      "Current iteration=1000, loss=0.4641220441888088\n",
      "Current iteration=1100, loss=0.4637096394382706\n",
      "Current iteration=1200, loss=0.4633711960497868\n",
      "Current iteration=1300, loss=0.46308718101333235\n",
      "Current iteration=1400, loss=0.4628441138143751\n",
      "Current iteration=1500, loss=0.4626325801510303\n",
      "Current iteration=1600, loss=0.46244590277643743\n",
      "Current iteration=1700, loss=0.4622792455126455\n",
      "Current iteration=1800, loss=0.4621290239969155\n",
      "Current iteration=1900, loss=0.46199252286706693\n",
      "Current iteration=0, loss=0.45814921295697775\n",
      "Current iteration=100, loss=0.4576481010681848\n",
      "Current iteration=200, loss=0.45749067013820144\n",
      "Current iteration=300, loss=0.45736188827003016\n",
      "Current iteration=400, loss=0.4572485488070142\n",
      "Current iteration=500, loss=0.45714666641592044\n",
      "Current iteration=600, loss=0.4570541024455162\n",
      "Current iteration=700, loss=0.45696941297854143\n",
      "Current iteration=800, loss=0.4568915256499076\n",
      "Current iteration=900, loss=0.456819602122833\n",
      "Current iteration=1000, loss=0.4567529647707205\n",
      "Current iteration=1100, loss=0.45669105257025905\n",
      "Current iteration=1200, loss=0.45663339251612384\n",
      "Current iteration=1300, loss=0.4565795800958769\n",
      "Current iteration=1400, loss=0.4565292654016878\n",
      "Current iteration=1500, loss=0.45648214292073563\n",
      "Current iteration=1600, loss=0.4564379438207633\n",
      "Current iteration=1700, loss=0.4563964299841581\n",
      "Current iteration=1800, loss=0.45635738930253733\n",
      "Current iteration=1900, loss=0.45632063190287353\n",
      "Current iteration=0, loss=0.4641106092837164\n",
      "Current iteration=100, loss=0.46351524712397213\n",
      "Current iteration=200, loss=0.4634044044496264\n",
      "Current iteration=300, loss=0.4633189964627607\n",
      "Current iteration=400, loss=0.4632446269409726\n",
      "Current iteration=500, loss=0.46317783716863814\n",
      "Current iteration=600, loss=0.4631169558032495\n",
      "Current iteration=700, loss=0.46306090415992024\n",
      "Current iteration=800, loss=0.46300890365979946\n",
      "Current iteration=900, loss=0.462960360773797\n",
      "Current iteration=1000, loss=0.46291480848068145\n",
      "Current iteration=1100, loss=0.46287187182731315\n",
      "Current iteration=1200, loss=0.4628312455975349\n",
      "Current iteration=1300, loss=0.4627926787819288\n",
      "Current iteration=1400, loss=0.46275596322010415\n",
      "Current iteration=1500, loss=0.4627209249976411\n",
      "Current iteration=1600, loss=0.46268741777365163\n",
      "Current iteration=1700, loss=0.462655317525503\n",
      "Current iteration=1800, loss=0.46262451836928414\n",
      "Current iteration=1900, loss=0.46259492921566414\n",
      "Current iteration=0, loss=0.45908015321925366\n",
      "Current iteration=100, loss=0.4584603441039422\n",
      "Current iteration=200, loss=0.4583696229724926\n",
      "Current iteration=300, loss=0.45831145282230334\n",
      "Current iteration=400, loss=0.4582661803751038\n",
      "Current iteration=500, loss=0.458228760421607\n",
      "Current iteration=600, loss=0.4581968901069518\n",
      "Current iteration=700, loss=0.45816919815832385\n",
      "Current iteration=800, loss=0.45814477335258186\n",
      "Current iteration=900, loss=0.45812297532197793\n",
      "Current iteration=1000, loss=0.45810333447805834\n",
      "Current iteration=1100, loss=0.45808549208814686\n",
      "Current iteration=1200, loss=0.45806916415657783\n",
      "Current iteration=1300, loss=0.4580541205872122\n",
      "Current iteration=1400, loss=0.4580401730639485\n",
      "Current iteration=1500, loss=0.45802716712698976\n",
      "Current iteration=1600, loss=0.45801497615389997\n",
      "Current iteration=1700, loss=0.45800349637980936\n",
      "Current iteration=1800, loss=0.4579926426893393\n",
      "Current iteration=1900, loss=0.45798234508588936\n",
      "Iteration 1\n",
      "Current iteration=0, loss=0.4628665162683923\n",
      "Current iteration=100, loss=0.4622407140870684\n",
      "Current iteration=200, loss=0.4621482524768061\n",
      "Current iteration=300, loss=0.4621032448446195\n",
      "Current iteration=400, loss=0.4620768859261407\n",
      "Current iteration=500, loss=0.4620599106279575\n",
      "Current iteration=600, loss=0.46204824381957665\n",
      "Current iteration=700, loss=0.46203980478966206\n",
      "Current iteration=800, loss=0.46203343528487806\n",
      "Current iteration=900, loss=0.46202845094730893\n",
      "Current iteration=1000, loss=0.4620244283899716\n",
      "Current iteration=1100, loss=0.4620210955340634\n",
      "Current iteration=1200, loss=0.46201827173083637\n",
      "Current iteration=1300, loss=0.4620158335533724\n",
      "Current iteration=1400, loss=0.4620136945070901\n",
      "Current iteration=1500, loss=0.462011792595351\n",
      "Current iteration=1600, loss=0.4620100824709922\n",
      "Current iteration=1700, loss=0.46200853034766665\n",
      "Current iteration=1800, loss=0.46200711061934974\n",
      "Current iteration=1900, loss=0.4620058035652774\n",
      "Current iteration=0, loss=0.4586745213123631\n",
      "Current iteration=100, loss=0.45830515357055485\n",
      "Current iteration=200, loss=0.45825629437518245\n",
      "Current iteration=300, loss=0.4582253383323779\n",
      "Current iteration=400, loss=0.4582012139251483\n",
      "Current iteration=500, loss=0.4581811495912897\n",
      "Current iteration=600, loss=0.4581639081685877\n",
      "Current iteration=700, loss=0.45814877250193536\n",
      "Current iteration=800, loss=0.4581352780888004\n",
      "Current iteration=900, loss=0.45812310551126073\n",
      "Current iteration=1000, loss=0.4581120258282777\n",
      "Current iteration=1100, loss=0.4581018694070114\n",
      "Current iteration=1200, loss=0.45809250692908976\n",
      "Current iteration=1300, loss=0.45808383730896357\n",
      "Current iteration=1400, loss=0.4580757797556257\n",
      "Current iteration=1500, loss=0.4580682684133422\n",
      "Current iteration=1600, loss=0.45806124865554276\n",
      "Current iteration=1700, loss=0.4580546744652865\n",
      "Current iteration=1800, loss=0.4580485065461994\n",
      "Current iteration=1900, loss=0.4580427109348301\n",
      "Current iteration=0, loss=0.4652652039813058\n",
      "Current iteration=100, loss=0.46470513181349654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=200, loss=0.4646252717293417\n",
      "Current iteration=300, loss=0.4645707172101313\n",
      "Current iteration=400, loss=0.4645272947293754\n",
      "Current iteration=500, loss=0.4644914055867129\n",
      "Current iteration=600, loss=0.4644612220212841\n",
      "Current iteration=700, loss=0.46443553606446025\n",
      "Current iteration=800, loss=0.46441346888158486\n",
      "Current iteration=900, loss=0.46439435227369985\n",
      "Current iteration=1000, loss=0.4643776658208182\n",
      "Current iteration=1100, loss=0.46436299814003645\n",
      "Current iteration=1200, loss=0.46435002066884284\n",
      "Current iteration=1300, loss=0.46433846886543517\n",
      "Current iteration=1400, loss=0.464328128244197\n",
      "Current iteration=1500, loss=0.46431882377731176\n",
      "Current iteration=1600, loss=0.46431041174103765\n",
      "Current iteration=1700, loss=0.46430277338515014\n",
      "Current iteration=1800, loss=0.4642958099850764\n",
      "Current iteration=1900, loss=0.46428943895427477\n",
      "Current iteration=0, loss=0.4609616373578861\n",
      "Current iteration=100, loss=0.4603904543688287\n",
      "Current iteration=200, loss=0.4603199874094537\n",
      "Current iteration=300, loss=0.46028012104758176\n",
      "Current iteration=400, loss=0.46025210524724225\n",
      "Current iteration=500, loss=0.4602310890719383\n",
      "Current iteration=600, loss=0.460214870441793\n",
      "Current iteration=700, loss=0.4602021598741674\n",
      "Current iteration=800, loss=0.46019210966194163\n",
      "Current iteration=900, loss=0.46018411997187414\n",
      "Current iteration=1000, loss=0.4601777424932794\n",
      "Current iteration=1100, loss=0.4601726310963639\n",
      "Current iteration=1200, loss=0.4601685151349767\n",
      "Current iteration=1300, loss=0.46016518253966204\n",
      "Current iteration=1400, loss=0.46016246736009087\n",
      "Current iteration=1500, loss=0.4601602399385418\n",
      "Current iteration=1600, loss=0.46015839905348715\n",
      "Current iteration=1700, loss=0.4601568656712551\n",
      "Current iteration=1800, loss=0.46015557801926504\n",
      "Current iteration=1900, loss=0.4601544877301302\n",
      "Iteration 2\n",
      "Current iteration=0, loss=0.4656899285456738\n",
      "Current iteration=100, loss=0.46505924123136044\n",
      "Current iteration=200, loss=0.46495390694633726\n",
      "Current iteration=300, loss=0.46489736088143174\n",
      "Current iteration=400, loss=0.46486085587641635\n",
      "Current iteration=500, loss=0.4648348932381669\n",
      "Current iteration=600, loss=0.46481519283766093\n",
      "Current iteration=700, loss=0.46479951273353826\n",
      "Current iteration=800, loss=0.46478657024524717\n",
      "Current iteration=900, loss=0.4647755849600549\n",
      "Current iteration=1000, loss=0.4647660585760356\n",
      "Current iteration=1100, loss=0.46475765966767424\n",
      "Current iteration=1200, loss=0.4647501597114445\n",
      "Current iteration=1300, loss=0.4647433959204546\n",
      "Current iteration=1400, loss=0.46473724883037887\n",
      "Current iteration=1500, loss=0.46473162833709225\n",
      "Current iteration=1600, loss=0.46472646474557167\n",
      "Current iteration=1700, loss=0.4647217028817337\n",
      "Current iteration=1800, loss=0.4647172981285307\n",
      "Current iteration=1900, loss=0.46471321370148216\n",
      "Current iteration=0, loss=0.46143605953614825\n",
      "Current iteration=100, loss=0.4610582975033122\n",
      "Current iteration=200, loss=0.4610001700775468\n",
      "Current iteration=300, loss=0.4609603603832058\n",
      "Current iteration=400, loss=0.460927897475599\n",
      "Current iteration=500, loss=0.4609000049054978\n",
      "Current iteration=600, loss=0.46087542152581934\n",
      "Current iteration=700, loss=0.4608534045390176\n",
      "Current iteration=800, loss=0.46083346446922574\n",
      "Current iteration=900, loss=0.4608152577933347\n",
      "Current iteration=1000, loss=0.4607985323295404\n",
      "Current iteration=1100, loss=0.4607830960862892\n",
      "Current iteration=1200, loss=0.4607687983029805\n",
      "Current iteration=1300, loss=0.4607555173999098\n",
      "Current iteration=1400, loss=0.46074315305901187\n",
      "Current iteration=1500, loss=0.46073162086907693\n",
      "Current iteration=1600, loss=0.46072084861127094\n",
      "Current iteration=1700, loss=0.4607107736211915\n",
      "Current iteration=1800, loss=0.4607013408741158\n",
      "Current iteration=1900, loss=0.4606925015666637\n",
      "Current iteration=0, loss=0.46772169155065924\n",
      "Current iteration=100, loss=0.46717740554547876\n",
      "Current iteration=200, loss=0.46710352050323234\n",
      "Current iteration=300, loss=0.467054623956351\n",
      "Current iteration=400, loss=0.46701680872539536\n",
      "Current iteration=500, loss=0.4669864109172589\n",
      "Current iteration=600, loss=0.4669615302417734\n",
      "Current iteration=700, loss=0.4669409136295404\n",
      "Current iteration=800, loss=0.46692366163525884\n",
      "Current iteration=900, loss=0.46690910231133703\n",
      "Current iteration=1000, loss=0.4668967218018354\n",
      "Current iteration=1100, loss=0.46688612093784654\n",
      "Current iteration=1200, loss=0.46687698597549826\n",
      "Current iteration=1300, loss=0.46686906792595806\n",
      "Current iteration=1400, loss=0.46686216751177795\n",
      "Current iteration=1500, loss=0.466856123997738\n",
      "Current iteration=1600, loss=0.46685080678095336\n",
      "Current iteration=1700, loss=0.4668461089912741\n",
      "Current iteration=1800, loss=0.4668419425799081\n",
      "Current iteration=1900, loss=0.46683823452280687\n",
      "Current iteration=0, loss=0.46357750836954237\n",
      "Current iteration=100, loss=0.4630127544117966\n",
      "Current iteration=200, loss=0.46294461296391665\n",
      "Current iteration=300, loss=0.46290649794295335\n",
      "Current iteration=400, loss=0.4628801299237361\n",
      "Current iteration=500, loss=0.46286073789088084\n",
      "Current iteration=600, loss=0.46284613120584317\n",
      "Current iteration=700, loss=0.46283499247961873\n",
      "Current iteration=800, loss=0.46282642380746447\n",
      "Current iteration=900, loss=0.46281977967929155\n",
      "Current iteration=1000, loss=0.4628145862914413\n",
      "Current iteration=1100, loss=0.46281049267364227\n",
      "Current iteration=1200, loss=0.4628072373958896\n",
      "Current iteration=1300, loss=0.4628046248497543\n",
      "Current iteration=1400, loss=0.4628025080611604\n",
      "Current iteration=1500, loss=0.46280077613577153\n",
      "Current iteration=1600, loss=0.46279934504127135\n",
      "Current iteration=1700, loss=0.4627981508124545\n",
      "Iteration 3\n",
      "Current iteration=0, loss=0.46863704363824493\n",
      "Current iteration=100, loss=0.4680096168130598\n",
      "Current iteration=200, loss=0.4678947414350196\n",
      "Current iteration=300, loss=0.4678302948106163\n",
      "Current iteration=400, loss=0.4677875675780163\n",
      "Current iteration=500, loss=0.4677567121399404\n",
      "Current iteration=600, loss=0.46773313668126376\n",
      "Current iteration=700, loss=0.46771435959501845\n",
      "Current iteration=800, loss=0.46769892183540845\n",
      "Current iteration=900, loss=0.46768591460593767\n",
      "Current iteration=1000, loss=0.46767474555939875\n",
      "Current iteration=1100, loss=0.46766501328959814\n",
      "Current iteration=1200, loss=0.46765643611846835\n",
      "Current iteration=1300, loss=0.4676488099654233\n",
      "Current iteration=1400, loss=0.4676419825539465\n",
      "Current iteration=1500, loss=0.46763583714545487\n",
      "Current iteration=1600, loss=0.46763028200706647\n",
      "Current iteration=1700, loss=0.46762524342740996\n",
      "Current iteration=1800, loss=0.46762066098322097\n",
      "Current iteration=1900, loss=0.4676164842660782\n",
      "Current iteration=0, loss=0.46424012448056534\n",
      "Current iteration=100, loss=0.4638640294969281\n",
      "Current iteration=200, loss=0.463807242861863\n",
      "Current iteration=300, loss=0.4637690568948116\n",
      "Current iteration=400, loss=0.463738454105026\n",
      "Current iteration=500, loss=0.4637126070663668\n",
      "Current iteration=600, loss=0.46369021492162776\n",
      "Current iteration=700, loss=0.4636705067430448\n",
      "Current iteration=800, loss=0.46365297118003584\n",
      "Current iteration=900, loss=0.4636372459921108\n",
      "Current iteration=1000, loss=0.4636230621136243\n",
      "Current iteration=1100, loss=0.4636102120283419\n",
      "Current iteration=1200, loss=0.4635985306754979\n",
      "Current iteration=1300, loss=0.4635878833762731\n",
      "Current iteration=1400, loss=0.4635781579109749\n",
      "Current iteration=1500, loss=0.4635692591495281\n",
      "Current iteration=1600, loss=0.4635611053044137\n",
      "Current iteration=1700, loss=0.46355362524432286\n",
      "Current iteration=1800, loss=0.4635467565195415\n",
      "Current iteration=1900, loss=0.46354044387657767\n",
      "Current iteration=0, loss=0.47047398381864125\n",
      "Current iteration=100, loss=0.4699450951113784\n",
      "Current iteration=200, loss=0.46987450614984133\n",
      "Current iteration=300, loss=0.4698286078464622\n",
      "Current iteration=400, loss=0.4697937962472893\n",
      "Current iteration=500, loss=0.46976633665988304\n",
      "Current iteration=600, loss=0.469744258243153\n",
      "Current iteration=700, loss=0.46972626760089214\n",
      "Current iteration=800, loss=0.469711449091096\n",
      "Current iteration=900, loss=0.46969913004862607\n",
      "Current iteration=1000, loss=0.4696888047872228\n",
      "Current iteration=1100, loss=0.469680086807344\n",
      "Current iteration=1200, loss=0.4696726768077456\n",
      "Current iteration=1300, loss=0.4696663404173495\n",
      "Current iteration=1400, loss=0.4696608922799888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1500, loss=0.4696561844635393\n",
      "Current iteration=1600, loss=0.4696520978963415\n",
      "Current iteration=1700, loss=0.4696485359660343\n",
      "Current iteration=1800, loss=0.4696454196867517\n",
      "Current iteration=1900, loss=0.4696426840177547\n",
      "Current iteration=0, loss=0.4664505899631512\n",
      "Current iteration=100, loss=0.4658915200293606\n",
      "Current iteration=200, loss=0.4658260173115206\n",
      "Current iteration=300, loss=0.465790381877855\n",
      "Current iteration=400, loss=0.46576665138100387\n",
      "Current iteration=500, loss=0.4657499166045897\n",
      "Current iteration=600, loss=0.465737814609744\n",
      "Current iteration=700, loss=0.46572891967303726\n",
      "Current iteration=800, loss=0.4657222954923297\n",
      "Current iteration=900, loss=0.4657173033535999\n",
      "Current iteration=1000, loss=0.4657134980392991\n",
      "Current iteration=1100, loss=0.46571056461417076\n",
      "Current iteration=1200, loss=0.46570827777902546\n",
      "Current iteration=1300, loss=0.4657064748473794\n",
      "Current iteration=1400, loss=0.46570503737497426\n",
      "Current iteration=1500, loss=0.4657038784687943\n",
      "Iteration 4\n",
      "Current iteration=0, loss=0.4718262930344462\n",
      "Current iteration=100, loss=0.4711982277863522\n",
      "Current iteration=200, loss=0.47107397605556606\n",
      "Current iteration=300, loss=0.47100395676937495\n",
      "Current iteration=400, loss=0.4709584969780603\n",
      "Current iteration=500, loss=0.4709267570934\n",
      "Current iteration=600, loss=0.470903463166819\n",
      "Current iteration=700, loss=0.4708856905981879\n",
      "Current iteration=800, loss=0.47087169725153305\n",
      "Current iteration=900, loss=0.4708603939304061\n",
      "Current iteration=1000, loss=0.47085107284642924\n",
      "Current iteration=1100, loss=0.47084325810891087\n",
      "Current iteration=1200, loss=0.47083661947856315\n",
      "Current iteration=1300, loss=0.47083092086747813\n",
      "Current iteration=1400, loss=0.4708259887000073\n",
      "Current iteration=1500, loss=0.470821691981147\n",
      "Current iteration=1600, loss=0.47081792944714046\n",
      "Current iteration=1700, loss=0.4708146210997057\n",
      "Current iteration=1800, loss=0.4708117025108413\n",
      "Current iteration=1900, loss=0.4708091209128776\n",
      "Current iteration=0, loss=0.4673646084004691\n",
      "Current iteration=100, loss=0.46699607998211523\n",
      "Current iteration=200, loss=0.4669438690048318\n",
      "Current iteration=300, loss=0.4669104826488073\n",
      "Current iteration=400, loss=0.46688482048439306\n",
      "Current iteration=500, loss=0.46686393369229734\n",
      "Current iteration=600, loss=0.4668464439638742\n",
      "Current iteration=700, loss=0.46683153806315125\n",
      "Current iteration=800, loss=0.4668186812471846\n",
      "Current iteration=900, loss=0.4668074972654781\n",
      "Current iteration=1000, loss=0.4667977078793081\n",
      "Current iteration=1100, loss=0.46678909922985273\n",
      "Current iteration=1200, loss=0.46678150187488054\n",
      "Current iteration=1300, loss=0.4667747783165311\n",
      "Current iteration=1400, loss=0.46676881486031646\n",
      "Current iteration=1500, loss=0.4667635160903756\n",
      "Current iteration=1600, loss=0.4667588009867614\n",
      "Current iteration=1700, loss=0.46675460010970476\n",
      "Current iteration=1800, loss=0.46675085349964934\n",
      "Current iteration=1900, loss=0.46674750907178836\n",
      "Current iteration=0, loss=0.4735070693581241\n",
      "Current iteration=100, loss=0.472996570951281\n",
      "Current iteration=200, loss=0.47292940675002443\n",
      "Current iteration=300, loss=0.47288654854547824\n",
      "Current iteration=400, loss=0.4728547613128689\n",
      "Current iteration=500, loss=0.4728302331647972\n",
      "Current iteration=600, loss=0.47281092078687786\n",
      "Current iteration=700, loss=0.47279549348034877\n",
      "Current iteration=800, loss=0.472783024265788\n",
      "Current iteration=900, loss=0.47277284467865316\n",
      "Current iteration=1000, loss=0.47276446144671325\n",
      "Current iteration=1100, loss=0.47275750412277634\n",
      "Current iteration=1200, loss=0.4727516904278827\n",
      "Current iteration=1300, loss=0.47274680253144585\n",
      "Current iteration=1400, loss=0.47274267042330426\n",
      "Current iteration=1500, loss=0.4727391600403747\n",
      "Current iteration=1600, loss=0.47273616465900437\n",
      "Current iteration=1700, loss=0.4727335985726631\n",
      "Current iteration=1800, loss=0.4727313923935341\n",
      "Current iteration=1900, loss=0.472729489523193\n",
      "Current iteration=0, loss=0.4696377116717347\n",
      "Current iteration=100, loss=0.469090393791861\n",
      "Current iteration=200, loss=0.4690294553222622\n",
      "Current iteration=300, loss=0.4689982282086869\n",
      "Current iteration=400, loss=0.46897851107521366\n",
      "Current iteration=500, loss=0.4689652284096047\n",
      "Current iteration=600, loss=0.4689559962109982\n",
      "Current iteration=700, loss=0.46894944310824405\n",
      "Current iteration=800, loss=0.46894471159147355\n",
      "Current iteration=900, loss=0.4689412424197064\n",
      "Current iteration=1000, loss=0.4689386614632777\n",
      "Current iteration=1100, loss=0.46893671392767355\n",
      "Current iteration=1200, loss=0.4689352238515364\n",
      "Current iteration=1300, loss=0.4689340682622724\n",
      "Iteration 5\n",
      "Current iteration=0, loss=0.4753966811365677\n",
      "Current iteration=100, loss=0.4747494995376723\n",
      "Current iteration=200, loss=0.47461059746313283\n",
      "Current iteration=300, loss=0.47453339656254895\n",
      "Current iteration=400, loss=0.4744853931578854\n",
      "Current iteration=500, loss=0.47445367674395605\n",
      "Current iteration=600, loss=0.4744317575827003\n",
      "Current iteration=700, loss=0.47441602356576257\n",
      "Current iteration=800, loss=0.47440434994015\n",
      "Current iteration=900, loss=0.47439543813087204\n",
      "Current iteration=1000, loss=0.47438846863453427\n",
      "Current iteration=1100, loss=0.4743829084868562\n",
      "Current iteration=1200, loss=0.4743784006474784\n",
      "Current iteration=1300, loss=0.4743746987709096\n",
      "Current iteration=1400, loss=0.4743716278892264\n",
      "Current iteration=1500, loss=0.47436906022880465\n",
      "Current iteration=1600, loss=0.4743669000365241\n",
      "Current iteration=1700, loss=0.47436507386290044\n",
      "Current iteration=1800, loss=0.4743635242056815\n",
      "Current iteration=1900, loss=0.47436220525756373\n",
      "Current iteration=0, loss=0.47089173456321076\n",
      "Current iteration=100, loss=0.47053611721301775\n",
      "Current iteration=200, loss=0.47048802868350076\n",
      "Current iteration=300, loss=0.47045889748279607\n",
      "Current iteration=400, loss=0.47043767892009375\n",
      "Current iteration=500, loss=0.4704212679156711\n",
      "Current iteration=600, loss=0.47040816829057436\n",
      "Current iteration=700, loss=0.4703974989141905\n",
      "Current iteration=800, loss=0.47038868933508127\n",
      "Current iteration=900, loss=0.4703813456634632\n",
      "Current iteration=1000, loss=0.4703751820271841\n",
      "Current iteration=1100, loss=0.47036998275514935\n",
      "Current iteration=1200, loss=0.47036558026420056\n",
      "Current iteration=1300, loss=0.4703618414206728\n",
      "Current iteration=1400, loss=0.4703586586950249\n",
      "Current iteration=1500, loss=0.47035594415413484\n",
      "Current iteration=1600, loss=0.47035362521136265\n",
      "Current iteration=1700, loss=0.4703516415141162\n",
      "Current iteration=1800, loss=0.470349942598171\n",
      "Current iteration=1900, loss=0.4703484860781868\n",
      "Current iteration=0, loss=0.4768601384806568\n",
      "Current iteration=100, loss=0.47637180139460966\n",
      "Current iteration=200, loss=0.4763086770428465\n",
      "Current iteration=300, loss=0.4762695273839521\n",
      "Current iteration=400, loss=0.4762414098115177\n",
      "Current iteration=500, loss=0.4762204073599703\n",
      "Current iteration=600, loss=0.47620439185203733\n",
      "Current iteration=700, loss=0.4761919929049192\n",
      "Current iteration=800, loss=0.4761822748389361\n",
      "Current iteration=900, loss=0.47617457803779584\n",
      "Current iteration=1000, loss=0.47616842683047134\n",
      "Current iteration=1100, loss=0.4761634719313942\n",
      "Current iteration=1200, loss=0.4761594529041926\n",
      "Current iteration=1300, loss=0.47615617294745544\n",
      "Current iteration=1400, loss=0.4761534815679804\n",
      "Current iteration=1500, loss=0.47615126244924577\n",
      "Current iteration=1600, loss=0.47614942481917305\n",
      "Current iteration=1700, loss=0.4761478972190278\n",
      "Current iteration=1800, loss=0.47614662294666976\n",
      "Current iteration=0, loss=0.47319561239464886\n",
      "Current iteration=100, loss=0.47265728836694276\n",
      "Current iteration=200, loss=0.4726037753683179\n",
      "Current iteration=300, loss=0.4725781934785808\n",
      "Current iteration=400, loss=0.4725627385037541\n",
      "Current iteration=500, loss=0.47255274508909667\n",
      "Current iteration=600, loss=0.47254606032792673\n",
      "Current iteration=700, loss=0.47254148138961505\n",
      "Current iteration=800, loss=0.4725382816614569\n",
      "Current iteration=900, loss=0.47253600439417737\n",
      "Current iteration=1000, loss=0.4725343552147957\n",
      "Current iteration=1100, loss=0.4725331408252122\n",
      "Iteration 6\n",
      "Current iteration=0, loss=0.4793756746658693\n",
      "Current iteration=100, loss=0.4786829402365286\n",
      "Current iteration=200, loss=0.4785242521037009\n",
      "Current iteration=300, loss=0.478439689117034\n",
      "Current iteration=400, loss=0.4783904829583435\n",
      "Current iteration=500, loss=0.47836034143908124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=600, loss=0.47834108412738957\n",
      "Current iteration=700, loss=0.4783282924800313\n",
      "Current iteration=800, loss=0.4783194812568674\n",
      "Current iteration=900, loss=0.47831320879738026\n",
      "Current iteration=1000, loss=0.4783086140182914\n",
      "Current iteration=1100, loss=0.47830516676362356\n",
      "Current iteration=1200, loss=0.4783025299982515\n",
      "Current iteration=1300, loss=0.47830048224474997\n",
      "Current iteration=1400, loss=0.47829887308985514\n",
      "Current iteration=1500, loss=0.4782975971366078\n",
      "Current iteration=0, loss=0.47482596881364775\n",
      "Current iteration=100, loss=0.4744838449716184\n",
      "Current iteration=200, loss=0.4744402027641865\n",
      "Current iteration=300, loss=0.4744152000494316\n",
      "Current iteration=400, loss=0.47439799019214934\n",
      "Current iteration=500, loss=0.47438542068608963\n",
      "Current iteration=600, loss=0.47437594233578195\n",
      "Current iteration=700, loss=0.47436864256903294\n",
      "Current iteration=800, loss=0.4743629375230334\n",
      "Current iteration=900, loss=0.4743584322155801\n",
      "Current iteration=1000, loss=0.4743548476354261\n",
      "Current iteration=1100, loss=0.4743519799241556\n",
      "Current iteration=1200, loss=0.4743496762429951\n",
      "Current iteration=1300, loss=0.474347819770193\n",
      "Current iteration=1400, loss=0.474346319925704\n",
      "Current iteration=1500, loss=0.4743451057263526\n",
      "Current iteration=0, loss=0.48055105842147317\n",
      "Current iteration=100, loss=0.4800883696939322\n",
      "Current iteration=200, loss=0.48003211952958813\n",
      "Current iteration=300, loss=0.4799993470962422\n",
      "Current iteration=400, loss=0.47997715350252146\n",
      "Current iteration=500, loss=0.4799615066410262\n",
      "Current iteration=600, loss=0.479950235203378\n",
      "Current iteration=700, loss=0.47994198483035166\n",
      "Current iteration=800, loss=0.47993586623651674\n",
      "Current iteration=900, loss=0.47993127789761014\n",
      "Current iteration=1000, loss=0.47992780386837847\n",
      "Current iteration=1100, loss=0.4799251513209712\n",
      "Current iteration=1200, loss=0.4799231109353936\n",
      "Current iteration=1300, loss=0.47992153108669994\n",
      "Current iteration=1400, loss=0.479920300648515\n",
      "Current iteration=0, loss=0.47717151384874046\n",
      "Current iteration=100, loss=0.4766133600188727\n",
      "Current iteration=200, loss=0.4765677391079994\n",
      "Current iteration=300, loss=0.47654770631489324\n",
      "Current iteration=400, loss=0.47653629987049\n",
      "Current iteration=500, loss=0.47652931817154703\n",
      "Current iteration=600, loss=0.47652488601370235\n",
      "Current iteration=700, loss=0.4765219970309834\n",
      "Current iteration=800, loss=0.47652007067623176\n",
      "Current iteration=900, loss=0.4765187590967176\n",
      "Iteration 7\n",
      "Current iteration=0, loss=0.4837425897442471\n",
      "Current iteration=100, loss=0.4829766345405645\n",
      "Current iteration=200, loss=0.48279681648718553\n",
      "Current iteration=300, loss=0.482708325343299\n",
      "Current iteration=400, loss=0.4826615989826377\n",
      "Current iteration=500, loss=0.48263577453234713\n",
      "Current iteration=600, loss=0.48262088870008585\n",
      "Current iteration=700, loss=0.482611936621907\n",
      "Current iteration=800, loss=0.48260632326026387\n",
      "Current iteration=900, loss=0.48260266349871267\n",
      "Current iteration=1000, loss=0.48260019435673385\n",
      "Current iteration=1100, loss=0.4825984804445725\n",
      "Current iteration=1200, loss=0.4825972635796126\n",
      "Current iteration=0, loss=0.4791354661382495\n",
      "Current iteration=100, loss=0.47880820914674344\n",
      "Current iteration=200, loss=0.47877020936780523\n",
      "Current iteration=300, loss=0.47874996659186336\n",
      "Current iteration=400, loss=0.4787370067059553\n",
      "Current iteration=500, loss=0.47872821152028316\n",
      "Current iteration=600, loss=0.4787220518609066\n",
      "Current iteration=700, loss=0.47871764606983197\n",
      "Current iteration=800, loss=0.4787144473685116\n",
      "Current iteration=900, loss=0.47871209992225\n",
      "Current iteration=1000, loss=0.4787103636000447\n",
      "Current iteration=1100, loss=0.4787090717902304\n",
      "Current iteration=0, loss=0.48461318755612937\n",
      "Current iteration=100, loss=0.4841712364366437\n",
      "Current iteration=200, loss=0.48412098160675987\n",
      "Current iteration=300, loss=0.48409408259731646\n",
      "Current iteration=400, loss=0.4840772451024818\n",
      "Current iteration=500, loss=0.4840662543797958\n",
      "Current iteration=600, loss=0.48405891630003967\n",
      "Current iteration=700, loss=0.48405393399823404\n",
      "Current iteration=800, loss=0.48405050450848325\n",
      "Current iteration=900, loss=0.48404811631547223\n",
      "Current iteration=1000, loss=0.4840464364691792\n",
      "Current iteration=1100, loss=0.48404524441491403\n",
      "Current iteration=0, loss=0.4815142602014494\n",
      "Current iteration=100, loss=0.4809553113963876\n",
      "Current iteration=200, loss=0.4809126260514535\n",
      "Current iteration=300, loss=0.4808964534017564\n",
      "Current iteration=400, loss=0.48088797649583515\n",
      "Current iteration=500, loss=0.48088314655627556\n",
      "Current iteration=600, loss=0.4808802792801966\n",
      "Current iteration=700, loss=0.4808785253874353\n",
      "Iteration 8\n",
      "Current iteration=0, loss=0.4884490290301534\n",
      "Current iteration=100, loss=0.48758417599278797\n",
      "Current iteration=200, loss=0.48738752522261575\n",
      "Current iteration=300, loss=0.4873019991218221\n",
      "Current iteration=400, loss=0.48726254467608665\n",
      "Current iteration=500, loss=0.4872435266854296\n",
      "Current iteration=600, loss=0.48723393221752126\n",
      "Current iteration=700, loss=0.4872288483002695\n",
      "Current iteration=800, loss=0.48722601631835744\n",
      "Current iteration=900, loss=0.48722436284424736\n",
      "Current iteration=0, loss=0.4837764639894822\n",
      "Current iteration=100, loss=0.48346485975376136\n",
      "Current iteration=200, loss=0.4834331529472807\n",
      "Current iteration=300, loss=0.4834178451332736\n",
      "Current iteration=400, loss=0.4834089601196604\n",
      "Current iteration=500, loss=0.48340350029621343\n",
      "Current iteration=600, loss=0.4834000401899122\n",
      "Current iteration=700, loss=0.48339780105962477\n",
      "Current iteration=800, loss=0.48339633015760664\n",
      "Current iteration=0, loss=0.489017522854579\n",
      "Current iteration=100, loss=0.48858799219719057\n",
      "Current iteration=200, loss=0.4885426942935002\n",
      "Current iteration=300, loss=0.48852095809643653\n",
      "Current iteration=400, loss=0.4885086865620179\n",
      "Current iteration=500, loss=0.4885014461072446\n",
      "Current iteration=600, loss=0.48849707060061576\n",
      "Current iteration=700, loss=0.48849437939523543\n",
      "Current iteration=800, loss=0.4884927004769494\n",
      "Current iteration=0, loss=0.4861689049639696\n",
      "Current iteration=100, loss=0.4856337630391879\n",
      "Current iteration=200, loss=0.4855929747994382\n",
      "Current iteration=300, loss=0.4855790260552877\n",
      "Current iteration=400, loss=0.48557247100671735\n",
      "Current iteration=500, loss=0.48556906666373983\n",
      "Current iteration=600, loss=0.4855672127538118\n",
      "Iteration 9\n",
      "Current iteration=0, loss=0.49341873116480517\n",
      "Current iteration=100, loss=0.4924370967133792\n",
      "Current iteration=200, loss=0.492235153916532\n",
      "Current iteration=300, loss=0.4921613708522904\n",
      "Current iteration=400, loss=0.4921329180307025\n",
      "Current iteration=500, loss=0.4921214108897818\n",
      "Current iteration=600, loss=0.4921164997079695\n",
      "Current iteration=700, loss=0.49211427493084264\n",
      "Current iteration=0, loss=0.4886829670433963\n",
      "Current iteration=100, loss=0.48838602332583597\n",
      "Current iteration=200, loss=0.48836102498954637\n",
      "Current iteration=300, loss=0.48835048747614423\n",
      "Current iteration=400, loss=0.4883451393716901\n",
      "Current iteration=500, loss=0.4883422705095037\n",
      "Current iteration=600, loss=0.4883406847620569\n",
      "Current iteration=0, loss=0.4937013982858346\n",
      "Current iteration=100, loss=0.4932793123887186\n",
      "Current iteration=200, loss=0.493239539710975\n",
      "Current iteration=300, loss=0.49322299311092405\n",
      "Current iteration=400, loss=0.49321485863075926\n",
      "Current iteration=500, loss=0.49321066982977835\n",
      "Current iteration=600, loss=0.4932084569149763\n",
      "Current iteration=0, loss=0.4910680277980604\n",
      "Current iteration=100, loss=0.4905664908493906\n",
      "Current iteration=200, loss=0.49053340350186553\n",
      "Current iteration=300, loss=0.4905227652847827\n",
      "Current iteration=400, loss=0.49051812619024837\n",
      "Current iteration=500, loss=0.4905159086309773\n",
      "Iteration 10\n",
      "Current iteration=0, loss=0.4985577723307725\n",
      "Current iteration=100, loss=0.4974554008280545\n",
      "Current iteration=200, loss=0.4972661546151381\n",
      "Current iteration=300, loss=0.49721143484387337\n",
      "Current iteration=400, loss=0.4971946595109798\n",
      "Current iteration=500, loss=0.4971891986597021\n",
      "Current iteration=600, loss=0.4971872931736809\n",
      "Current iteration=0, loss=0.4937751850649056\n",
      "Current iteration=100, loss=0.49349170502184453\n",
      "Current iteration=200, loss=0.493473267180733\n",
      "Current iteration=300, loss=0.4934668710340784\n",
      "Current iteration=400, loss=0.4934641768255643\n",
      "Current iteration=0, loss=0.4985818108522083\n",
      "Current iteration=100, loss=0.49817494196920203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=200, loss=0.4981435360920889\n",
      "Current iteration=300, loss=0.4981327574591921\n",
      "Current iteration=400, loss=0.4981283697319265\n",
      "Current iteration=500, loss=0.4981264947769446\n",
      "Current iteration=0, loss=0.4961345593295948\n",
      "Current iteration=100, loss=0.4956751971734358\n",
      "Current iteration=200, loss=0.4956503191482764\n",
      "Current iteration=300, loss=0.4956435524391135\n",
      "Current iteration=400, loss=0.4956410356634344\n",
      "Iteration 11\n",
      "Current iteration=0, loss=0.5037772053776347\n",
      "Current iteration=100, loss=0.5025703236132024\n",
      "Current iteration=200, loss=0.5024141414757165\n",
      "Current iteration=300, loss=0.5023811846429596\n",
      "Current iteration=400, loss=0.5023737127598864\n",
      "Current iteration=0, loss=0.49897537876223125\n",
      "Current iteration=100, loss=0.49870686917317336\n",
      "Current iteration=200, loss=0.4986942541978005\n",
      "Current iteration=300, loss=0.4986909147270251\n",
      "Current iteration=0, loss=0.5035925833496077\n",
      "Current iteration=100, loss=0.5032126675875356\n",
      "Current iteration=200, loss=0.5031911760544227\n",
      "Current iteration=300, loss=0.5031855001153448\n",
      "Current iteration=0, loss=0.5013010979379108\n",
      "Current iteration=100, loss=0.5008916589221771\n",
      "Current iteration=200, loss=0.5008742642232845\n",
      "Current iteration=300, loss=0.5008705562171747\n",
      "Iteration 12\n",
      "Current iteration=0, loss=0.5090231027289213\n",
      "Current iteration=100, loss=0.5077427730105896\n",
      "Current iteration=200, loss=0.5076323408389829\n",
      "Current iteration=300, loss=0.5076169253068916\n",
      "Current iteration=0, loss=0.5042309886731451\n",
      "Current iteration=100, loss=0.5039784093709988\n",
      "Current iteration=200, loss=0.5039706709001248\n",
      "Current iteration=0, loss=0.5086933537696376\n",
      "Current iteration=100, loss=0.5083435571564999\n",
      "Current iteration=200, loss=0.5083306366869883\n",
      "Current iteration=300, loss=0.5083282484898707\n",
      "Current iteration=0, loss=0.5065250012492012\n",
      "Current iteration=100, loss=0.506164207263494\n",
      "Current iteration=200, loss=0.5061532853787797\n",
      "Iteration 13\n",
      "Current iteration=0, loss=0.5142675944146927\n",
      "Current iteration=100, loss=0.512954591539414\n",
      "Current iteration=200, loss=0.5128900826150311\n",
      "Current iteration=300, loss=0.5128848083583306\n",
      "Current iteration=0, loss=0.5095154483280897\n",
      "Current iteration=100, loss=0.5092804501292625\n",
      "Current iteration=200, loss=0.5092763236073686\n",
      "Current iteration=0, loss=0.5138556137346332\n",
      "Current iteration=100, loss=0.5135361773846123\n",
      "Current iteration=200, loss=0.5135295725368956\n",
      "Current iteration=0, loss=0.5117874367195548\n",
      "Current iteration=100, loss=0.5114641249554549\n",
      "Current iteration=200, loss=0.511458235590475\n",
      "Iteration 14\n",
      "Current iteration=0, loss=0.5195125939917203\n",
      "Current iteration=100, loss=0.5182117031208098\n",
      "Current iteration=200, loss=0.5181822516293239\n",
      "Current iteration=0, loss=0.5148303434655477\n",
      "Current iteration=100, loss=0.5146152383892733\n",
      "Current iteration=0, loss=0.5190750301547695\n",
      "Current iteration=100, loss=0.5187858227449124\n",
      "Current iteration=0, loss=0.5170837899614658\n",
      "Current iteration=100, loss=0.5167917887183999\n",
      "Iteration 15\n",
      "Current iteration=0, loss=0.5247953455896937\n",
      "Current iteration=100, loss=0.5235463411197036\n",
      "Current iteration=0, loss=0.520210779952587\n",
      "Current iteration=100, loss=0.520016769217579\n",
      "Current iteration=0, loss=0.5243771123310397\n",
      "Current iteration=100, loss=0.5241181525620144\n",
      "Current iteration=0, loss=0.5224406655652784\n",
      "Current iteration=100, loss=0.5221810268916084\n",
      "Iteration 16\n",
      "Current iteration=0, loss=0.5301862645981132\n",
      "Current iteration=100, loss=0.5290139441611581\n",
      "Current iteration=0, loss=0.5257217482106207\n",
      "Current iteration=0, loss=0.5298169546738258\n",
      "Current iteration=100, loss=0.5295875727121264\n",
      "Current iteration=0, loss=0.527921166044161\n",
      "Current iteration=100, loss=0.5276959742726762\n",
      "Iteration 17\n",
      "Current iteration=0, loss=0.5357753582189791\n",
      "Current iteration=100, loss=0.5346883915571885\n",
      "Current iteration=0, loss=0.5314488876571448\n",
      "Current iteration=0, loss=0.5354695157796456\n",
      "Current iteration=0, loss=0.5336104035792386\n",
      "Iteration 18\n",
      "Current iteration=0, loss=0.5416566187762581\n",
      "Current iteration=0, loss=0.5374897775562543\n",
      "Current iteration=0, loss=0.5414190823219291\n",
      "Current iteration=0, loss=0.53960296132648\n",
      "Iteration 19\n",
      "Current iteration=0, loss=0.5479239411647839\n",
      "Current iteration=0, loss=0.5439465428672557\n",
      "Current iteration=0, loss=0.5477557204552979\n",
      "Current iteration=0, loss=0.5459961594967714\n",
      "Iteration 20\n",
      "Current iteration=0, loss=0.554669458302295\n",
      "Current iteration=0, loss=0.5509132473292193\n",
      "Current iteration=0, loss=0.5545678443598689\n",
      "Current iteration=0, loss=0.5528842699049166\n",
      "Iteration 21\n",
      "Current iteration=0, loss=0.5619658854005743\n",
      "Current iteration=0, loss=0.5584629649860817\n",
      "Current iteration=0, loss=0.561933857468647\n",
      "Current iteration=0, loss=0.5603397436464752\n",
      "Iteration 22\n",
      "Current iteration=0, loss=0.5698546828609506\n",
      "Current iteration=100, loss=0.5743309884113793\n",
      "Current iteration=200, loss=0.574329515939294\n",
      "Current iteration=300, loss=0.5743295159392852\n",
      "Current iteration=400, loss=0.5743295159392852\n",
      "Current iteration=500, loss=0.5743295159392852\n",
      "Current iteration=600, loss=0.5743295159392852\n",
      "Current iteration=700, loss=0.5743295159392852\n",
      "Current iteration=800, loss=0.5743295159392852\n",
      "Current iteration=900, loss=0.5743295159392853\n",
      "Current iteration=1000, loss=0.5743295159392852\n",
      "Current iteration=1100, loss=0.5743295159392852\n",
      "Current iteration=1200, loss=0.5743295159392852\n",
      "Current iteration=1300, loss=0.5743295159392852\n",
      "Current iteration=1400, loss=0.5743295159392852\n",
      "Current iteration=1500, loss=0.5743295159392853\n",
      "Current iteration=1600, loss=0.5743295159392853\n",
      "Current iteration=1700, loss=0.5743295159392852\n",
      "Current iteration=1800, loss=0.5743295159392852\n",
      "Current iteration=1900, loss=0.5743295159392852\n",
      "Current iteration=0, loss=0.5716057563416127\n",
      "Current iteration=100, loss=0.5701111953720969\n",
      "Current iteration=200, loss=0.5701111954541391\n",
      "Current iteration=300, loss=0.5701111954541391\n",
      "Current iteration=400, loss=0.5701111954541391\n",
      "Current iteration=500, loss=0.5701111954541391\n",
      "Current iteration=600, loss=0.5701111954541391\n",
      "Current iteration=700, loss=0.5701111954541391\n",
      "Current iteration=800, loss=0.5701111954541391\n",
      "Current iteration=900, loss=0.5701111954541391\n",
      "Current iteration=1000, loss=0.5701111954541391\n",
      "Current iteration=1100, loss=0.5701111954541391\n",
      "Current iteration=1200, loss=0.5701111954541391\n",
      "Current iteration=1300, loss=0.5701111954541391\n",
      "Current iteration=1400, loss=0.5701111954541391\n",
      "Current iteration=1500, loss=0.5701111954541391\n",
      "Current iteration=1600, loss=0.5701111954541391\n",
      "Current iteration=1700, loss=0.5701111954541391\n",
      "Current iteration=1800, loss=0.5701111954541391\n",
      "Current iteration=1900, loss=0.5701111954541391\n",
      "Current iteration=0, loss=0.5731233716889256\n",
      "Current iteration=100, loss=0.5740490096696542\n",
      "Current iteration=200, loss=0.5740490096898924\n",
      "Current iteration=300, loss=0.5740490096898924\n",
      "Current iteration=400, loss=0.5740490096898924\n",
      "Current iteration=500, loss=0.5740490096898924\n",
      "Current iteration=600, loss=0.5740490096898924\n",
      "Current iteration=700, loss=0.5740490096898924\n",
      "Current iteration=800, loss=0.5740490096898924\n",
      "Current iteration=900, loss=0.5740490096898924\n",
      "Current iteration=1000, loss=0.5740490096898924\n",
      "Current iteration=1100, loss=0.5740490096898924\n",
      "Current iteration=1200, loss=0.5740490096898924\n",
      "Current iteration=1300, loss=0.5740490096898924\n",
      "Current iteration=1400, loss=0.5740490096898924\n",
      "Current iteration=1500, loss=0.5740490096898924\n",
      "Current iteration=1600, loss=0.5740490096898924\n",
      "Current iteration=1700, loss=0.5740490096898924\n",
      "Current iteration=1800, loss=0.5740490096898924\n",
      "Current iteration=1900, loss=0.5740490096898924\n",
      "Current iteration=0, loss=0.5720551178547613\n",
      "Current iteration=100, loss=0.5683720935519994\n",
      "Current iteration=200, loss=0.5683540210395452\n",
      "Iteration 23\n",
      "Current iteration=0, loss=0.5783491469306018\n",
      "Current iteration=100, loss=0.5924910677412192\n",
      "Current iteration=200, loss=0.5924910677398454\n",
      "Current iteration=300, loss=0.5924910677398454\n",
      "Current iteration=400, loss=0.5924910677398454\n",
      "Current iteration=500, loss=0.5924910677398454\n",
      "Current iteration=600, loss=0.5924910677398454\n",
      "Current iteration=700, loss=0.5924910677398454\n",
      "Current iteration=800, loss=0.5924910677398454\n",
      "Current iteration=900, loss=0.5924910677398454\n",
      "Current iteration=1000, loss=0.5924910677398454\n",
      "Current iteration=1100, loss=0.5924910677398454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1200, loss=0.5924910677398454\n",
      "Current iteration=1300, loss=0.5924910677398454\n",
      "Current iteration=1400, loss=0.5924910677398454\n",
      "Current iteration=1500, loss=0.5924910677398454\n",
      "Current iteration=1600, loss=0.5924910677398454\n",
      "Current iteration=1700, loss=0.5924910677398454\n",
      "Current iteration=1800, loss=0.5924910677398454\n",
      "Current iteration=1900, loss=0.5924910677398454\n",
      "Current iteration=0, loss=0.5897943800827146\n",
      "Current iteration=100, loss=0.5882203460925397\n",
      "Current iteration=200, loss=0.588220346092539\n",
      "Current iteration=300, loss=0.588220346092539\n",
      "Current iteration=400, loss=0.588220346092539\n",
      "Current iteration=500, loss=0.588220346092539\n",
      "Current iteration=600, loss=0.588220346092539\n",
      "Current iteration=700, loss=0.5882203460925391\n",
      "Current iteration=800, loss=0.588220346092539\n",
      "Current iteration=900, loss=0.5882203460925391\n",
      "Current iteration=1000, loss=0.5882203460925391\n",
      "Current iteration=1100, loss=0.5882203460925391\n",
      "Current iteration=1200, loss=0.588220346092539\n",
      "Current iteration=1300, loss=0.588220346092539\n",
      "Current iteration=1400, loss=0.588220346092539\n",
      "Current iteration=1500, loss=0.588220346092539\n",
      "Current iteration=1600, loss=0.5882203460925391\n",
      "Current iteration=1700, loss=0.5882203460925391\n",
      "Current iteration=1800, loss=0.5882203460925391\n",
      "Current iteration=1900, loss=0.588220346092539\n",
      "Current iteration=0, loss=0.590893111208182\n",
      "Current iteration=100, loss=0.5924845062282854\n",
      "Current iteration=200, loss=0.5924845062282855\n",
      "Current iteration=300, loss=0.5924845062282855\n",
      "Current iteration=400, loss=0.5924845062282855\n",
      "Current iteration=500, loss=0.5924845062282855\n",
      "Current iteration=600, loss=0.5924845062282855\n",
      "Current iteration=700, loss=0.5924845062282855\n",
      "Current iteration=800, loss=0.5924845062282855\n",
      "Current iteration=900, loss=0.5924845062282855\n",
      "Current iteration=1000, loss=0.5924845062282855\n",
      "Current iteration=1100, loss=0.5924845062282855\n",
      "Current iteration=1200, loss=0.5924845062282855\n",
      "Current iteration=1300, loss=0.5924845062282855\n",
      "Current iteration=1400, loss=0.5924845062282855\n",
      "Current iteration=1500, loss=0.5924845062282855\n",
      "Current iteration=1600, loss=0.5924845062282855\n",
      "Current iteration=1700, loss=0.5924845062282855\n",
      "Current iteration=1800, loss=0.5924845062282855\n",
      "Current iteration=1900, loss=0.5924845062282855\n",
      "Current iteration=0, loss=0.5893756746776435\n",
      "Current iteration=100, loss=0.5843793500395098\n",
      "Current iteration=200, loss=0.584379350039384\n",
      "Current iteration=300, loss=0.584379350039384\n",
      "Current iteration=400, loss=0.584379350039384\n",
      "Current iteration=500, loss=0.584379350039384\n",
      "Current iteration=600, loss=0.584379350039384\n",
      "Current iteration=700, loss=0.584379350039384\n",
      "Current iteration=800, loss=0.584379350039384\n",
      "Current iteration=900, loss=0.584379350039384\n",
      "Current iteration=1000, loss=0.584379350039384\n",
      "Current iteration=1100, loss=0.584379350039384\n",
      "Current iteration=1200, loss=0.584379350039384\n",
      "Current iteration=1300, loss=0.584379350039384\n",
      "Current iteration=1400, loss=0.584379350039384\n",
      "Current iteration=1500, loss=0.584379350039384\n",
      "Current iteration=1600, loss=0.584379350039384\n",
      "Current iteration=1700, loss=0.584379350039384\n",
      "Current iteration=1800, loss=0.584379350039384\n",
      "Current iteration=1900, loss=0.584379350039384\n",
      "Iteration 24\n",
      "Current iteration=0, loss=0.5984818133262206\n",
      "Current iteration=100, loss=0.6191394330430047\n",
      "Current iteration=200, loss=0.6191394330430047\n",
      "Current iteration=300, loss=0.6191394330430047\n",
      "Current iteration=400, loss=0.6191394330430047\n",
      "Current iteration=500, loss=0.6191394330430047\n",
      "Current iteration=600, loss=0.6191394330430047\n",
      "Current iteration=700, loss=0.6191394330430047\n",
      "Current iteration=800, loss=0.6191394330430047\n",
      "Current iteration=900, loss=0.6191394330430047\n",
      "Current iteration=1000, loss=0.6191394330430047\n",
      "Current iteration=1100, loss=0.6191394330430047\n",
      "Current iteration=1200, loss=0.6191394330430047\n",
      "Current iteration=1300, loss=0.6191394330430047\n",
      "Current iteration=1400, loss=0.6191394330430047\n",
      "Current iteration=1500, loss=0.6191394330430047\n",
      "Current iteration=1600, loss=0.6191394330430047\n",
      "Current iteration=1700, loss=0.6191394330430047\n",
      "Current iteration=1800, loss=0.6191394330430047\n",
      "Current iteration=1900, loss=0.6191394330430047\n",
      "Current iteration=0, loss=0.6164211392398674\n",
      "Current iteration=100, loss=0.6150043679226874\n",
      "Current iteration=200, loss=0.6150043679226874\n",
      "Current iteration=300, loss=0.6150043679226874\n",
      "Current iteration=400, loss=0.6150043679226874\n",
      "Current iteration=500, loss=0.6150043679226874\n",
      "Current iteration=600, loss=0.6150043679226874\n",
      "Current iteration=700, loss=0.6150043679226874\n",
      "Current iteration=800, loss=0.6150043679226874\n",
      "Current iteration=900, loss=0.6150043679226874\n",
      "Current iteration=1000, loss=0.6150043679226874\n",
      "Current iteration=1100, loss=0.6150043679226873\n",
      "Current iteration=1200, loss=0.6150043679226874\n",
      "Current iteration=1300, loss=0.6150043679226874\n",
      "Current iteration=1400, loss=0.6150043679226874\n",
      "Current iteration=1500, loss=0.6150043679226874\n",
      "Current iteration=1600, loss=0.6150043679226873\n",
      "Current iteration=1700, loss=0.6150043679226873\n",
      "Current iteration=1800, loss=0.6150043679226873\n",
      "Current iteration=1900, loss=0.6150043679226873\n",
      "Current iteration=0, loss=0.6173830422189015\n",
      "Current iteration=100, loss=0.6195946723520598\n",
      "Current iteration=200, loss=0.6195946723520598\n",
      "Current iteration=300, loss=0.6195946723520598\n",
      "Current iteration=400, loss=0.6195946723520598\n",
      "Current iteration=500, loss=0.6195946723520598\n",
      "Current iteration=600, loss=0.6195946723520599\n",
      "Current iteration=700, loss=0.6195946723520598\n",
      "Current iteration=800, loss=0.6195946723520598\n",
      "Current iteration=900, loss=0.6195946723520599\n",
      "Current iteration=1000, loss=0.6195946723520598\n",
      "Current iteration=1100, loss=0.6195946723520598\n",
      "Current iteration=1200, loss=0.6195946723520598\n",
      "Current iteration=1300, loss=0.6195946723520598\n",
      "Current iteration=1400, loss=0.6195946723520598\n",
      "Current iteration=1500, loss=0.6195946723520598\n",
      "Current iteration=1600, loss=0.6195946723520598\n",
      "Current iteration=1700, loss=0.6195946723520598\n",
      "Current iteration=1800, loss=0.6195946723520598\n",
      "Current iteration=1900, loss=0.6195946723520598\n",
      "Current iteration=0, loss=0.6149794121233965\n",
      "Current iteration=100, loss=0.6098921447008074\n",
      "Current iteration=200, loss=0.6098921447008074\n",
      "Current iteration=300, loss=0.6098921447008074\n",
      "Current iteration=400, loss=0.6098921447008074\n",
      "Current iteration=500, loss=0.6098921447008074\n",
      "Current iteration=600, loss=0.6098921447008074\n",
      "Current iteration=700, loss=0.6098921447008074\n",
      "Current iteration=800, loss=0.6098921447008074\n",
      "Current iteration=900, loss=0.6098921447008074\n",
      "Current iteration=1000, loss=0.6098921447008074\n",
      "Current iteration=1100, loss=0.6098921447008074\n",
      "Current iteration=1200, loss=0.6098921447008074\n",
      "Current iteration=1300, loss=0.6098921447008074\n",
      "Current iteration=1400, loss=0.6098921447008074\n",
      "Current iteration=1500, loss=0.6098921447008074\n",
      "Current iteration=1600, loss=0.6098921447008074\n",
      "Current iteration=1700, loss=0.6098921447008074\n",
      "Current iteration=1800, loss=0.6098921447008074\n",
      "Current iteration=1900, loss=0.6098921447008074\n",
      "Iteration 25\n",
      "Current iteration=0, loss=0.6330969663532124\n",
      "Current iteration=100, loss=0.6610651809534157\n",
      "Current iteration=200, loss=0.6610651809534157\n",
      "Current iteration=300, loss=0.6610651809534157\n",
      "Current iteration=400, loss=0.6610651809534157\n",
      "Current iteration=500, loss=0.6610651809534157\n",
      "Current iteration=600, loss=0.6610651809534157\n",
      "Current iteration=700, loss=0.6610651809534157\n",
      "Current iteration=800, loss=0.6610651809534157\n",
      "Current iteration=900, loss=0.6610651809534157\n",
      "Current iteration=1000, loss=0.6610651809534157\n",
      "Current iteration=1100, loss=0.6610651809534157\n",
      "Current iteration=1200, loss=0.6610651809534157\n",
      "Current iteration=1300, loss=0.6610651809534157\n",
      "Current iteration=1400, loss=0.6610651809534157\n",
      "Current iteration=1500, loss=0.6610651809534157\n",
      "Current iteration=1600, loss=0.6610651809534157\n",
      "Current iteration=1700, loss=0.6610651809534157\n",
      "Current iteration=1800, loss=0.6610651809534157\n",
      "Current iteration=1900, loss=0.6610651809534157\n",
      "Current iteration=0, loss=0.6581615677586972\n",
      "Current iteration=100, loss=0.6570901402296804\n",
      "Current iteration=200, loss=0.6570901402296804\n",
      "Current iteration=300, loss=0.6570901402296804\n",
      "Current iteration=400, loss=0.6570901402296804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=500, loss=0.6570901402296804\n",
      "Current iteration=600, loss=0.6570901402296804\n",
      "Current iteration=700, loss=0.6570901402296804\n",
      "Current iteration=800, loss=0.6570901402296804\n",
      "Current iteration=900, loss=0.6570901402296804\n",
      "Current iteration=1000, loss=0.6570901402296804\n",
      "Current iteration=1100, loss=0.6570901402296804\n",
      "Current iteration=1200, loss=0.6570901402296804\n",
      "Current iteration=1300, loss=0.6570901402296804\n",
      "Current iteration=1400, loss=0.6570901402296804\n",
      "Current iteration=1500, loss=0.6570901402296804\n",
      "Current iteration=1600, loss=0.6570901402296804\n",
      "Current iteration=1700, loss=0.6570901402296804\n",
      "Current iteration=1800, loss=0.6570901402296804\n",
      "Current iteration=1900, loss=0.6570901402296804\n",
      "Current iteration=0, loss=0.6593558066188273\n",
      "Current iteration=100, loss=0.6621331697617637\n",
      "Current iteration=200, loss=0.6621331697617637\n",
      "Current iteration=300, loss=0.6621331697617637\n",
      "Current iteration=400, loss=0.6621331697617637\n",
      "Current iteration=500, loss=0.6621331697617637\n",
      "Current iteration=600, loss=0.6621331697617637\n",
      "Current iteration=700, loss=0.6621331697617637\n",
      "Current iteration=800, loss=0.6621331697617637\n",
      "Current iteration=900, loss=0.6621331697617637\n",
      "Current iteration=1000, loss=0.6621331697617637\n",
      "Current iteration=1100, loss=0.6621331697617637\n",
      "Current iteration=1200, loss=0.6621331697617637\n",
      "Current iteration=1300, loss=0.6621331697617637\n",
      "Current iteration=1400, loss=0.6621331697617637\n",
      "Current iteration=1500, loss=0.6621331697617637\n",
      "Current iteration=1600, loss=0.6621331697617637\n",
      "Current iteration=1700, loss=0.6621331697617637\n",
      "Current iteration=1800, loss=0.6621331697617637\n",
      "Current iteration=1900, loss=0.6621331697617637\n",
      "Current iteration=0, loss=0.6555126019213868\n",
      "Current iteration=100, loss=0.6499990171488649\n",
      "Current iteration=200, loss=0.6499990171488649\n",
      "Current iteration=300, loss=0.6499990171488649\n",
      "Current iteration=400, loss=0.6499990171488649\n",
      "Current iteration=500, loss=0.6499990171488649\n",
      "Current iteration=600, loss=0.6499990171488649\n",
      "Current iteration=700, loss=0.6499990171488649\n",
      "Current iteration=800, loss=0.6499990171488649\n",
      "Current iteration=900, loss=0.6499990171488649\n",
      "Current iteration=1000, loss=0.6499990171488649\n",
      "Current iteration=1100, loss=0.6499990171488649\n",
      "Current iteration=1200, loss=0.6499990171488649\n",
      "Current iteration=1300, loss=0.6499990171488649\n",
      "Current iteration=1400, loss=0.6499990171488649\n",
      "Current iteration=1500, loss=0.6499990171488649\n",
      "Current iteration=1600, loss=0.6499990171488649\n",
      "Current iteration=1700, loss=0.6499990171488649\n",
      "Current iteration=1800, loss=0.6499990171488649\n",
      "Current iteration=1900, loss=0.6499990171488649\n",
      "Iteration 26\n",
      "Current iteration=0, loss=0.6926487511266769\n",
      "Current iteration=100, loss=0.7368505538977996\n",
      "Current iteration=200, loss=0.7368505538977996\n",
      "Current iteration=300, loss=0.7368505538977996\n",
      "Current iteration=400, loss=0.7368505538977996\n",
      "Current iteration=500, loss=0.7368505538977996\n",
      "Current iteration=600, loss=0.7368505538977996\n",
      "Current iteration=700, loss=0.7368505538977996\n",
      "Current iteration=800, loss=0.7368505538977996\n",
      "Current iteration=900, loss=0.7368505538977996\n",
      "Current iteration=1000, loss=0.7368505538977996\n",
      "Current iteration=1100, loss=0.7368505538977996\n",
      "Current iteration=1200, loss=0.7368505538977996\n",
      "Current iteration=1300, loss=0.7368505538977996\n",
      "Current iteration=1400, loss=0.7368505538977996\n",
      "Current iteration=1500, loss=0.7368505538977996\n",
      "Current iteration=1600, loss=0.7368505538977996\n",
      "Current iteration=1700, loss=0.7368505538977996\n",
      "Current iteration=1800, loss=0.7368505538977996\n",
      "Current iteration=1900, loss=0.7368505538977996\n",
      "Current iteration=0, loss=0.7335848667384346\n",
      "Current iteration=100, loss=0.7329569251615853\n",
      "Current iteration=200, loss=0.7329569251615853\n",
      "Current iteration=300, loss=0.7329569251615853\n",
      "Current iteration=400, loss=0.7329569251615853\n",
      "Current iteration=500, loss=0.7329569251615853\n",
      "Current iteration=600, loss=0.7329569251615851\n",
      "Current iteration=700, loss=0.7329569251615853\n",
      "Current iteration=800, loss=0.7329569251615853\n",
      "Current iteration=900, loss=0.7329569251615853\n",
      "Current iteration=1000, loss=0.7329569251615853\n",
      "Current iteration=1100, loss=0.7329569251615853\n",
      "Current iteration=1200, loss=0.7329569251615853\n",
      "Current iteration=1300, loss=0.7329569251615853\n",
      "Current iteration=1400, loss=0.7329569251615851\n",
      "Current iteration=1500, loss=0.7329569251615853\n",
      "Current iteration=1600, loss=0.7329569251615853\n",
      "Current iteration=1700, loss=0.7329569251615853\n",
      "Current iteration=1800, loss=0.7329569251615853\n",
      "Current iteration=1900, loss=0.7329569251615853\n",
      "Current iteration=0, loss=0.7351318786312382\n",
      "Current iteration=100, loss=0.7385340649732598\n",
      "Current iteration=200, loss=0.7385340649732598\n",
      "Current iteration=300, loss=0.7385340649732597\n",
      "Current iteration=400, loss=0.7385340649732598\n",
      "Current iteration=500, loss=0.7385340649732595\n",
      "Current iteration=600, loss=0.7385340649732598\n",
      "Current iteration=700, loss=0.7385340649732597\n",
      "Current iteration=800, loss=0.7385340649732597\n",
      "Current iteration=900, loss=0.7385340649732597\n",
      "Current iteration=1000, loss=0.7385340649732597\n",
      "Current iteration=1100, loss=0.7385340649732597\n",
      "Current iteration=1200, loss=0.7385340649732598\n",
      "Current iteration=1300, loss=0.7385340649732598\n",
      "Current iteration=1400, loss=0.7385340649732597\n",
      "Current iteration=1500, loss=0.7385340649732595\n",
      "Current iteration=1600, loss=0.7385340649732598\n",
      "Current iteration=1700, loss=0.7385340649732598\n",
      "Current iteration=1800, loss=0.7385340649732597\n",
      "Current iteration=1900, loss=0.7385340649732597\n",
      "Current iteration=0, loss=0.7290930778213137\n",
      "Current iteration=100, loss=0.7225622974202771\n",
      "Current iteration=200, loss=0.7225622974202771\n",
      "Current iteration=300, loss=0.7225622974202771\n",
      "Current iteration=400, loss=0.722562297420277\n",
      "Current iteration=500, loss=0.722562297420277\n",
      "Current iteration=600, loss=0.7225622974202771\n",
      "Current iteration=700, loss=0.7225622974202771\n",
      "Current iteration=800, loss=0.7225622974202771\n",
      "Current iteration=900, loss=0.722562297420277\n",
      "Current iteration=1000, loss=0.7225622974202771\n",
      "Current iteration=1100, loss=0.7225622974202771\n",
      "Current iteration=1200, loss=0.7225622974202771\n",
      "Current iteration=1300, loss=0.7225622974202771\n",
      "Current iteration=1400, loss=0.7225622974202771\n",
      "Current iteration=1500, loss=0.7225622974202771\n",
      "Current iteration=1600, loss=0.7225622974202771\n",
      "Current iteration=1700, loss=0.7225622974202771\n",
      "Current iteration=1800, loss=0.7225622974202771\n",
      "Current iteration=1900, loss=0.7225622974202771\n",
      "Iteration 27\n",
      "Current iteration=0, loss=0.8139804930890985\n",
      "Current iteration=100, loss=0.9034612853153292\n",
      "Current iteration=200, loss=0.9034612853153292\n",
      "Current iteration=300, loss=0.9034612853153292\n",
      "Current iteration=400, loss=0.9034612853153292\n",
      "Current iteration=500, loss=0.9034612853153292\n",
      "Current iteration=600, loss=0.9034612853153292\n",
      "Current iteration=700, loss=0.9034612853153292\n",
      "Current iteration=800, loss=0.9034612853153292\n",
      "Current iteration=900, loss=0.9034612853153292\n",
      "Current iteration=1000, loss=0.9034612853153292\n",
      "Current iteration=1100, loss=0.9034612853153292\n",
      "Current iteration=1200, loss=0.9034612853153292\n",
      "Current iteration=1300, loss=0.9034612853153292\n",
      "Current iteration=1400, loss=0.9034612853153292\n",
      "Current iteration=1500, loss=0.9034612853153292\n",
      "Current iteration=1600, loss=0.9034612853153292\n",
      "Current iteration=1700, loss=0.9034612853153292\n",
      "Current iteration=1800, loss=0.9034612853153292\n",
      "Current iteration=1900, loss=0.9034612853153292\n",
      "Current iteration=0, loss=0.8998444432922956\n",
      "Current iteration=100, loss=0.8998801566885586\n",
      "Current iteration=200, loss=0.8998801566885586\n",
      "Current iteration=300, loss=0.8998801566885586\n",
      "Current iteration=400, loss=0.8998801566885586\n",
      "Current iteration=500, loss=0.8998801566885586\n",
      "Current iteration=600, loss=0.8998801566885586\n",
      "Current iteration=700, loss=0.8998801566885586\n",
      "Current iteration=800, loss=0.8998801566885586\n",
      "Current iteration=900, loss=0.8998801566885586\n",
      "Current iteration=1000, loss=0.8998801566885586\n",
      "Current iteration=1100, loss=0.8998801566885586\n",
      "Current iteration=1200, loss=0.8998801566885586\n",
      "Current iteration=1300, loss=0.8998801566885586\n",
      "Current iteration=1400, loss=0.8998801566885586\n",
      "Current iteration=1500, loss=0.8998801566885586\n",
      "Current iteration=1600, loss=0.8998801566885586\n",
      "Current iteration=1700, loss=0.8998801566885586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1800, loss=0.8998801566885586\n",
      "Current iteration=1900, loss=0.8998801566885586\n",
      "Current iteration=0, loss=0.9015598520968873\n",
      "Current iteration=100, loss=0.9062051010918881\n",
      "Current iteration=200, loss=0.9062051010918881\n",
      "Current iteration=300, loss=0.9062051010918881\n",
      "Current iteration=400, loss=0.9062051010918881\n",
      "Current iteration=500, loss=0.9062051010918881\n",
      "Current iteration=600, loss=0.9062051010918881\n",
      "Current iteration=700, loss=0.9062051010918881\n",
      "Current iteration=800, loss=0.9062051010918881\n",
      "Current iteration=900, loss=0.9062051010918881\n",
      "Current iteration=1000, loss=0.9062051010918881\n",
      "Current iteration=1100, loss=0.9062051010918881\n",
      "Current iteration=1200, loss=0.9062051010918881\n",
      "Current iteration=1300, loss=0.9062051010918881\n",
      "Current iteration=1400, loss=0.9062051010918881\n",
      "Current iteration=1500, loss=0.9062051010918881\n",
      "Current iteration=1600, loss=0.9062051010918881\n",
      "Current iteration=1700, loss=0.9062051010918881\n",
      "Current iteration=1800, loss=0.9062051010918881\n",
      "Current iteration=1900, loss=0.9062051010918881\n",
      "Current iteration=0, loss=0.8931098992589894\n",
      "Current iteration=100, loss=0.8844729305459889\n",
      "Current iteration=200, loss=0.8844729305459889\n",
      "Current iteration=300, loss=0.8844729305459889\n",
      "Current iteration=400, loss=0.8844729305459889\n",
      "Current iteration=500, loss=0.8844729305459889\n",
      "Current iteration=600, loss=0.8844729305459889\n",
      "Current iteration=700, loss=0.8844729305459889\n",
      "Current iteration=800, loss=0.8844729305459889\n",
      "Current iteration=900, loss=0.8844729305459889\n",
      "Current iteration=1000, loss=0.8844729305459889\n",
      "Current iteration=1100, loss=0.8844729305459889\n",
      "Current iteration=1200, loss=0.8844729305459889\n",
      "Current iteration=1300, loss=0.8844729305459889\n",
      "Current iteration=1400, loss=0.8844729305459889\n",
      "Current iteration=1500, loss=0.8844729305459889\n",
      "Current iteration=1600, loss=0.8844729305459889\n",
      "Current iteration=1700, loss=0.8844729305459889\n",
      "Current iteration=1800, loss=0.8844729305459889\n",
      "Current iteration=1900, loss=0.8844729305459889\n",
      "Iteration 28\n",
      "Current iteration=0, loss=1.1295725306922866\n",
      "Current iteration=100, loss=1.3853835504271785\n",
      "Current iteration=200, loss=1.3853835504271783\n",
      "Current iteration=300, loss=1.3853835504271783\n",
      "Current iteration=400, loss=1.3853835504271783\n",
      "Current iteration=500, loss=1.3853835504271783\n",
      "Current iteration=600, loss=1.3853835504271783\n",
      "Current iteration=700, loss=1.3853835504271783\n",
      "Current iteration=800, loss=1.3853835504271783\n",
      "Current iteration=900, loss=1.3853835504271783\n",
      "Current iteration=1000, loss=1.3853835504271783\n",
      "Current iteration=1100, loss=1.3853835504271783\n",
      "Current iteration=1200, loss=1.3853835504271783\n",
      "Current iteration=1300, loss=1.3853835504271783\n",
      "Current iteration=1400, loss=1.3853835504271783\n",
      "Current iteration=1500, loss=1.3853835504271783\n",
      "Current iteration=1600, loss=1.3853835504271783\n",
      "Current iteration=1700, loss=1.3853835504271783\n",
      "Current iteration=1800, loss=1.3853835504271783\n",
      "Current iteration=1900, loss=1.3853835504271783\n",
      "Current iteration=0, loss=1.382767656167743\n",
      "Current iteration=100, loss=1.3840485074656668\n",
      "Current iteration=200, loss=1.3840485074656668\n",
      "Current iteration=300, loss=1.3840485074656665\n",
      "Current iteration=400, loss=1.3840485074656665\n",
      "Current iteration=500, loss=1.3840485074656665\n",
      "Current iteration=600, loss=1.3840485074656665\n",
      "Current iteration=700, loss=1.3840485074656665\n",
      "Current iteration=800, loss=1.3840485074656665\n",
      "Current iteration=900, loss=1.3840485074656665\n",
      "Current iteration=1000, loss=1.3840485074656665\n",
      "Current iteration=1100, loss=1.3840485074656665\n",
      "Current iteration=1200, loss=1.3840485074656665\n",
      "Current iteration=1300, loss=1.3840485074656665\n",
      "Current iteration=1400, loss=1.3840485074656665\n",
      "Current iteration=1500, loss=1.3840485074656665\n",
      "Current iteration=1600, loss=1.3840485074656665\n",
      "Current iteration=1700, loss=1.3840485074656665\n",
      "Current iteration=1800, loss=1.3840485074656665\n",
      "Current iteration=1900, loss=1.3840485074656665\n",
      "Current iteration=0, loss=1.3831739801601834\n",
      "Current iteration=100, loss=1.390777892133176\n",
      "Current iteration=200, loss=1.390777892133176\n",
      "Current iteration=300, loss=1.390777892133176\n",
      "Current iteration=400, loss=1.390777892133176\n",
      "Current iteration=500, loss=1.390777892133176\n",
      "Current iteration=600, loss=1.390777892133176\n",
      "Current iteration=700, loss=1.390777892133176\n",
      "Current iteration=800, loss=1.390777892133176\n",
      "Current iteration=900, loss=1.390777892133176\n",
      "Current iteration=1000, loss=1.390777892133176\n",
      "Current iteration=1100, loss=1.390777892133176\n",
      "Current iteration=1200, loss=1.390777892133176\n",
      "Current iteration=1300, loss=1.390777892133176\n",
      "Current iteration=1400, loss=1.390777892133176\n",
      "Current iteration=1500, loss=1.390777892133176\n",
      "Current iteration=1600, loss=1.390777892133176\n",
      "Current iteration=1700, loss=1.390777892133176\n",
      "Current iteration=1800, loss=1.390777892133176\n",
      "Current iteration=1900, loss=1.390777892133176\n",
      "Current iteration=0, loss=1.3706891436594226\n",
      "Current iteration=100, loss=1.3566975273753306\n",
      "Current iteration=200, loss=1.3566975273753303\n",
      "Current iteration=300, loss=1.3566975273753303\n",
      "Current iteration=400, loss=1.3566975273753303\n",
      "Current iteration=500, loss=1.3566975273753303\n",
      "Current iteration=600, loss=1.3566975273753303\n",
      "Current iteration=700, loss=1.3566975273753303\n",
      "Current iteration=800, loss=1.3566975273753303\n",
      "Current iteration=900, loss=1.3566975273753303\n",
      "Current iteration=1000, loss=1.3566975273753303\n",
      "Current iteration=1100, loss=1.3566975273753303\n",
      "Current iteration=1200, loss=1.3566975273753303\n",
      "Current iteration=1300, loss=1.3566975273753303\n",
      "Current iteration=1400, loss=1.3566975273753303\n",
      "Current iteration=1500, loss=1.3566975273753303\n",
      "Current iteration=1600, loss=1.3566975273753303\n",
      "Current iteration=1700, loss=1.3566975273753303\n",
      "Current iteration=1800, loss=1.3566975273753303\n",
      "Current iteration=1900, loss=1.3566975273753303\n",
      "Iteration 29\n",
      "Current iteration=0, loss=2.2328752544592243\n",
      "Current iteration=100, loss=3.635019074593141\n",
      "Current iteration=200, loss=3.6350190746049442\n",
      "Current iteration=300, loss=3.6350190746049442\n",
      "Current iteration=400, loss=3.6350190746049442\n",
      "Current iteration=500, loss=3.6350190746049442\n",
      "Current iteration=600, loss=3.6350190746049442\n",
      "Current iteration=700, loss=3.6350190746049442\n",
      "Current iteration=800, loss=3.6350190746049442\n",
      "Current iteration=900, loss=3.6350190746049442\n",
      "Current iteration=1000, loss=3.6350190746049442\n",
      "Current iteration=1100, loss=3.6350190746049442\n",
      "Current iteration=1200, loss=3.6350190746049442\n",
      "Current iteration=1300, loss=3.6350190746049442\n",
      "Current iteration=1400, loss=3.6350190746049442\n",
      "Current iteration=1500, loss=3.6350190746049442\n",
      "Current iteration=1600, loss=3.6350190746049442\n",
      "Current iteration=1700, loss=3.6350190746049442\n",
      "Current iteration=1800, loss=3.6350190746049442\n",
      "Current iteration=1900, loss=3.6350190746049442\n",
      "Current iteration=0, loss=3.635337812188763\n",
      "Current iteration=100, loss=3.643173440342485\n",
      "Current iteration=200, loss=3.643173440339221\n",
      "Current iteration=300, loss=3.643173440339221\n",
      "Current iteration=400, loss=3.643173440339221\n",
      "Current iteration=500, loss=3.643173440339221\n",
      "Current iteration=600, loss=3.643173440339221\n",
      "Current iteration=700, loss=3.643173440339221\n",
      "Current iteration=800, loss=3.643173440339221\n",
      "Current iteration=900, loss=3.643173440339221\n",
      "Current iteration=1000, loss=3.643173440339221\n",
      "Current iteration=1100, loss=3.643173440339221\n",
      "Current iteration=1200, loss=3.643173440339221\n",
      "Current iteration=1300, loss=3.643173440339221\n",
      "Current iteration=1400, loss=3.643173440339221\n",
      "Current iteration=1500, loss=3.643173440339221\n",
      "Current iteration=1600, loss=3.643173440339221\n",
      "Current iteration=1700, loss=3.643173440339221\n",
      "Current iteration=1800, loss=3.643173440339221\n",
      "Current iteration=1900, loss=3.643173440339221\n",
      "Current iteration=0, loss=3.6301721079467058\n",
      "Current iteration=100, loss=3.6448128233492736\n",
      "Current iteration=200, loss=3.644812823378978\n",
      "Current iteration=300, loss=3.644812823378978\n",
      "Current iteration=400, loss=3.644812823378978\n",
      "Current iteration=500, loss=3.644812823378978\n",
      "Current iteration=600, loss=3.644812823378978\n",
      "Current iteration=700, loss=3.644812823378978\n",
      "Current iteration=800, loss=3.644812823378978\n",
      "Current iteration=900, loss=3.644812823378978\n",
      "Current iteration=1000, loss=3.644812823378978\n",
      "Current iteration=1100, loss=3.644812823378978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=1200, loss=3.644812823378978\n",
      "Current iteration=1300, loss=3.644812823378978\n",
      "Current iteration=1400, loss=3.644812823378978\n",
      "Current iteration=1500, loss=3.644812823378978\n",
      "Current iteration=1600, loss=3.644812823378978\n",
      "Current iteration=1700, loss=3.644812823378978\n",
      "Current iteration=1800, loss=3.644812823378978\n",
      "Current iteration=1900, loss=3.644812823378978\n",
      "Current iteration=0, loss=3.6074820923598656\n",
      "Current iteration=100, loss=3.5701763569148643\n",
      "Current iteration=200, loss=3.5701763568925013\n",
      "Current iteration=300, loss=3.5701763568925013\n",
      "Current iteration=400, loss=3.5701763568925013\n",
      "Current iteration=500, loss=3.5701763568925013\n",
      "Current iteration=600, loss=3.5701763568925013\n",
      "Current iteration=700, loss=3.5701763568925013\n",
      "Current iteration=800, loss=3.5701763568925013\n",
      "Current iteration=900, loss=3.5701763568925013\n",
      "Current iteration=1000, loss=3.5701763568925013\n",
      "Current iteration=1100, loss=3.5701763568925013\n",
      "Current iteration=1200, loss=3.5701763568925013\n",
      "Current iteration=1300, loss=3.5701763568925013\n",
      "Current iteration=1400, loss=3.5701763568925013\n",
      "Current iteration=1500, loss=3.5701763568925013\n",
      "Current iteration=1600, loss=3.5701763568925013\n",
      "Current iteration=1700, loss=3.5701763568925013\n",
      "Current iteration=1800, loss=3.5701763568925013\n",
      "Current iteration=1900, loss=3.5701763568925013\n"
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    optimal_lambda = logistic_optimal_lambda(y_logistic, standardized_dset, initial_w, max_iters, gamma)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00013738237958832623, 0.0001, 0.0001]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree 3 polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00013738237958832623, 0.00013738237958832623, 0.00013738237958832623]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.0001, 0.0001]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5836319739997964\n",
      "Current iteration=100, loss=0.38299140175875035\n",
      "Current iteration=200, loss=0.37803365822497376\n",
      "Current iteration=300, loss=0.37645182879044486\n",
      "Current iteration=400, loss=0.3757436234372618\n",
      "Current iteration=500, loss=0.3753383539575887\n",
      "Current iteration=600, loss=0.37504392132409753\n",
      "Current iteration=700, loss=0.3747993795321187\n",
      "Current iteration=800, loss=0.3745825514463692\n",
      "Current iteration=900, loss=0.3743843054702021\n",
      "Current iteration=1000, loss=0.3742003263408803\n",
      "Current iteration=1100, loss=0.3740282770401534\n",
      "Current iteration=1200, loss=0.37386669992413457\n",
      "Current iteration=1300, loss=0.37371456864327324\n",
      "Current iteration=1400, loss=0.37357109541035727\n",
      "Current iteration=1500, loss=0.3734356423191489\n",
      "Current iteration=1600, loss=0.3733076760382906\n",
      "Current iteration=1700, loss=0.37320222103428036\n",
      "Current iteration=1800, loss=0.3731331670545731\n",
      "Current iteration=1900, loss=0.3730784831660644\n",
      "Current iteration=0, loss=0.6214390936229288\n",
      "Current iteration=100, loss=0.4982530496962079\n",
      "Current iteration=200, loss=0.48993165127197424\n",
      "Current iteration=300, loss=0.4858267813931224\n",
      "Current iteration=400, loss=0.4834515013754209\n",
      "Current iteration=500, loss=0.4819422400515691\n",
      "Current iteration=600, loss=0.48092240761578864\n",
      "Current iteration=700, loss=0.4801964525166599\n",
      "Current iteration=800, loss=0.4796556513136122\n",
      "Current iteration=900, loss=0.479236541006507\n",
      "Current iteration=1000, loss=0.47890051162027103\n",
      "Current iteration=1100, loss=0.47862324433361325\n",
      "Current iteration=1200, loss=0.4783889372481233\n",
      "Current iteration=1300, loss=0.4781870106577929\n",
      "Current iteration=1400, loss=0.4780102125410273\n",
      "Current iteration=1500, loss=0.4778535468206434\n",
      "Current iteration=1600, loss=0.47771357420627736\n",
      "Current iteration=1700, loss=0.477587743602448\n",
      "Current iteration=1800, loss=0.47747392012112067\n",
      "Current iteration=1900, loss=0.47737029324616476\n",
      "Current iteration=0, loss=0.563132101232646\n",
      "Current iteration=100, loss=0.4926735182964259\n",
      "Current iteration=200, loss=0.4811322959824088\n",
      "Current iteration=300, loss=0.4751097733315286\n",
      "Current iteration=400, loss=0.4715085830931237\n",
      "Current iteration=500, loss=0.4691903113374064\n",
      "Current iteration=600, loss=0.4676222659881502\n",
      "Current iteration=700, loss=0.46652856135481924\n",
      "Current iteration=800, loss=0.4657412929939137\n",
      "Current iteration=900, loss=0.4651560380431964\n",
      "Current iteration=1000, loss=0.46470787073015074\n",
      "Current iteration=1100, loss=0.4643551679871395\n",
      "Current iteration=1200, loss=0.4640705227205961\n",
      "Current iteration=1300, loss=0.463835488647547\n",
      "Current iteration=1400, loss=0.46363743099947224\n",
      "Current iteration=1500, loss=0.4634675657587149\n",
      "Current iteration=1600, loss=0.4633196909618907\n",
      "Current iteration=1700, loss=0.4631893474324072\n",
      "Current iteration=1800, loss=0.46307326294936213\n",
      "Current iteration=1900, loss=0.4629689855403567\n"
     ]
    }
   ],
   "source": [
    "ws_RLR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    loss, w_RLR = reg_logistic_regression(y_logistic, standardized_dset, lambdas[jet_num], initial_w, max_iters, gamma)\n",
    "    ws_RLR.append(w_RLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_RLR, pri_jet_num_idx, clean_features, parameters, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80052\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree 3 polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8017799999999999\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
