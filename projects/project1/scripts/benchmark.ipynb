{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, predictions):\n",
    "    N = y.size\n",
    "    accuracy = 1 - (np.count_nonzero(predictions-y)/N)\n",
    "    print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(weights, clean_features, parameters):\n",
    "    np.save('all/weights.npy', weights)\n",
    "    np.save('all/clean_features.npy', clean_features)\n",
    "    np.save('all/parameters.npy', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   3.,   4.,   4.,   9.,  16.,   8.,  27.,  64.],\n",
       "       [  1.,   5.,   6.,   7.,  25.,  36.,  49., 125., 216., 343.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[1,2,3,4],[1,5,6,7]])\n",
    "build_poly(test[:,1:], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Without feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'all/train.csv'\n",
    "labels, input_data, ids, features = load_csv_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis',\n",
       "       'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot',\n",
       "       'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta',\n",
       "       'PRI_tau_phi', 'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi',\n",
       "       'PRI_met', 'PRI_met_phi', 'PRI_met_sumet', 'PRI_jet_num',\n",
       "       'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi',\n",
       "       'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta',\n",
       "       'PRI_jet_subleading_phi', 'PRI_jet_all_pt'], dtype='<U27')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_tr, mean_tr, std_tr = extend_and_standardize(x_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:70: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:6: RuntimeWarning: overflow encountered in square\n",
      "  return 1/2*np.mean(e**2)\n"
     ]
    }
   ],
   "source": [
    "losses_GD, ws_GD = least_squares_GD(y_tr, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in greater\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/julien/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in less_equal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "predictions_GD = predict_labels(w_GD,x_te)\n",
    "compute_accuracy(y_te,predictions_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_LS = least_squares(y_tr,x_tr)\n",
    "predictions = predict_labels(w_LS,x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74402\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_te, _, _ = extend_and_standardize(x_te, mean_tr, std_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, w_LS = least_squares(y_tr,tx_tr)\n",
    "predictions = predict_labels(w_LS,tx_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74468\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross-validation to find good hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k_fold = 4\n",
    "k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "lambda_ = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "lambdas, tr_losses, te_losses = find_optimal_lambda(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "optimal_lambda = find_optimal_lambda(y_tr,x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rr = ridge_regression(y_tr,x_tr,optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004520353656360241"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_labels(w_rr,x_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7453000000000001\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(x_tr.shape[1])\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "y_tr_log = np.ones(y_tr.size)\n",
    "y_tr_log[y_tr == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_logistic = logistic_regression(y_tr_log, x_tr, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876599999999999\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_labels(w_logistic, x_te)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n"
     ]
    }
   ],
   "source": [
    "loss, w_reg_logistic = reg_logistic_regression(y_tr_log, x_tr, optimal_lambda, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7079599999999999\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_labels(w_reg_logistic, x_te)\n",
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: EDA and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'all/train.csv'\n",
    "labels, input_data, ids, features = load_csv_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = split_data(input_data, labels, training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = x_tr, y_tr  # input_data, labels\n",
    "\n",
    "i, = np.where(features == 'PRI_jet_num')\n",
    "pri_jet_num_idx = np.squeeze(i)\n",
    "cond_null = X[:, pri_jet_num_idx] == 0\n",
    "cond_one = X[:, pri_jet_num_idx] == 1\n",
    "cond_plural = X[:, pri_jet_num_idx] >= 2\n",
    "conditions = [cond_null, cond_one, cond_plural]\n",
    "\n",
    "dsets = [X[cond] for cond in conditions]\n",
    "ybs = [y[cond] for cond in conditions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, just remove any column with undefined -999 values. Also, before standardization, remove features with 0 variance. \n",
    "Second part: test how replacing -999 in DER_mass_MMC by defined mean affects the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dsets = []\n",
    "clean_features = []\n",
    "\n",
    "for dset in dsets:\n",
    "    \n",
    "    # Impute undefined DER_mass_MMC\n",
    "    \"\"\"\n",
    "    DER_mass_MMC = dset[:,0]\n",
    "    undefined_indices = (DER_mass_MMC == -999)\n",
    "    filter_undefined = DER_mass_MMC[~undefined_indices]\n",
    "    defined_mean = np.mean(filter_undefined)\n",
    "    print(defined_mean)\n",
    "    defined_median = np.median(filter_undefined)\n",
    "    print(defined_median)\n",
    "    DER_mass_MMC[undefined_indices] = defined_median\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove constant features and features with undefined samples\n",
    "    no_undefined = np.all(dset != -999, axis = 0)\n",
    "    no_constant = np.any(dset != dset[0], axis = 0)\n",
    "    cleaned = no_undefined * no_constant\n",
    "    clean_dset = dset[:,cleaned]\n",
    "    clean_dsets.append(clean_dset)\n",
    "    clean_features.append(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize and extend data, save mean and standard deviation of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = []\n",
    "standardized_dsets = []\n",
    "\n",
    "for clean_dset in clean_dsets:\n",
    "    extended_dset = build_poly(clean_dset, 3)\n",
    "    standardized_dset, mean_x, std_x = extend_and_standardize(extended_dset[:,1:])\n",
    "    # standardized_dset, mean_x, std_x = extend_and_standardize(clean_dset)\n",
    "    # Added for testing purposes, handles outliers\n",
    "    \"\"\"\n",
    "    standardized_dset[standardized_dset > 3] = 3\n",
    "    standardized_dset[standardized_dset < -3]  = -3\n",
    "    \"\"\"\n",
    "    # Polynomial expansion\n",
    "    # standardized_dset = build_poly(standardized_dset[:,1:], 3)\n",
    "    standardized_dsets.append(standardized_dset)\n",
    "    parameters.append((mean_x,std_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only extend datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ws_GD = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    losses_GD, w_GD = least_squares_GD(ybs[jet_num], standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_GD.append(w_GD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_GD, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75998\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72386\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: bit worse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72848\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 1000\n",
    "gamma = 0.1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_SGD = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    loss_SGD, w_SGD = least_squares_SGD(ybs[jet_num], standardized_dset, initial_w, batch_size, max_iters, gamma)\n",
    "    ws_SGD.append(w_SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_SGD, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75512\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_LS = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    loss, w = least_squares(ybs[jet_num],standardized_dset)\n",
    "    ws_LS.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_LS, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79222\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75986\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7598\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76336\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_LS = []\n",
    "for jet_num, extended_dset in enumerate(extended_dsets):\n",
    "    loss, w = least_squares(ybs[jet_num],extended_dset)\n",
    "    ws_LS.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76336\n"
     ]
    }
   ],
   "source": [
    "predictions = model_predictions(x_te, ws_LS, pri_jet_num_idx, clean_features, parameters)\n",
    "compute_accuracy(y_te, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n"
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    optimal_lambda = ridge_optimal_lambda(ybs[jet_num], standardized_dset)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_RR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    w_RR = ridge_regression(ybs[jet_num],standardized_dset,lambdas[jet_num])\n",
    "    ws_RR.append(w_RR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_RR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6776\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_RR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75988\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75992\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5836174146430618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n",
      "Current iteration=900, loss=nan\n",
      "Current iteration=1000, loss=nan\n",
      "Current iteration=1100, loss=nan\n",
      "Current iteration=1200, loss=nan\n",
      "Current iteration=1300, loss=nan\n",
      "Current iteration=1400, loss=nan\n",
      "Current iteration=1500, loss=nan\n",
      "Current iteration=1600, loss=nan\n",
      "Current iteration=1700, loss=nan\n",
      "Current iteration=1800, loss=nan\n",
      "Current iteration=1900, loss=nan\n",
      "Current iteration=0, loss=0.6214271156124798\n",
      "Current iteration=100, loss=0.4975096661324537\n",
      "Current iteration=200, loss=0.4886285318645617\n",
      "Current iteration=300, loss=0.48404018991788084\n",
      "Current iteration=400, loss=0.48125344293360034\n",
      "Current iteration=500, loss=0.47939747174224556\n",
      "Current iteration=600, loss=0.47808464272880336\n",
      "Current iteration=700, loss=0.4771075602050127\n",
      "Current iteration=800, loss=0.4763478781915445\n",
      "Current iteration=900, loss=0.4757347272316412\n",
      "Current iteration=1000, loss=0.4752239434379351\n",
      "Current iteration=1100, loss=0.47478711988144057\n",
      "Current iteration=1200, loss=0.4744053940994833\n",
      "Current iteration=1300, loss=0.47406595250303846\n",
      "Current iteration=1400, loss=0.47376034484515434\n",
      "Current iteration=1500, loss=0.4734828120367118\n",
      "Current iteration=1600, loss=0.47322837174207577\n",
      "Current iteration=1700, loss=0.47299272239203294\n",
      "Current iteration=1800, loss=0.47277246352249697\n",
      "Current iteration=1900, loss=0.4725649603632951\n",
      "Current iteration=0, loss=0.5631037862458238\n",
      "Current iteration=100, loss=0.49199305116657094\n",
      "Current iteration=200, loss=0.4797179364644475\n",
      "Current iteration=300, loss=0.47300907327732494\n",
      "Current iteration=400, loss=0.46880369367820185\n",
      "Current iteration=500, loss=0.46596318616486315\n",
      "Current iteration=600, loss=0.4639481483762245\n",
      "Current iteration=700, loss=0.4624729667531535\n",
      "Current iteration=800, loss=0.4613557504513534\n",
      "Current iteration=900, loss=0.46048196267866004\n",
      "Current iteration=1000, loss=0.45977840420453525\n",
      "Current iteration=1100, loss=0.45919663953673956\n",
      "Current iteration=1200, loss=0.45870387171214\n",
      "Current iteration=1300, loss=0.4582776382569207\n",
      "Current iteration=1400, loss=0.4579023593979651\n",
      "Current iteration=1500, loss=0.45756698270744106\n",
      "Current iteration=1600, loss=0.45726346476409463\n",
      "Current iteration=1700, loss=0.4569858223213848\n",
      "Current iteration=1800, loss=0.4567295236148463\n",
      "Current iteration=1900, loss=0.45649108175746567\n"
     ]
    }
   ],
   "source": [
    "ws_LR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    loss, w_LR = logistic_regression(y_logistic, standardized_dset, initial_w, max_iters, gamma)\n",
    "    ws_LR.append(w_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_LR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80266\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(ws_RR, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76258\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76196\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76416\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n",
      "/home/julien/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py:116: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = (-y * np.log(pred) - (1 - y) * np.log(1 - pred)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=nan\n",
      "Current iteration=100, loss=nan\n",
      "Current iteration=200, loss=nan\n",
      "Current iteration=300, loss=nan\n",
      "Current iteration=400, loss=nan\n",
      "Current iteration=500, loss=nan\n",
      "Current iteration=600, loss=nan\n",
      "Current iteration=700, loss=nan\n",
      "Current iteration=800, loss=nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-c76101953c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mybs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjet_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my_logistic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mybs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mjet_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimal_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_optimal_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_logistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardized_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mlambdas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimal_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_optimal_lambda\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mloss_te_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mloss_te_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_te\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mtesting_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_te_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_cross_validation\u001b[0;34m(y, tx, k_indices, k, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# regularized logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;31m# calculate the loss for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# get loss and update w.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_by_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# log info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlearning_by_gradient_descent\u001b[0;34m(y, tx, w, gamma, lambda_)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \"\"\"\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Epfl/Courses/ML_course/projects/project1/scripts/implementations.py\u001b[0m in \u001b[0;36mlogistic_gradient\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m\"\"\"compute the gradient of loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lambdas = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    optimal_lambda = logistic_optimal_lambda(y_logistic, standardized_dset, initial_w, max_iters, gamma)\n",
    "    lambdas.append(optimal_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.0001, 0.00013738237958832623]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambdas when replacing -999 by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0001, 0.0001, 0.0001]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, loss=0.5981457873646676\n",
      "Current iteration=100, loss=0.40570366954781983\n",
      "Current iteration=200, loss=0.39811158731651086\n",
      "Current iteration=300, loss=0.3951233762054761\n",
      "Current iteration=400, loss=0.3937249484158812\n",
      "Current iteration=500, loss=0.39302899842308897\n",
      "Current iteration=600, loss=0.3926703056127306\n",
      "Current iteration=700, loss=0.39248120630136046\n",
      "Current iteration=800, loss=0.3923800033816537\n",
      "Current iteration=900, loss=0.39232526283559516\n",
      "Current iteration=1000, loss=0.3922954253301242\n",
      "Current iteration=1100, loss=0.3922790701887242\n",
      "Current iteration=1200, loss=0.39227006822843535\n",
      "Current iteration=1300, loss=0.3922650984133083\n",
      "Current iteration=1400, loss=0.3922623484964606\n",
      "Current iteration=1500, loss=0.3922608243656276\n",
      "Current iteration=0, loss=0.6370622906477821\n",
      "Current iteration=100, loss=0.5440962786181257\n",
      "Current iteration=200, loss=0.5421053931684284\n",
      "Current iteration=300, loss=0.5416118282423613\n",
      "Current iteration=400, loss=0.54146090795682\n",
      "Current iteration=500, loss=0.5414110536697603\n",
      "Current iteration=600, loss=0.5413940004007834\n",
      "Current iteration=700, loss=0.5413880623987355\n",
      "Current iteration=800, loss=0.541385974816579\n",
      "Current iteration=0, loss=0.6052480026197808\n",
      "Current iteration=100, loss=0.5277363905813086\n",
      "Current iteration=200, loss=0.5253907368563153\n",
      "Current iteration=300, loss=0.524873646207783\n",
      "Current iteration=400, loss=0.5247265930618712\n",
      "Current iteration=500, loss=0.5246787258130633\n",
      "Current iteration=600, loss=0.5246616388789702\n",
      "Current iteration=700, loss=0.5246551142235027\n",
      "Current iteration=800, loss=0.5246524867060653\n"
     ]
    }
   ],
   "source": [
    "ws_RLR = []\n",
    "for jet_num, standardized_dset in enumerate(standardized_dsets):\n",
    "    initial_w = np.zeros(standardized_dset.shape[1])\n",
    "    max_iters = 2000\n",
    "    gamma = 0.7 # 0.01\n",
    "    y_logistic = np.ones(ybs[jet_num].size)\n",
    "    y_logistic[ybs[jet_num] == -1] = 0\n",
    "    loss, w_RLR = reg_logistic_regression(y_logistic, standardized_dset, lambdas[jet_num], initial_w, max_iters, gamma)\n",
    "    ws_RLR.append(w_RLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_predictions(x_te, ws_RLR, pri_jet_num_idx, clean_features, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7599400000000001\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second score, after replacing -999 in DER_mass_MMC by the defined mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76004\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third score, after replacing -999 in DER_mass_MMC by the defined median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7593799999999999\n"
     ]
    }
   ],
   "source": [
    "compute_accuracy(y_te,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
